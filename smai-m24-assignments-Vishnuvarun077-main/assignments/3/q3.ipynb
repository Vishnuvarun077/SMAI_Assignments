{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           CRIM          ZN      INDUS      CHAS       NOX        RM  \\\n",
      "mean   3.611874   11.211934  11.083992  0.069959  0.554695  6.284634   \n",
      "std    8.720192   23.388876   6.835896  0.255340  0.115878  0.702617   \n",
      "min    0.006320    0.000000   0.460000  0.000000  0.385000  3.561000   \n",
      "max   88.976200  100.000000  27.740000  1.000000  0.871000  8.780000   \n",
      "\n",
      "             AGE        DIS        RAD         TAX    PTRATIO           B  \\\n",
      "mean   68.518519   3.795043   9.549407  408.237154  18.455534  356.674032   \n",
      "std    27.999513   2.105710   8.707259  168.537116   2.164946   91.294864   \n",
      "min     2.900000   1.129600   1.000000  187.000000  12.600000    0.320000   \n",
      "max   100.000000  12.126500  24.000000  711.000000  22.000000  396.900000   \n",
      "\n",
      "          LSTAT       MEDV  \n",
      "mean  12.715432  22.532806  \n",
      "std    7.155871   9.197104  \n",
      "min    1.730000   5.000000  \n",
      "max   37.970000  50.000000  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset and display basic statistics\n",
    "housing_data = pd.read_csv(\"../../data/external/HousingData.csv\")\n",
    "stats_summary = housing_data.agg(['mean', 'std', 'min', 'max'])\n",
    "print(stats_summary)\n",
    "\n",
    "# Plot the distribution of the target variable (MEDV)\n",
    "medv_values = housing_data['MEDV']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(medv_values, bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('MEDV')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of MEDV')\n",
    "plt.savefig('figures/3/MEDV_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
    "features = housing_data.drop(columns=['MEDV'])\n",
    "target = housing_data['MEDV']\n",
    "target = np.array(target).reshape(-1, 1)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Normalize the features using Min-Max scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_normalized = min_max_scaler.fit_transform(X_train_imputed)\n",
    "X_val_normalized = min_max_scaler.transform(X_val_imputed)\n",
    "X_test_normalized = min_max_scaler.transform(X_test_imputed)\n",
    "\n",
    "# Standardize the features to have mean=0 and std=1 using Z-score scaling\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standardized = standard_scaler.fit_transform(X_train_imputed)\n",
    "X_val_standardized = standard_scaler.transform(X_val_imputed)\n",
    "X_test_standardized = standard_scaler.transform(X_test_imputed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:qdi3z82p) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-durian-5</strong> at: <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal/runs/qdi3z82p' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal/runs/qdi3z82p</a><br/> View project at: <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241010_021411-qdi3z82p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:qdi3z82p). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srivishnuvarun/3rd year/SMAI/smai-m24-assignments-Vishnuvarun077/assignments/3/wandb/run-20241010_021622-vbd5arbi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal/runs/vbd5arbi' target=\"_blank\">charmed-river-6</a></strong> to <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal/runs/vbd5arbi' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal/runs/vbd5arbi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 77.4661\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 68.5489\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 73.7671\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 86.4225\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 83.1795\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 91.1427\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 158.4535\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 160.0700\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 142.5039\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 75.8649\n",
      "Epoch 200/500, Loss: 56.8447\n",
      "Epoch 300/500, Loss: 45.5020\n",
      "Epoch 400/500, Loss: 38.1486\n",
      "Epoch 500/500, Loss: 32.4123\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 74.1928\n",
      "Epoch 200/500, Loss: 57.5791\n",
      "Epoch 300/500, Loss: 46.2761\n",
      "Epoch 400/500, Loss: 38.9784\n",
      "Epoch 500/500, Loss: 33.2532\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 76.0521\n",
      "Epoch 200/500, Loss: 56.4046\n",
      "Epoch 300/500, Loss: 45.4125\n",
      "Epoch 400/500, Loss: 38.6864\n",
      "Epoch 500/500, Loss: 33.4597\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 91.2870\n",
      "Epoch 200/500, Loss: 76.7580\n",
      "Epoch 300/500, Loss: 67.7599\n",
      "Epoch 400/500, Loss: 59.2864\n",
      "Epoch 500/500, Loss: 52.2789\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 88.8189\n",
      "Epoch 200/500, Loss: 73.8605\n",
      "Epoch 300/500, Loss: 64.3481\n",
      "Epoch 400/500, Loss: 56.5066\n",
      "Epoch 500/500, Loss: 50.8285\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 86.2723\n",
      "Epoch 200/500, Loss: 72.0145\n",
      "Epoch 300/500, Loss: 63.6259\n",
      "Epoch 400/500, Loss: 56.4082\n",
      "Epoch 500/500, Loss: 50.8916\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 178.9041\n",
      "Epoch 200/500, Loss: 88.1711\n",
      "Epoch 300/500, Loss: 77.1770\n",
      "Epoch 400/500, Loss: 71.8211\n",
      "Epoch 500/500, Loss: 66.7585\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 150.0426\n",
      "Epoch 200/500, Loss: 85.6657\n",
      "Epoch 300/500, Loss: 77.5087\n",
      "Epoch 400/500, Loss: 72.7160\n",
      "Epoch 500/500, Loss: 67.5787\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 169.0604\n",
      "Epoch 200/500, Loss: 81.4062\n",
      "Epoch 300/500, Loss: 72.0529\n",
      "Epoch 400/500, Loss: 66.8114\n",
      "Epoch 500/500, Loss: 61.8588\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 75.4375\n",
      "Epoch 200/1000, Loss: 53.9836\n",
      "Epoch 300/1000, Loss: 42.7698\n",
      "Epoch 400/1000, Loss: 35.8211\n",
      "Epoch 500/1000, Loss: 30.7950\n",
      "Epoch 600/1000, Loss: 27.6753\n",
      "Epoch 700/1000, Loss: 25.7520\n",
      "Epoch 800/1000, Loss: 24.3741\n",
      "Epoch 900/1000, Loss: 23.2493\n",
      "Epoch 1000/1000, Loss: 22.2718\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 71.6422\n",
      "Epoch 200/1000, Loss: 52.7073\n",
      "Epoch 300/1000, Loss: 43.0979\n",
      "Epoch 400/1000, Loss: 36.6526\n",
      "Epoch 500/1000, Loss: 31.6271\n",
      "Epoch 600/1000, Loss: 28.2705\n",
      "Epoch 700/1000, Loss: 26.1276\n",
      "Epoch 800/1000, Loss: 24.6166\n",
      "Epoch 900/1000, Loss: 23.4180\n",
      "Epoch 1000/1000, Loss: 22.3984\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 73.4739\n",
      "Epoch 200/1000, Loss: 54.0285\n",
      "Epoch 300/1000, Loss: 43.3204\n",
      "Epoch 400/1000, Loss: 36.0519\n",
      "Epoch 500/1000, Loss: 30.8164\n",
      "Epoch 600/1000, Loss: 27.6504\n",
      "Epoch 700/1000, Loss: 25.7043\n",
      "Epoch 800/1000, Loss: 24.3013\n",
      "Epoch 900/1000, Loss: 23.1503\n",
      "Epoch 1000/1000, Loss: 22.1478\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 89.6864\n",
      "Epoch 200/1000, Loss: 75.5409\n",
      "Epoch 300/1000, Loss: 65.9998\n",
      "Epoch 400/1000, Loss: 57.8576\n",
      "Epoch 500/1000, Loss: 51.6590\n",
      "Epoch 600/1000, Loss: 46.8324\n",
      "Epoch 700/1000, Loss: 42.6664\n",
      "Epoch 800/1000, Loss: 38.8371\n",
      "Epoch 900/1000, Loss: 35.3554\n",
      "Epoch 1000/1000, Loss: 32.3590\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 89.0192\n",
      "Epoch 200/1000, Loss: 70.8564\n",
      "Epoch 300/1000, Loss: 58.9557\n",
      "Epoch 400/1000, Loss: 50.8583\n",
      "Epoch 500/1000, Loss: 45.6844\n",
      "Epoch 600/1000, Loss: 41.7889\n",
      "Epoch 700/1000, Loss: 38.3932\n",
      "Epoch 800/1000, Loss: 35.3477\n",
      "Epoch 900/1000, Loss: 32.7136\n",
      "Epoch 1000/1000, Loss: 30.5372\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 91.4491\n",
      "Epoch 200/1000, Loss: 75.3155\n",
      "Epoch 300/1000, Loss: 64.5138\n",
      "Epoch 400/1000, Loss: 54.9572\n",
      "Epoch 500/1000, Loss: 48.2322\n",
      "Epoch 600/1000, Loss: 43.4903\n",
      "Epoch 700/1000, Loss: 39.6362\n",
      "Epoch 800/1000, Loss: 36.2523\n",
      "Epoch 900/1000, Loss: 33.3227\n",
      "Epoch 1000/1000, Loss: 30.9176\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 169.2449\n",
      "Epoch 200/1000, Loss: 88.4838\n",
      "Epoch 300/1000, Loss: 79.5061\n",
      "Epoch 400/1000, Loss: 74.4014\n",
      "Epoch 500/1000, Loss: 69.3349\n",
      "Epoch 600/1000, Loss: 64.5132\n",
      "Epoch 700/1000, Loss: 60.1530\n",
      "Epoch 800/1000, Loss: 56.3477\n",
      "Epoch 900/1000, Loss: 53.1145\n",
      "Epoch 1000/1000, Loss: 50.3873\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 173.5624\n",
      "Epoch 200/1000, Loss: 87.6155\n",
      "Epoch 300/1000, Loss: 76.9729\n",
      "Epoch 400/1000, Loss: 71.8081\n",
      "Epoch 500/1000, Loss: 66.8375\n",
      "Epoch 600/1000, Loss: 62.0184\n",
      "Epoch 700/1000, Loss: 57.6842\n",
      "Epoch 800/1000, Loss: 53.9985\n",
      "Epoch 900/1000, Loss: 50.9101\n",
      "Epoch 1000/1000, Loss: 48.2802\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 162.9370\n",
      "Epoch 200/1000, Loss: 86.2311\n",
      "Epoch 300/1000, Loss: 77.7137\n",
      "Epoch 400/1000, Loss: 73.2752\n",
      "Epoch 500/1000, Loss: 68.7663\n",
      "Epoch 600/1000, Loss: 64.1237\n",
      "Epoch 700/1000, Loss: 59.5779\n",
      "Epoch 800/1000, Loss: 55.3631\n",
      "Epoch 900/1000, Loss: 51.6165\n",
      "Epoch 1000/1000, Loss: 48.3517\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 21.4399\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 21.7933\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 22.0220\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 34.9196\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 33.6560\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 34.3815\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 50.9848\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 45.1242\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 52.1458\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 22.0272\n",
      "Epoch 200/500, Loss: 16.4191\n",
      "Epoch 300/500, Loss: 13.7540\n",
      "Epoch 400/500, Loss: 12.0274\n",
      "Epoch 500/500, Loss: 10.6540\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 22.5156\n",
      "Epoch 200/500, Loss: 16.6034\n",
      "Epoch 300/500, Loss: 14.0343\n",
      "Epoch 400/500, Loss: 12.4548\n",
      "Epoch 500/500, Loss: 11.1863\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 22.6526\n",
      "Epoch 200/500, Loss: 16.4346\n",
      "Epoch 300/500, Loss: 13.6522\n",
      "Epoch 400/500, Loss: 12.0269\n",
      "Epoch 500/500, Loss: 10.6619\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 30.2168\n",
      "Epoch 200/500, Loss: 21.7335\n",
      "Epoch 300/500, Loss: 18.3984\n",
      "Epoch 400/500, Loss: 16.3065\n",
      "Epoch 500/500, Loss: 14.8740\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 31.9359\n",
      "Epoch 200/500, Loss: 22.3140\n",
      "Epoch 300/500, Loss: 19.1531\n",
      "Epoch 400/500, Loss: 16.9030\n",
      "Epoch 500/500, Loss: 15.1684\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 30.4023\n",
      "Epoch 200/500, Loss: 21.9753\n",
      "Epoch 300/500, Loss: 18.7211\n",
      "Epoch 400/500, Loss: 16.5955\n",
      "Epoch 500/500, Loss: 15.1424\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 52.6209\n",
      "Epoch 200/500, Loss: 32.7718\n",
      "Epoch 300/500, Loss: 24.5672\n",
      "Epoch 400/500, Loss: 21.4945\n",
      "Epoch 500/500, Loss: 19.4122\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 48.2393\n",
      "Epoch 200/500, Loss: 29.8981\n",
      "Epoch 300/500, Loss: 24.6673\n",
      "Epoch 400/500, Loss: 21.9338\n",
      "Epoch 500/500, Loss: 19.8736\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 48.2263\n",
      "Epoch 200/500, Loss: 30.2330\n",
      "Epoch 300/500, Loss: 24.7325\n",
      "Epoch 400/500, Loss: 21.9063\n",
      "Epoch 500/500, Loss: 19.8013\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 22.3300\n",
      "Epoch 200/1000, Loss: 16.2019\n",
      "Epoch 300/1000, Loss: 13.6889\n",
      "Epoch 400/1000, Loss: 12.2745\n",
      "Epoch 500/1000, Loss: 11.0307\n",
      "Epoch 600/1000, Loss: 9.8220\n",
      "Epoch 700/1000, Loss: 8.7562\n",
      "Epoch 800/1000, Loss: 7.8927\n",
      "Epoch 900/1000, Loss: 7.2105\n",
      "Epoch 1000/1000, Loss: 6.6714\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 22.5016\n",
      "Epoch 200/1000, Loss: 16.2889\n",
      "Epoch 300/1000, Loss: 13.8361\n",
      "Epoch 400/1000, Loss: 12.2972\n",
      "Epoch 500/1000, Loss: 11.0030\n",
      "Epoch 600/1000, Loss: 9.8351\n",
      "Epoch 700/1000, Loss: 8.7697\n",
      "Epoch 800/1000, Loss: 7.8474\n",
      "Epoch 900/1000, Loss: 7.1023\n",
      "Early stopping at epoch 913\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 22.5126\n",
      "Epoch 200/1000, Loss: 17.1549\n",
      "Epoch 300/1000, Loss: 14.1499\n",
      "Epoch 400/1000, Loss: 12.1803\n",
      "Epoch 500/1000, Loss: 10.5885\n",
      "Epoch 600/1000, Loss: 9.2551\n",
      "Epoch 700/1000, Loss: 8.1880\n",
      "Epoch 800/1000, Loss: 7.3640\n",
      "Epoch 900/1000, Loss: 6.7323\n",
      "Epoch 1000/1000, Loss: 6.2411\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 28.8023\n",
      "Epoch 200/1000, Loss: 22.0012\n",
      "Epoch 300/1000, Loss: 18.7898\n",
      "Epoch 400/1000, Loss: 16.5992\n",
      "Epoch 500/1000, Loss: 15.1008\n",
      "Epoch 600/1000, Loss: 14.0092\n",
      "Epoch 700/1000, Loss: 13.1240\n",
      "Epoch 800/1000, Loss: 12.3558\n",
      "Epoch 900/1000, Loss: 11.6741\n",
      "Epoch 1000/1000, Loss: 11.0544\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 33.0779\n",
      "Epoch 200/1000, Loss: 22.3267\n",
      "Epoch 300/1000, Loss: 18.9017\n",
      "Epoch 400/1000, Loss: 16.6317\n",
      "Epoch 500/1000, Loss: 15.1104\n",
      "Epoch 600/1000, Loss: 14.0657\n",
      "Early stopping at epoch 631\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 33.4555\n",
      "Epoch 200/1000, Loss: 22.0940\n",
      "Epoch 300/1000, Loss: 18.6154\n",
      "Epoch 400/1000, Loss: 16.3517\n",
      "Epoch 500/1000, Loss: 14.7610\n",
      "Epoch 600/1000, Loss: 13.5671\n",
      "Epoch 700/1000, Loss: 12.5750\n",
      "Epoch 800/1000, Loss: 11.6942\n",
      "Epoch 900/1000, Loss: 10.8969\n",
      "Epoch 1000/1000, Loss: 10.1593\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 52.1145\n",
      "Epoch 200/1000, Loss: 33.9967\n",
      "Epoch 300/1000, Loss: 26.3576\n",
      "Epoch 400/1000, Loss: 23.1467\n",
      "Epoch 500/1000, Loss: 20.9623\n",
      "Epoch 600/1000, Loss: 19.2836\n",
      "Epoch 700/1000, Loss: 17.9222\n",
      "Epoch 800/1000, Loss: 16.8044\n",
      "Epoch 900/1000, Loss: 15.8938\n",
      "Epoch 1000/1000, Loss: 15.1408\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 47.2545\n",
      "Epoch 200/1000, Loss: 29.6011\n",
      "Epoch 300/1000, Loss: 24.1896\n",
      "Epoch 400/1000, Loss: 21.6235\n",
      "Epoch 500/1000, Loss: 19.7419\n",
      "Epoch 600/1000, Loss: 18.2347\n",
      "Epoch 700/1000, Loss: 17.0047\n",
      "Epoch 800/1000, Loss: 16.0073\n",
      "Epoch 900/1000, Loss: 15.2036\n",
      "Epoch 1000/1000, Loss: 14.5525\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 48.8222\n",
      "Epoch 200/1000, Loss: 30.1293\n",
      "Epoch 300/1000, Loss: 24.5807\n",
      "Epoch 400/1000, Loss: 21.7659\n",
      "Epoch 500/1000, Loss: 19.7851\n",
      "Epoch 600/1000, Loss: 18.2585\n",
      "Epoch 700/1000, Loss: 17.0279\n",
      "Epoch 800/1000, Loss: 16.0172\n",
      "Epoch 900/1000, Loss: 15.1813\n",
      "Epoch 1000/1000, Loss: 14.4873\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 34\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 37\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 7.0468\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 11.3197\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 11.2240\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 11.1563\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 14.5775\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 14.6761\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 14.0681\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 36\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 7.5562\n",
      "Epoch 200/500, Loss: 4.8876\n",
      "Early stopping at epoch 250\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 7.7575\n",
      "Epoch 200/500, Loss: 4.8363\n",
      "Early stopping at epoch 206\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 11.8163\n",
      "Epoch 200/500, Loss: 7.1997\n",
      "Early stopping at epoch 202\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 11.4135\n",
      "Epoch 200/500, Loss: 7.0590\n",
      "Epoch 300/500, Loss: 5.3813\n",
      "Epoch 400/500, Loss: 4.4651\n",
      "Epoch 500/500, Loss: 3.8374\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 11.6428\n",
      "Epoch 200/500, Loss: 7.0170\n",
      "Epoch 300/500, Loss: 5.1757\n",
      "Epoch 400/500, Loss: 4.3647\n",
      "Epoch 500/500, Loss: 3.8095\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 14.0650\n",
      "Epoch 200/500, Loss: 10.2516\n",
      "Epoch 300/500, Loss: 7.7664\n",
      "Epoch 400/500, Loss: 6.3820\n",
      "Epoch 500/500, Loss: 5.5955\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 15.1592\n",
      "Early stopping at epoch 128\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 14.6785\n",
      "Early stopping at epoch 116\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 7.6721\n",
      "Epoch 200/1000, Loss: 5.0674\n",
      "Epoch 300/1000, Loss: 3.9412\n",
      "Early stopping at epoch 326\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 7.6625\n",
      "Early stopping at epoch 187\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 7.5456\n",
      "Epoch 200/1000, Loss: 5.1224\n",
      "Early stopping at epoch 243\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 11.7042\n",
      "Epoch 200/1000, Loss: 6.8069\n",
      "Epoch 300/1000, Loss: 5.0570\n",
      "Epoch 400/1000, Loss: 4.2870\n",
      "Early stopping at epoch 425\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 72\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 11.3411\n",
      "Epoch 200/1000, Loss: 7.0108\n",
      "Epoch 300/1000, Loss: 5.4046\n",
      "Epoch 400/1000, Loss: 4.5416\n",
      "Early stopping at epoch 498\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 14.4122\n",
      "Epoch 200/1000, Loss: 10.1712\n",
      "Epoch 300/1000, Loss: 7.7574\n",
      "Epoch 400/1000, Loss: 6.3904\n",
      "Epoch 500/1000, Loss: 5.5855\n",
      "Epoch 600/1000, Loss: 5.0143\n",
      "Epoch 700/1000, Loss: 4.5576\n",
      "Epoch 800/1000, Loss: 4.1812\n",
      "Epoch 900/1000, Loss: 3.8666\n",
      "Early stopping at epoch 920\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 14.6128\n",
      "Epoch 200/1000, Loss: 9.7115\n",
      "Epoch 300/1000, Loss: 7.1097\n",
      "Epoch 400/1000, Loss: 5.8675\n",
      "Epoch 500/1000, Loss: 5.1778\n",
      "Epoch 600/1000, Loss: 4.6999\n",
      "Epoch 700/1000, Loss: 4.3252\n",
      "Epoch 800/1000, Loss: 4.0111\n",
      "Epoch 900/1000, Loss: 3.7388\n",
      "Early stopping at epoch 942\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 14.3014\n",
      "Early stopping at epoch 103\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 99\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 86\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 70\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 78.2476\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 69.6232\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 75.6628\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 303.6980\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 255.2631\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 319.8063\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 66\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 81\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 63.1077\n",
      "Early stopping at epoch 111\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 79.8185\n",
      "Epoch 200/500, Loss: 65.9588\n",
      "Early stopping at epoch 282\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 79.7750\n",
      "Early stopping at epoch 153\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 74.0872\n",
      "Early stopping at epoch 128\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 266.1554\n",
      "Epoch 200/500, Loss: 70.3049\n",
      "Early stopping at epoch 232\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 233.9608\n",
      "Epoch 200/500, Loss: 69.4040\n",
      "Epoch 300/500, Loss: 62.2479\n",
      "Early stopping at epoch 396\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 270.5748\n",
      "Epoch 200/500, Loss: 66.5863\n",
      "Early stopping at epoch 242\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 64.8454\n",
      "Early stopping at epoch 116\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 72\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 94\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 76.9500\n",
      "Epoch 200/1000, Loss: 60.5272\n",
      "Early stopping at epoch 299\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 85.3877\n",
      "Epoch 200/1000, Loss: 63.7228\n",
      "Early stopping at epoch 253\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 73.8927\n",
      "Early stopping at epoch 126\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 270.9002\n",
      "Epoch 200/1000, Loss: 70.7857\n",
      "Epoch 300/1000, Loss: 61.2912\n",
      "Early stopping at epoch 380\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 286.6331\n",
      "Epoch 200/1000, Loss: 71.1873\n",
      "Epoch 300/1000, Loss: 60.2752\n",
      "Early stopping at epoch 303\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 323.9474\n",
      "Epoch 200/1000, Loss: 76.7517\n",
      "Epoch 300/1000, Loss: 62.5627\n",
      "Epoch 400/1000, Loss: 59.8714\n",
      "Early stopping at epoch 446\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 29\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 27\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 75\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 30\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 28\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 9\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 28\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 27\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 46\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 30\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 41\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 15\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 27\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 30\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 15\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 42\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 42\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 43\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 6\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 15\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 9\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 6\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 5\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 5\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 5\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 6\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 6\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 5\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 17.8601\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 17.4467\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 18.3602\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 21.5433\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 27.8236\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 21.8367\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 36.0249\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 33.6558\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 30.1646\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 16.0146\n",
      "Epoch 200/500, Loss: 12.4550\n",
      "Epoch 300/500, Loss: 10.7382\n",
      "Epoch 400/500, Loss: 9.5647\n",
      "Epoch 500/500, Loss: 8.6294\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 16.2846\n",
      "Epoch 200/500, Loss: 12.9088\n",
      "Epoch 300/500, Loss: 11.2080\n",
      "Epoch 400/500, Loss: 10.1206\n",
      "Early stopping at epoch 433\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 17.7405\n",
      "Epoch 200/500, Loss: 12.8933\n",
      "Epoch 300/500, Loss: 10.8340\n",
      "Epoch 400/500, Loss: 9.5908\n",
      "Epoch 500/500, Loss: 8.6832\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 24.6739\n",
      "Epoch 200/500, Loss: 19.2325\n",
      "Epoch 300/500, Loss: 16.7680\n",
      "Epoch 400/500, Loss: 15.1288\n",
      "Epoch 500/500, Loss: 13.9324\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 22.3084\n",
      "Epoch 200/500, Loss: 17.7497\n",
      "Epoch 300/500, Loss: 15.6396\n",
      "Epoch 400/500, Loss: 14.2315\n",
      "Epoch 500/500, Loss: 13.1200\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 20.0044\n",
      "Epoch 200/500, Loss: 16.6732\n",
      "Epoch 300/500, Loss: 14.9718\n",
      "Epoch 400/500, Loss: 13.7674\n",
      "Epoch 500/500, Loss: 12.8233\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 32.1866\n",
      "Epoch 200/500, Loss: 22.3844\n",
      "Epoch 300/500, Loss: 19.0745\n",
      "Epoch 400/500, Loss: 17.0715\n",
      "Epoch 500/500, Loss: 15.7044\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 34.8333\n",
      "Epoch 200/500, Loss: 23.6790\n",
      "Epoch 300/500, Loss: 20.0498\n",
      "Epoch 400/500, Loss: 17.8927\n",
      "Epoch 500/500, Loss: 16.3784\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 34.0466\n",
      "Epoch 200/500, Loss: 24.3148\n",
      "Epoch 300/500, Loss: 20.7957\n",
      "Epoch 400/500, Loss: 18.6517\n",
      "Epoch 500/500, Loss: 17.1994\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 20.0364\n",
      "Epoch 200/1000, Loss: 15.2348\n",
      "Epoch 300/1000, Loss: 12.8023\n",
      "Epoch 400/1000, Loss: 11.1930\n",
      "Epoch 500/1000, Loss: 9.9838\n",
      "Epoch 600/1000, Loss: 9.0116\n",
      "Early stopping at epoch 626\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 16.6724\n",
      "Epoch 200/1000, Loss: 13.0540\n",
      "Epoch 300/1000, Loss: 11.2796\n",
      "Early stopping at epoch 399\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 18.4352\n",
      "Epoch 200/1000, Loss: 15.1806\n",
      "Epoch 300/1000, Loss: 13.2511\n",
      "Epoch 400/1000, Loss: 11.8831\n",
      "Epoch 500/1000, Loss: 10.7178\n",
      "Epoch 600/1000, Loss: 9.6871\n",
      "Early stopping at epoch 649\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 25.7794\n",
      "Epoch 200/1000, Loss: 20.1147\n",
      "Epoch 300/1000, Loss: 17.1804\n",
      "Epoch 400/1000, Loss: 15.2644\n",
      "Epoch 500/1000, Loss: 13.9096\n",
      "Epoch 600/1000, Loss: 12.8939\n",
      "Epoch 700/1000, Loss: 12.0754\n",
      "Epoch 800/1000, Loss: 11.4181\n",
      "Epoch 900/1000, Loss: 10.8578\n",
      "Epoch 1000/1000, Loss: 10.3763\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 23.5734\n",
      "Epoch 200/1000, Loss: 18.3420\n",
      "Epoch 300/1000, Loss: 15.7721\n",
      "Epoch 400/1000, Loss: 14.0338\n",
      "Epoch 500/1000, Loss: 12.7655\n",
      "Epoch 600/1000, Loss: 11.7847\n",
      "Epoch 700/1000, Loss: 11.0459\n",
      "Epoch 800/1000, Loss: 10.4427\n",
      "Epoch 900/1000, Loss: 9.9182\n",
      "Epoch 1000/1000, Loss: 9.4478\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 25.5629\n",
      "Epoch 200/1000, Loss: 20.0960\n",
      "Epoch 300/1000, Loss: 17.2034\n",
      "Epoch 400/1000, Loss: 15.2887\n",
      "Epoch 500/1000, Loss: 13.9227\n",
      "Epoch 600/1000, Loss: 12.8661\n",
      "Epoch 700/1000, Loss: 12.0185\n",
      "Epoch 800/1000, Loss: 11.2958\n",
      "Epoch 900/1000, Loss: 10.6541\n",
      "Early stopping at epoch 950\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 36.0957\n",
      "Epoch 200/1000, Loss: 23.7380\n",
      "Epoch 300/1000, Loss: 19.7386\n",
      "Epoch 400/1000, Loss: 17.4433\n",
      "Epoch 500/1000, Loss: 15.8157\n",
      "Epoch 600/1000, Loss: 14.5983\n",
      "Epoch 700/1000, Loss: 13.6479\n",
      "Epoch 800/1000, Loss: 12.8813\n",
      "Epoch 900/1000, Loss: 12.2293\n",
      "Epoch 1000/1000, Loss: 11.6642\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 32.8214\n",
      "Epoch 200/1000, Loss: 21.8521\n",
      "Epoch 300/1000, Loss: 18.5740\n",
      "Epoch 400/1000, Loss: 16.6950\n",
      "Epoch 500/1000, Loss: 15.4052\n",
      "Epoch 600/1000, Loss: 14.4528\n",
      "Epoch 700/1000, Loss: 13.7158\n",
      "Epoch 800/1000, Loss: 13.1173\n",
      "Epoch 900/1000, Loss: 12.6135\n",
      "Epoch 1000/1000, Loss: 12.1724\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 35.1196\n",
      "Epoch 200/1000, Loss: 22.0936\n",
      "Epoch 300/1000, Loss: 19.1130\n",
      "Epoch 400/1000, Loss: 17.5142\n",
      "Epoch 500/1000, Loss: 16.3726\n",
      "Epoch 600/1000, Loss: 15.4826\n",
      "Epoch 700/1000, Loss: 14.7163\n",
      "Epoch 800/1000, Loss: 14.0366\n",
      "Epoch 900/1000, Loss: 13.4363\n",
      "Epoch 1000/1000, Loss: 12.8967\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 98\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 73\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 78\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 10.0805\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 98\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 10.4657\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 11.5461\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 12.9936\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 13.0288\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 93\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 75\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 8.0447\n",
      "Early stopping at epoch 103\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 9.8825\n",
      "Epoch 200/500, Loss: 6.7788\n",
      "Early stopping at epoch 245\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 10.1520\n",
      "Early stopping at epoch 112\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 9.0455\n",
      "Early stopping at epoch 127\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 13.0857\n",
      "Epoch 200/500, Loss: 9.6813\n",
      "Epoch 300/500, Loss: 7.6557\n",
      "Early stopping at epoch 371\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 13.1325\n",
      "Epoch 200/500, Loss: 9.9602\n",
      "Epoch 300/500, Loss: 7.9951\n",
      "Early stopping at epoch 306\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 12.4759\n",
      "Epoch 200/500, Loss: 9.0950\n",
      "Epoch 300/500, Loss: 7.1861\n",
      "Epoch 400/500, Loss: 5.9213\n",
      "Early stopping at epoch 424\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 67\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 7.8858\n",
      "Early stopping at epoch 109\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 7.1511\n",
      "Early stopping at epoch 134\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 10.3082\n",
      "Early stopping at epoch 170\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 10.2242\n",
      "Early stopping at epoch 130\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 9.4685\n",
      "Early stopping at epoch 189\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 11.6123\n",
      "Early stopping at epoch 145\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 12.2039\n",
      "Epoch 200/1000, Loss: 8.5709\n",
      "Epoch 300/1000, Loss: 6.8006\n",
      "Early stopping at epoch 375\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 12.5750\n",
      "Epoch 200/1000, Loss: 9.1582\n",
      "Early stopping at epoch 298\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 6\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 29\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 12\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 17\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 18\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 6\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 17\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 33\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 12\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 13\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 24\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 11\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 13\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 58\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 45\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 10\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 10\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 15\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 13\n",
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 17\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 69.2233\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 65.1122\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 63.3127\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 78.3653\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 79.6656\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 79.9631\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 98.0797\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 90.3682\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 92.8424\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 68.8352\n",
      "Epoch 200/500, Loss: 48.7748\n",
      "Epoch 300/500, Loss: 38.1031\n",
      "Epoch 400/500, Loss: 31.5479\n",
      "Epoch 500/500, Loss: 27.5478\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 63.7622\n",
      "Epoch 200/500, Loss: 46.3924\n",
      "Epoch 300/500, Loss: 37.5338\n",
      "Epoch 400/500, Loss: 31.7007\n",
      "Epoch 500/500, Loss: 27.8512\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 66.9531\n",
      "Epoch 200/500, Loss: 48.4635\n",
      "Epoch 300/500, Loss: 37.9199\n",
      "Epoch 400/500, Loss: 30.8088\n",
      "Epoch 500/500, Loss: 26.4746\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 77.0704\n",
      "Epoch 200/500, Loss: 65.1965\n",
      "Epoch 300/500, Loss: 54.6690\n",
      "Epoch 400/500, Loss: 46.8407\n",
      "Epoch 500/500, Loss: 41.2644\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 79.5591\n",
      "Epoch 200/500, Loss: 65.8467\n",
      "Epoch 300/500, Loss: 53.4607\n",
      "Epoch 400/500, Loss: 44.8290\n",
      "Epoch 500/500, Loss: 38.8494\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 83.9063\n",
      "Epoch 200/500, Loss: 70.2042\n",
      "Epoch 300/500, Loss: 57.2811\n",
      "Epoch 400/500, Loss: 48.7719\n",
      "Epoch 500/500, Loss: 43.1213\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 92.6206\n",
      "Epoch 200/500, Loss: 75.4036\n",
      "Epoch 300/500, Loss: 68.3387\n",
      "Epoch 400/500, Loss: 61.6684\n",
      "Epoch 500/500, Loss: 55.9280\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 102.5620\n",
      "Epoch 200/500, Loss: 80.5893\n",
      "Epoch 300/500, Loss: 72.6272\n",
      "Epoch 400/500, Loss: 64.5663\n",
      "Epoch 500/500, Loss: 57.6032\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 99.5375\n",
      "Epoch 200/500, Loss: 78.2847\n",
      "Epoch 300/500, Loss: 71.2688\n",
      "Epoch 400/500, Loss: 64.3374\n",
      "Epoch 500/500, Loss: 58.0976\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 62.9588\n",
      "Epoch 200/1000, Loss: 46.9339\n",
      "Epoch 300/1000, Loss: 37.4233\n",
      "Epoch 400/1000, Loss: 30.6268\n",
      "Epoch 500/1000, Loss: 26.5821\n",
      "Epoch 600/1000, Loss: 24.3778\n",
      "Epoch 700/1000, Loss: 23.0271\n",
      "Epoch 800/1000, Loss: 22.0360\n",
      "Epoch 900/1000, Loss: 21.2212\n",
      "Epoch 1000/1000, Loss: 20.5136\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 63.4467\n",
      "Epoch 200/1000, Loss: 46.9007\n",
      "Epoch 300/1000, Loss: 37.8211\n",
      "Epoch 400/1000, Loss: 31.3399\n",
      "Epoch 500/1000, Loss: 27.2554\n",
      "Epoch 600/1000, Loss: 24.8672\n",
      "Epoch 700/1000, Loss: 23.3492\n",
      "Epoch 800/1000, Loss: 22.2469\n",
      "Epoch 900/1000, Loss: 21.3664\n",
      "Epoch 1000/1000, Loss: 20.6228\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 67.9656\n",
      "Epoch 200/1000, Loss: 48.0425\n",
      "Epoch 300/1000, Loss: 36.7629\n",
      "Epoch 400/1000, Loss: 29.8254\n",
      "Epoch 500/1000, Loss: 26.1164\n",
      "Epoch 600/1000, Loss: 24.1960\n",
      "Epoch 700/1000, Loss: 22.9757\n",
      "Epoch 800/1000, Loss: 22.0374\n",
      "Epoch 900/1000, Loss: 21.2469\n",
      "Epoch 1000/1000, Loss: 20.5532\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 79.9500\n",
      "Epoch 200/1000, Loss: 68.6097\n",
      "Epoch 300/1000, Loss: 58.4232\n",
      "Epoch 400/1000, Loss: 51.2972\n",
      "Epoch 500/1000, Loss: 46.2899\n",
      "Epoch 600/1000, Loss: 42.1199\n",
      "Epoch 700/1000, Loss: 38.3295\n",
      "Epoch 800/1000, Loss: 34.9027\n",
      "Epoch 900/1000, Loss: 31.9427\n",
      "Epoch 1000/1000, Loss: 29.5151\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 79.6844\n",
      "Epoch 200/1000, Loss: 65.7314\n",
      "Epoch 300/1000, Loss: 54.6877\n",
      "Epoch 400/1000, Loss: 47.5203\n",
      "Epoch 500/1000, Loss: 42.3794\n",
      "Epoch 600/1000, Loss: 38.1166\n",
      "Epoch 700/1000, Loss: 34.4883\n",
      "Epoch 800/1000, Loss: 31.5230\n",
      "Epoch 900/1000, Loss: 29.2120\n",
      "Epoch 1000/1000, Loss: 27.4614\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 79.2314\n",
      "Epoch 200/1000, Loss: 66.0806\n",
      "Epoch 300/1000, Loss: 55.1663\n",
      "Epoch 400/1000, Loss: 47.8951\n",
      "Epoch 500/1000, Loss: 42.9318\n",
      "Epoch 600/1000, Loss: 38.9688\n",
      "Epoch 700/1000, Loss: 35.5309\n",
      "Epoch 800/1000, Loss: 32.5657\n",
      "Epoch 900/1000, Loss: 30.1114\n",
      "Epoch 1000/1000, Loss: 28.1610\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 92.6531\n",
      "Epoch 200/1000, Loss: 76.1976\n",
      "Epoch 300/1000, Loss: 70.0574\n",
      "Epoch 400/1000, Loss: 64.0986\n",
      "Epoch 500/1000, Loss: 58.5691\n",
      "Epoch 600/1000, Loss: 53.7234\n",
      "Epoch 700/1000, Loss: 49.6139\n",
      "Epoch 800/1000, Loss: 46.1420\n",
      "Epoch 900/1000, Loss: 43.1628\n",
      "Epoch 1000/1000, Loss: 40.5489\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 99.8759\n",
      "Epoch 200/1000, Loss: 80.0424\n",
      "Epoch 300/1000, Loss: 73.6241\n",
      "Epoch 400/1000, Loss: 66.8398\n",
      "Epoch 500/1000, Loss: 60.2212\n",
      "Epoch 600/1000, Loss: 54.3857\n",
      "Epoch 700/1000, Loss: 49.5562\n",
      "Epoch 800/1000, Loss: 45.6409\n",
      "Epoch 900/1000, Loss: 42.4178\n",
      "Epoch 1000/1000, Loss: 39.6788\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 96.7293\n",
      "Epoch 200/1000, Loss: 80.2553\n",
      "Epoch 300/1000, Loss: 74.0896\n",
      "Epoch 400/1000, Loss: 67.8373\n",
      "Epoch 500/1000, Loss: 61.9833\n",
      "Epoch 600/1000, Loss: 56.7371\n",
      "Epoch 700/1000, Loss: 52.2215\n",
      "Epoch 800/1000, Loss: 48.4043\n",
      "Epoch 900/1000, Loss: 45.1341\n",
      "Epoch 1000/1000, Loss: 42.2552\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 20.9127\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 20.4714\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 20.6184\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 26.2975\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 26.2999\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 26.1498\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 39.9856\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 37.6259\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 37.2015\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 21.0557\n",
      "Epoch 200/500, Loss: 16.6769\n",
      "Epoch 300/500, Loss: 14.1706\n",
      "Early stopping at epoch 392\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 20.9914\n",
      "Epoch 200/500, Loss: 16.8138\n",
      "Epoch 300/500, Loss: 14.3463\n",
      "Early stopping at epoch 329\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 20.8209\n",
      "Epoch 200/500, Loss: 16.0694\n",
      "Epoch 300/500, Loss: 13.5968\n",
      "Epoch 400/500, Loss: 12.0617\n",
      "Epoch 500/500, Loss: 10.8593\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 25.3568\n",
      "Epoch 200/500, Loss: 20.0723\n",
      "Epoch 300/500, Loss: 17.5768\n",
      "Epoch 400/500, Loss: 15.9367\n",
      "Epoch 500/500, Loss: 14.7649\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 27.2314\n",
      "Epoch 200/500, Loss: 20.7138\n",
      "Epoch 300/500, Loss: 18.0624\n",
      "Epoch 400/500, Loss: 16.2525\n",
      "Epoch 500/500, Loss: 14.9266\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 27.2395\n",
      "Epoch 200/500, Loss: 20.7430\n",
      "Epoch 300/500, Loss: 18.0424\n",
      "Epoch 400/500, Loss: 16.2454\n",
      "Epoch 500/500, Loss: 14.9982\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 43.6034\n",
      "Epoch 200/500, Loss: 26.6821\n",
      "Epoch 300/500, Loss: 22.5415\n",
      "Epoch 400/500, Loss: 20.3916\n",
      "Epoch 500/500, Loss: 18.8293\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 41.4448\n",
      "Epoch 200/500, Loss: 27.1932\n",
      "Epoch 300/500, Loss: 22.9248\n",
      "Epoch 400/500, Loss: 20.6820\n",
      "Epoch 500/500, Loss: 19.0384\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 38.3095\n",
      "Epoch 200/500, Loss: 25.8681\n",
      "Epoch 300/500, Loss: 22.5432\n",
      "Epoch 400/500, Loss: 20.6512\n",
      "Epoch 500/500, Loss: 19.1893\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 20.1350\n",
      "Epoch 200/1000, Loss: 15.7978\n",
      "Epoch 300/1000, Loss: 13.4262\n",
      "Epoch 400/1000, Loss: 11.8545\n",
      "Epoch 500/1000, Loss: 10.5898\n",
      "Epoch 600/1000, Loss: 9.4732\n",
      "Epoch 700/1000, Loss: 8.5108\n",
      "Epoch 800/1000, Loss: 7.7257\n",
      "Epoch 900/1000, Loss: 7.1073\n",
      "Epoch 1000/1000, Loss: 6.6239\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 20.7755\n",
      "Epoch 200/1000, Loss: 16.3126\n",
      "Epoch 300/1000, Loss: 13.7803\n",
      "Epoch 400/1000, Loss: 12.1556\n",
      "Epoch 500/1000, Loss: 10.8487\n",
      "Epoch 600/1000, Loss: 9.6882\n",
      "Epoch 700/1000, Loss: 8.6558\n",
      "Epoch 800/1000, Loss: 7.7889\n",
      "Epoch 900/1000, Loss: 7.0978\n",
      "Epoch 1000/1000, Loss: 6.5609\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 21.1682\n",
      "Epoch 200/1000, Loss: 16.5312\n",
      "Epoch 300/1000, Loss: 14.0557\n",
      "Epoch 400/1000, Loss: 12.5331\n",
      "Epoch 500/1000, Loss: 11.3407\n",
      "Epoch 600/1000, Loss: 10.2512\n",
      "Epoch 700/1000, Loss: 9.2435\n",
      "Epoch 800/1000, Loss: 8.3471\n",
      "Epoch 900/1000, Loss: 7.5911\n",
      "Epoch 1000/1000, Loss: 6.9768\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 27.4415\n",
      "Epoch 200/1000, Loss: 21.1093\n",
      "Epoch 300/1000, Loss: 18.3558\n",
      "Epoch 400/1000, Loss: 16.5040\n",
      "Epoch 500/1000, Loss: 15.1936\n",
      "Epoch 600/1000, Loss: 14.2164\n",
      "Epoch 700/1000, Loss: 13.4400\n",
      "Epoch 800/1000, Loss: 12.7861\n",
      "Epoch 900/1000, Loss: 12.2068\n",
      "Epoch 1000/1000, Loss: 11.6748\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 27.5561\n",
      "Epoch 200/1000, Loss: 20.3954\n",
      "Epoch 300/1000, Loss: 17.7459\n",
      "Epoch 400/1000, Loss: 16.0131\n",
      "Epoch 500/1000, Loss: 14.7833\n",
      "Early stopping at epoch 591\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 26.7245\n",
      "Epoch 200/1000, Loss: 20.7621\n",
      "Epoch 300/1000, Loss: 18.1788\n",
      "Epoch 400/1000, Loss: 16.3725\n",
      "Epoch 500/1000, Loss: 15.0470\n",
      "Epoch 600/1000, Loss: 14.0318\n",
      "Epoch 700/1000, Loss: 13.2024\n",
      "Epoch 800/1000, Loss: 12.4852\n",
      "Epoch 900/1000, Loss: 11.8340\n",
      "Epoch 1000/1000, Loss: 11.2190\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 40.4047\n",
      "Epoch 200/1000, Loss: 25.6645\n",
      "Epoch 300/1000, Loss: 21.9987\n",
      "Epoch 400/1000, Loss: 19.8961\n",
      "Epoch 500/1000, Loss: 18.3651\n",
      "Epoch 600/1000, Loss: 17.1788\n",
      "Epoch 700/1000, Loss: 16.2287\n",
      "Epoch 800/1000, Loss: 15.4477\n",
      "Epoch 900/1000, Loss: 14.7898\n",
      "Epoch 1000/1000, Loss: 14.2224\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 38.3318\n",
      "Epoch 200/1000, Loss: 25.4890\n",
      "Epoch 300/1000, Loss: 21.8182\n",
      "Epoch 400/1000, Loss: 19.7154\n",
      "Epoch 500/1000, Loss: 18.1896\n",
      "Epoch 600/1000, Loss: 17.0070\n",
      "Epoch 700/1000, Loss: 16.0640\n",
      "Epoch 800/1000, Loss: 15.2956\n",
      "Epoch 900/1000, Loss: 14.6559\n",
      "Epoch 1000/1000, Loss: 14.1115\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 41.4895\n",
      "Epoch 200/1000, Loss: 26.1452\n",
      "Epoch 300/1000, Loss: 22.5737\n",
      "Epoch 400/1000, Loss: 20.5200\n",
      "Epoch 500/1000, Loss: 18.9350\n",
      "Epoch 600/1000, Loss: 17.6279\n",
      "Epoch 700/1000, Loss: 16.5268\n",
      "Epoch 800/1000, Loss: 15.5992\n",
      "Epoch 900/1000, Loss: 14.8199\n",
      "Epoch 1000/1000, Loss: 14.1624\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 8.7684\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 37\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 7.7865\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 11.2856\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 11.7116\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 11.4670\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 14.4753\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 14.4091\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 14.6183\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 33\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 8.2119\n",
      "Epoch 200/500, Loss: 5.4124\n",
      "Early stopping at epoch 228\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 7.4496\n",
      "Epoch 200/500, Loss: 5.1876\n",
      "Early stopping at epoch 243\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 11.5718\n",
      "Epoch 200/500, Loss: 7.0272\n",
      "Epoch 300/500, Loss: 5.1991\n",
      "Early stopping at epoch 366\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 11.9012\n",
      "Epoch 200/500, Loss: 7.4567\n",
      "Epoch 300/500, Loss: 5.6957\n",
      "Early stopping at epoch 311\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 11.2850\n",
      "Epoch 200/500, Loss: 6.9981\n",
      "Epoch 300/500, Loss: 5.3957\n",
      "Epoch 400/500, Loss: 4.5433\n",
      "Epoch 500/500, Loss: 4.0012\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 13.9404\n",
      "Early stopping at epoch 114\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 14.1712\n",
      "Epoch 200/500, Loss: 10.5457\n",
      "Epoch 300/500, Loss: 7.8453\n",
      "Epoch 400/500, Loss: 6.2261\n",
      "Epoch 500/500, Loss: 5.4205\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 14.7215\n",
      "Early stopping at epoch 116\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 7.8590\n",
      "Epoch 200/1000, Loss: 5.1680\n",
      "Epoch 300/1000, Loss: 4.2503\n",
      "Epoch 400/1000, Loss: 3.6284\n",
      "Early stopping at epoch 414\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 7.9310\n",
      "Epoch 200/1000, Loss: 5.1874\n",
      "Early stopping at epoch 220\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 7.8701\n",
      "Epoch 200/1000, Loss: 5.1226\n",
      "Early stopping at epoch 277\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 77\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 11.5147\n",
      "Epoch 200/1000, Loss: 7.1758\n",
      "Epoch 300/1000, Loss: 5.5471\n",
      "Epoch 400/1000, Loss: 4.7332\n",
      "Epoch 500/1000, Loss: 4.1664\n",
      "Epoch 600/1000, Loss: 3.7397\n",
      "Epoch 700/1000, Loss: 3.3957\n",
      "Early stopping at epoch 766\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 11.2029\n",
      "Epoch 200/1000, Loss: 7.0546\n",
      "Early stopping at epoch 230\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 14.2081\n",
      "Early stopping at epoch 134\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 14.5675\n",
      "Epoch 200/1000, Loss: 10.6191\n",
      "Epoch 300/1000, Loss: 8.1243\n",
      "Epoch 400/1000, Loss: 6.6837\n",
      "Epoch 500/1000, Loss: 5.8505\n",
      "Epoch 600/1000, Loss: 5.3139\n",
      "Epoch 700/1000, Loss: 4.9299\n",
      "Epoch 800/1000, Loss: 4.6268\n",
      "Epoch 900/1000, Loss: 4.3667\n",
      "Epoch 1000/1000, Loss: 4.1294\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 14.1314\n",
      "Epoch 200/1000, Loss: 10.4416\n",
      "Epoch 300/1000, Loss: 8.0114\n",
      "Epoch 400/1000, Loss: 6.4155\n",
      "Epoch 500/1000, Loss: 5.5291\n",
      "Epoch 600/1000, Loss: 4.9912\n",
      "Epoch 700/1000, Loss: 4.5982\n",
      "Epoch 800/1000, Loss: 4.2786\n",
      "Epoch 900/1000, Loss: 4.0031\n",
      "Epoch 1000/1000, Loss: 3.7549\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 70\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 75\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 42.3211\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 48.7320\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 47.5899\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 54.6849\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 253.6028\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 257.6019\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 195.9279\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 63\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 43.6759\n",
      "Epoch 200/500, Loss: 35.7772\n",
      "Epoch 300/500, Loss: 30.0427\n",
      "Epoch 400/500, Loss: 24.6846\n",
      "Epoch 500/500, Loss: 20.1455\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 41.4924\n",
      "Epoch 200/500, Loss: 33.0394\n",
      "Epoch 300/500, Loss: 25.8217\n",
      "Epoch 400/500, Loss: 20.2229\n",
      "Epoch 500/500, Loss: 16.2843\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 53.3753\n",
      "Epoch 200/500, Loss: 41.4392\n",
      "Epoch 300/500, Loss: 36.7604\n",
      "Epoch 400/500, Loss: 32.8998\n",
      "Epoch 500/500, Loss: 29.3443\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 48.6769\n",
      "Epoch 200/500, Loss: 41.0013\n",
      "Epoch 300/500, Loss: 36.7704\n",
      "Epoch 400/500, Loss: 32.7607\n",
      "Epoch 500/500, Loss: 29.0004\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 50.6778\n",
      "Epoch 200/500, Loss: 40.9116\n",
      "Epoch 300/500, Loss: 36.7300\n",
      "Epoch 400/500, Loss: 33.0895\n",
      "Epoch 500/500, Loss: 29.7103\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 292.8032\n",
      "Epoch 200/500, Loss: 56.9316\n",
      "Epoch 300/500, Loss: 45.4609\n",
      "Epoch 400/500, Loss: 42.1337\n",
      "Epoch 500/500, Loss: 39.5958\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 231.1108\n",
      "Epoch 200/500, Loss: 49.8721\n",
      "Epoch 300/500, Loss: 44.3772\n",
      "Epoch 400/500, Loss: 41.7351\n",
      "Epoch 500/500, Loss: 39.7592\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 210.1489\n",
      "Epoch 200/500, Loss: 51.2235\n",
      "Epoch 300/500, Loss: 45.4170\n",
      "Epoch 400/500, Loss: 42.4019\n",
      "Epoch 500/500, Loss: 39.9873\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 40.4352\n",
      "Epoch 200/1000, Loss: 31.3345\n",
      "Epoch 300/1000, Loss: 24.8787\n",
      "Epoch 400/1000, Loss: 20.1130\n",
      "Epoch 500/1000, Loss: 16.4871\n",
      "Epoch 600/1000, Loss: 13.6540\n",
      "Epoch 700/1000, Loss: 11.5094\n",
      "Epoch 800/1000, Loss: 9.9361\n",
      "Epoch 900/1000, Loss: 8.7570\n",
      "Epoch 1000/1000, Loss: 7.8388\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 40.3032\n",
      "Epoch 200/1000, Loss: 31.9341\n",
      "Epoch 300/1000, Loss: 25.8188\n",
      "Epoch 400/1000, Loss: 21.0475\n",
      "Epoch 500/1000, Loss: 17.4147\n",
      "Epoch 600/1000, Loss: 14.5941\n",
      "Epoch 700/1000, Loss: 12.3401\n",
      "Early stopping at epoch 780\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 45.0823\n",
      "Epoch 200/1000, Loss: 37.2435\n",
      "Epoch 300/1000, Loss: 30.7079\n",
      "Epoch 400/1000, Loss: 24.6961\n",
      "Epoch 500/1000, Loss: 19.7784\n",
      "Epoch 600/1000, Loss: 15.9326\n",
      "Epoch 700/1000, Loss: 12.9692\n",
      "Epoch 800/1000, Loss: 10.7613\n",
      "Epoch 900/1000, Loss: 9.1522\n",
      "Epoch 1000/1000, Loss: 7.9432\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 55.0860\n",
      "Epoch 200/1000, Loss: 43.0657\n",
      "Epoch 300/1000, Loss: 37.8824\n",
      "Epoch 400/1000, Loss: 33.7522\n",
      "Epoch 500/1000, Loss: 30.0785\n",
      "Epoch 600/1000, Loss: 26.7732\n",
      "Epoch 700/1000, Loss: 23.8395\n",
      "Epoch 800/1000, Loss: 21.2700\n",
      "Epoch 900/1000, Loss: 19.0445\n",
      "Epoch 1000/1000, Loss: 17.1225\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 50.9372\n",
      "Early stopping at epoch 139\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 50.5151\n",
      "Epoch 200/1000, Loss: 41.0516\n",
      "Epoch 300/1000, Loss: 36.9144\n",
      "Epoch 400/1000, Loss: 33.2310\n",
      "Epoch 500/1000, Loss: 29.8991\n",
      "Epoch 600/1000, Loss: 26.9153\n",
      "Epoch 700/1000, Loss: 24.2623\n",
      "Epoch 800/1000, Loss: 21.9131\n",
      "Epoch 900/1000, Loss: 19.8530\n",
      "Epoch 1000/1000, Loss: 18.0665\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 244.0850\n",
      "Epoch 200/1000, Loss: 49.4618\n",
      "Epoch 300/1000, Loss: 43.9735\n",
      "Epoch 400/1000, Loss: 41.6105\n",
      "Epoch 500/1000, Loss: 39.4879\n",
      "Epoch 600/1000, Loss: 37.4557\n",
      "Epoch 700/1000, Loss: 35.4861\n",
      "Epoch 800/1000, Loss: 33.5797\n",
      "Epoch 900/1000, Loss: 31.7292\n",
      "Epoch 1000/1000, Loss: 29.9435\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 228.0012\n",
      "Epoch 200/1000, Loss: 48.9544\n",
      "Epoch 300/1000, Loss: 43.9802\n",
      "Epoch 400/1000, Loss: 41.5119\n",
      "Epoch 500/1000, Loss: 39.2337\n",
      "Epoch 600/1000, Loss: 37.0081\n",
      "Epoch 700/1000, Loss: 34.8680\n",
      "Epoch 800/1000, Loss: 32.8176\n",
      "Epoch 900/1000, Loss: 30.8185\n",
      "Epoch 1000/1000, Loss: 28.8687\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 189.4788\n",
      "Epoch 200/1000, Loss: 48.8100\n",
      "Epoch 300/1000, Loss: 43.5556\n",
      "Epoch 400/1000, Loss: 40.4816\n",
      "Epoch 500/1000, Loss: 37.8287\n",
      "Epoch 600/1000, Loss: 35.4403\n",
      "Epoch 700/1000, Loss: 33.2915\n",
      "Epoch 800/1000, Loss: 31.3357\n",
      "Epoch 900/1000, Loss: 29.5164\n",
      "Epoch 1000/1000, Loss: 27.8088\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 8.1047\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 12\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 9.2541\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 17.5450\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 17.5781\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 17.0583\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 28.5575\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 29.8226\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 27.3847\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 8.8574\n",
      "Epoch 200/500, Loss: 3.9062\n",
      "Epoch 300/500, Loss: 2.6092\n",
      "Epoch 400/500, Loss: 2.0232\n",
      "Early stopping at epoch 433\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 68\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 8.5073\n",
      "Epoch 200/500, Loss: 4.0807\n",
      "Epoch 300/500, Loss: 2.7977\n",
      "Epoch 400/500, Loss: 2.1317\n",
      "Epoch 500/500, Loss: 1.7135\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 18.6797\n",
      "Early stopping at epoch 159\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 16.1604\n",
      "Epoch 200/500, Loss: 7.6639\n",
      "Epoch 300/500, Loss: 4.8573\n",
      "Epoch 400/500, Loss: 3.5779\n",
      "Epoch 500/500, Loss: 2.8773\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 18.5976\n",
      "Epoch 200/500, Loss: 8.3934\n",
      "Early stopping at epoch 213\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 25.8498\n",
      "Epoch 200/500, Loss: 14.6148\n",
      "Epoch 300/500, Loss: 9.3359\n",
      "Early stopping at epoch 300\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 27.8646\n",
      "Epoch 200/500, Loss: 15.2525\n",
      "Early stopping at epoch 250\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 39\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 9.9684\n",
      "Epoch 200/1000, Loss: 3.9080\n",
      "Epoch 300/1000, Loss: 2.3077\n",
      "Epoch 400/1000, Loss: 1.6268\n",
      "Epoch 500/1000, Loss: 1.2272\n",
      "Epoch 600/1000, Loss: 0.9614\n",
      "Epoch 700/1000, Loss: 0.7777\n",
      "Epoch 800/1000, Loss: 0.6500\n",
      "Epoch 900/1000, Loss: 0.5585\n",
      "Epoch 1000/1000, Loss: 0.4889\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 69\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 8.6600\n",
      "Epoch 200/1000, Loss: 4.0946\n",
      "Epoch 300/1000, Loss: 2.8079\n",
      "Epoch 400/1000, Loss: 2.1547\n",
      "Epoch 500/1000, Loss: 1.7435\n",
      "Epoch 600/1000, Loss: 1.4412\n",
      "Epoch 700/1000, Loss: 1.2082\n",
      "Epoch 800/1000, Loss: 1.0236\n",
      "Early stopping at epoch 824\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 17.5772\n",
      "Epoch 200/1000, Loss: 8.2310\n",
      "Epoch 300/1000, Loss: 4.8888\n",
      "Epoch 400/1000, Loss: 3.5318\n",
      "Epoch 500/1000, Loss: 2.8466\n",
      "Epoch 600/1000, Loss: 2.4080\n",
      "Epoch 700/1000, Loss: 2.0846\n",
      "Epoch 800/1000, Loss: 1.8315\n",
      "Early stopping at epoch 839\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 18.1958\n",
      "Epoch 200/1000, Loss: 8.7590\n",
      "Epoch 300/1000, Loss: 5.3194\n",
      "Epoch 400/1000, Loss: 4.0109\n",
      "Epoch 500/1000, Loss: 3.2838\n",
      "Epoch 600/1000, Loss: 2.7824\n",
      "Epoch 700/1000, Loss: 2.3962\n",
      "Epoch 800/1000, Loss: 2.0920\n",
      "Epoch 900/1000, Loss: 1.8523\n",
      "Epoch 1000/1000, Loss: 1.6610\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 27.2395\n",
      "Epoch 200/1000, Loss: 14.9139\n",
      "Epoch 300/1000, Loss: 9.2249\n",
      "Epoch 400/1000, Loss: 6.3970\n",
      "Epoch 500/1000, Loss: 4.9194\n",
      "Epoch 600/1000, Loss: 4.0593\n",
      "Epoch 700/1000, Loss: 3.5167\n",
      "Epoch 800/1000, Loss: 3.1439\n",
      "Epoch 900/1000, Loss: 2.8669\n",
      "Epoch 1000/1000, Loss: 2.6442\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 30.2069\n",
      "Epoch 200/1000, Loss: 16.3023\n",
      "Epoch 300/1000, Loss: 10.2877\n",
      "Epoch 400/1000, Loss: 7.3244\n",
      "Epoch 500/1000, Loss: 5.8137\n",
      "Epoch 600/1000, Loss: 4.8742\n",
      "Epoch 700/1000, Loss: 4.2389\n",
      "Epoch 800/1000, Loss: 3.7684\n",
      "Epoch 900/1000, Loss: 3.3921\n",
      "Epoch 1000/1000, Loss: 3.0861\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 28.2022\n",
      "Epoch 200/1000, Loss: 16.8900\n",
      "Epoch 300/1000, Loss: 10.9293\n",
      "Epoch 400/1000, Loss: 7.5674\n",
      "Epoch 500/1000, Loss: 5.6408\n",
      "Epoch 600/1000, Loss: 4.5012\n",
      "Epoch 700/1000, Loss: 3.7868\n",
      "Epoch 800/1000, Loss: 3.3028\n",
      "Epoch 900/1000, Loss: 2.9479\n",
      "Epoch 1000/1000, Loss: 2.6711\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 17\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 22\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 9\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 32\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 35\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 30\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 9\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 29\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 30\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 32\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 26\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 53\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 11\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 26\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 56\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 26\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 13\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 17.4603\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 17.0942\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 16.0163\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 21.0364\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 19.7581\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 24.0447\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 31.9564\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 26.7340\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 27.2963\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 16.0967\n",
      "Epoch 200/500, Loss: 12.6799\n",
      "Epoch 300/500, Loss: 10.8232\n",
      "Epoch 400/500, Loss: 9.4987\n",
      "Early stopping at epoch 494\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 16.2534\n",
      "Epoch 200/500, Loss: 12.5333\n",
      "Epoch 300/500, Loss: 10.4054\n",
      "Epoch 400/500, Loss: 8.9390\n",
      "Epoch 500/500, Loss: 7.8016\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 17.7793\n",
      "Epoch 200/500, Loss: 13.8231\n",
      "Epoch 300/500, Loss: 11.6037\n",
      "Epoch 400/500, Loss: 10.0113\n",
      "Early stopping at epoch 471\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 20.4015\n",
      "Epoch 200/500, Loss: 16.1982\n",
      "Epoch 300/500, Loss: 14.1207\n",
      "Epoch 400/500, Loss: 12.7086\n",
      "Epoch 500/500, Loss: 11.6448\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 19.9372\n",
      "Epoch 200/500, Loss: 16.2128\n",
      "Epoch 300/500, Loss: 14.1747\n",
      "Epoch 400/500, Loss: 12.7746\n",
      "Epoch 500/500, Loss: 11.7078\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 19.9799\n",
      "Epoch 200/500, Loss: 16.0783\n",
      "Epoch 300/500, Loss: 14.0267\n",
      "Epoch 400/500, Loss: 12.6208\n",
      "Epoch 500/500, Loss: 11.5776\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 26.9367\n",
      "Epoch 200/500, Loss: 20.4401\n",
      "Epoch 300/500, Loss: 18.0075\n",
      "Epoch 400/500, Loss: 16.4403\n",
      "Epoch 500/500, Loss: 15.3366\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 29.3294\n",
      "Epoch 200/500, Loss: 19.5479\n",
      "Epoch 300/500, Loss: 16.7065\n",
      "Epoch 400/500, Loss: 15.1526\n",
      "Epoch 500/500, Loss: 14.0734\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 28.7586\n",
      "Epoch 200/500, Loss: 20.3783\n",
      "Epoch 300/500, Loss: 18.1723\n",
      "Epoch 400/500, Loss: 16.8230\n",
      "Epoch 500/500, Loss: 15.7661\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 18.3766\n",
      "Epoch 200/1000, Loss: 13.4674\n",
      "Epoch 300/1000, Loss: 10.8231\n",
      "Epoch 400/1000, Loss: 9.0880\n",
      "Epoch 500/1000, Loss: 7.9175\n",
      "Epoch 600/1000, Loss: 7.0830\n",
      "Epoch 700/1000, Loss: 6.4155\n",
      "Epoch 800/1000, Loss: 5.8836\n",
      "Epoch 900/1000, Loss: 5.4143\n",
      "Early stopping at epoch 972\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 16.0641\n",
      "Epoch 200/1000, Loss: 12.7935\n",
      "Epoch 300/1000, Loss: 11.0122\n",
      "Epoch 400/1000, Loss: 9.7128\n",
      "Early stopping at epoch 490\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 17.9541\n",
      "Epoch 200/1000, Loss: 13.8760\n",
      "Epoch 300/1000, Loss: 11.6367\n",
      "Epoch 400/1000, Loss: 10.0861\n",
      "Epoch 500/1000, Loss: 8.8984\n",
      "Epoch 600/1000, Loss: 7.9635\n",
      "Early stopping at epoch 644\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 21.8771\n",
      "Epoch 200/1000, Loss: 17.2087\n",
      "Epoch 300/1000, Loss: 14.9773\n",
      "Epoch 400/1000, Loss: 13.4279\n",
      "Epoch 500/1000, Loss: 12.2030\n",
      "Epoch 600/1000, Loss: 11.1633\n",
      "Epoch 700/1000, Loss: 10.2722\n",
      "Epoch 800/1000, Loss: 9.4964\n",
      "Epoch 900/1000, Loss: 8.8323\n",
      "Early stopping at epoch 969\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 20.0004\n",
      "Epoch 200/1000, Loss: 15.9873\n",
      "Epoch 300/1000, Loss: 13.9989\n",
      "Epoch 400/1000, Loss: 12.5733\n",
      "Epoch 500/1000, Loss: 11.4808\n",
      "Epoch 600/1000, Loss: 10.5852\n",
      "Epoch 700/1000, Loss: 9.8583\n",
      "Epoch 800/1000, Loss: 9.2296\n",
      "Early stopping at epoch 803\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 21.9288\n",
      "Epoch 200/1000, Loss: 16.4072\n",
      "Epoch 300/1000, Loss: 14.0195\n",
      "Epoch 400/1000, Loss: 12.4985\n",
      "Epoch 500/1000, Loss: 11.3621\n",
      "Epoch 600/1000, Loss: 10.4669\n",
      "Epoch 700/1000, Loss: 9.7290\n",
      "Epoch 800/1000, Loss: 9.0996\n",
      "Epoch 900/1000, Loss: 8.5506\n",
      "Epoch 1000/1000, Loss: 8.0650\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 29.3519\n",
      "Epoch 200/1000, Loss: 22.5177\n",
      "Epoch 300/1000, Loss: 19.0623\n",
      "Epoch 400/1000, Loss: 16.8285\n",
      "Epoch 500/1000, Loss: 15.2850\n",
      "Epoch 600/1000, Loss: 14.1290\n",
      "Epoch 700/1000, Loss: 13.1989\n",
      "Epoch 800/1000, Loss: 12.4283\n",
      "Epoch 900/1000, Loss: 11.7739\n",
      "Epoch 1000/1000, Loss: 11.1787\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 31.0753\n",
      "Epoch 200/1000, Loss: 20.8933\n",
      "Epoch 300/1000, Loss: 17.9005\n",
      "Epoch 400/1000, Loss: 16.2012\n",
      "Epoch 500/1000, Loss: 15.0241\n",
      "Epoch 600/1000, Loss: 14.1369\n",
      "Epoch 700/1000, Loss: 13.4121\n",
      "Epoch 800/1000, Loss: 12.7882\n",
      "Epoch 900/1000, Loss: 12.2456\n",
      "Epoch 1000/1000, Loss: 11.7610\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 27.8444\n",
      "Epoch 200/1000, Loss: 20.7509\n",
      "Epoch 300/1000, Loss: 18.1737\n",
      "Epoch 400/1000, Loss: 16.5541\n",
      "Epoch 500/1000, Loss: 15.3061\n",
      "Epoch 600/1000, Loss: 14.3401\n",
      "Epoch 700/1000, Loss: 13.5513\n",
      "Epoch 800/1000, Loss: 12.8639\n",
      "Epoch 900/1000, Loss: 12.2554\n",
      "Epoch 1000/1000, Loss: 11.6894\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 5.8387\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 91\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 91\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 8.8690\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 8.9260\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 8.4331\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 11.0175\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 10.9833\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 11.2570\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 5.5532\n",
      "Early stopping at epoch 121\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 77\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 6.4018\n",
      "Early stopping at epoch 152\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 9.7883\n",
      "Early stopping at epoch 153\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 81\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 8.7881\n",
      "Epoch 200/500, Loss: 5.6161\n",
      "Early stopping at epoch 208\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 11.0171\n",
      "Epoch 200/500, Loss: 8.0471\n",
      "Early stopping at epoch 266\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 11.3750\n",
      "Epoch 200/500, Loss: 7.8652\n",
      "Early stopping at epoch 237\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 11.6606\n",
      "Epoch 200/500, Loss: 8.5481\n",
      "Epoch 300/500, Loss: 6.7439\n",
      "Early stopping at epoch 305\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 64\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 66\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 94\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 9.2224\n",
      "Early stopping at epoch 177\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 8.6831\n",
      "Early stopping at epoch 140\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 7.7461\n",
      "Early stopping at epoch 147\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 12.2685\n",
      "Epoch 200/1000, Loss: 8.4348\n",
      "Early stopping at epoch 269\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 11.3286\n",
      "Epoch 200/1000, Loss: 7.8433\n",
      "Epoch 300/1000, Loss: 5.9525\n",
      "Early stopping at epoch 303\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 10.9944\n",
      "Epoch 200/1000, Loss: 7.9169\n",
      "Early stopping at epoch 226\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 20\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 26\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 10\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 20\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 25\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 21\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 11\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 9\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 34\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 34\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 33\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 13\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 20\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 10\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 15\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 6\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 17\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 17\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 34\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 43\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 5\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 40\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 11\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [128, 64], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 55.3336\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 58.2966\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 58.5486\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 69.9120\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 70.3128\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 70.0603\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 77.7049\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 78.7298\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 81.6690\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 58.2751\n",
      "Epoch 200/500, Loss: 40.8716\n",
      "Epoch 300/500, Loss: 31.7755\n",
      "Epoch 400/500, Loss: 26.9379\n",
      "Epoch 500/500, Loss: 24.5563\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 56.6029\n",
      "Epoch 200/500, Loss: 40.0793\n",
      "Epoch 300/500, Loss: 31.1320\n",
      "Epoch 400/500, Loss: 26.3213\n",
      "Epoch 500/500, Loss: 23.9112\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 55.4766\n",
      "Epoch 200/500, Loss: 37.9705\n",
      "Epoch 300/500, Loss: 29.7030\n",
      "Epoch 400/500, Loss: 25.6421\n",
      "Epoch 500/500, Loss: 23.6687\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 69.5419\n",
      "Epoch 200/500, Loss: 53.9657\n",
      "Epoch 300/500, Loss: 44.2464\n",
      "Epoch 400/500, Loss: 37.9585\n",
      "Epoch 500/500, Loss: 33.3239\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 71.2702\n",
      "Epoch 200/500, Loss: 55.2375\n",
      "Epoch 300/500, Loss: 45.9778\n",
      "Epoch 400/500, Loss: 40.2541\n",
      "Epoch 500/500, Loss: 35.7818\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 69.8407\n",
      "Epoch 200/500, Loss: 53.7172\n",
      "Epoch 300/500, Loss: 44.8319\n",
      "Epoch 400/500, Loss: 39.5784\n",
      "Epoch 500/500, Loss: 35.5122\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 79.2837\n",
      "Epoch 200/500, Loss: 70.5554\n",
      "Epoch 300/500, Loss: 62.1231\n",
      "Epoch 400/500, Loss: 54.5419\n",
      "Epoch 500/500, Loss: 48.3938\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 78.0124\n",
      "Epoch 200/500, Loss: 67.9809\n",
      "Epoch 300/500, Loss: 59.3552\n",
      "Epoch 400/500, Loss: 52.7488\n",
      "Epoch 500/500, Loss: 47.9004\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 77.0579\n",
      "Epoch 200/500, Loss: 66.8609\n",
      "Epoch 300/500, Loss: 58.0410\n",
      "Epoch 400/500, Loss: 50.9392\n",
      "Epoch 500/500, Loss: 45.5923\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 53.6800\n",
      "Epoch 200/1000, Loss: 37.0459\n",
      "Epoch 300/1000, Loss: 29.6135\n",
      "Epoch 400/1000, Loss: 25.7909\n",
      "Epoch 500/1000, Loss: 23.8042\n",
      "Epoch 600/1000, Loss: 22.5551\n",
      "Epoch 700/1000, Loss: 21.6227\n",
      "Epoch 800/1000, Loss: 20.8593\n",
      "Epoch 900/1000, Loss: 20.2027\n",
      "Epoch 1000/1000, Loss: 19.6209\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 54.3998\n",
      "Epoch 200/1000, Loss: 38.5013\n",
      "Epoch 300/1000, Loss: 30.1878\n",
      "Epoch 400/1000, Loss: 25.7734\n",
      "Epoch 500/1000, Loss: 23.6180\n",
      "Epoch 600/1000, Loss: 22.3584\n",
      "Epoch 700/1000, Loss: 21.4468\n",
      "Epoch 800/1000, Loss: 20.7048\n",
      "Epoch 900/1000, Loss: 20.0643\n",
      "Epoch 1000/1000, Loss: 19.4925\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 55.7251\n",
      "Epoch 200/1000, Loss: 38.3508\n",
      "Epoch 300/1000, Loss: 30.0928\n",
      "Epoch 400/1000, Loss: 25.9717\n",
      "Epoch 500/1000, Loss: 23.9415\n",
      "Epoch 600/1000, Loss: 22.7114\n",
      "Epoch 700/1000, Loss: 21.7987\n",
      "Epoch 800/1000, Loss: 21.0466\n",
      "Epoch 900/1000, Loss: 20.3936\n",
      "Epoch 1000/1000, Loss: 19.8095\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 68.3206\n",
      "Epoch 200/1000, Loss: 50.6261\n",
      "Epoch 300/1000, Loss: 41.6053\n",
      "Epoch 400/1000, Loss: 36.1012\n",
      "Epoch 500/1000, Loss: 31.9931\n",
      "Epoch 600/1000, Loss: 28.9000\n",
      "Epoch 700/1000, Loss: 26.6682\n",
      "Epoch 800/1000, Loss: 25.0931\n",
      "Epoch 900/1000, Loss: 23.9655\n",
      "Epoch 1000/1000, Loss: 23.1219\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 69.0999\n",
      "Epoch 200/1000, Loss: 54.3271\n",
      "Epoch 300/1000, Loss: 45.3464\n",
      "Epoch 400/1000, Loss: 39.1133\n",
      "Epoch 500/1000, Loss: 34.2112\n",
      "Epoch 600/1000, Loss: 30.4822\n",
      "Epoch 700/1000, Loss: 27.8332\n",
      "Epoch 800/1000, Loss: 26.0231\n",
      "Epoch 900/1000, Loss: 24.7786\n",
      "Epoch 1000/1000, Loss: 23.8843\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 71.7553\n",
      "Epoch 200/1000, Loss: 56.4444\n",
      "Epoch 300/1000, Loss: 46.6006\n",
      "Epoch 400/1000, Loss: 40.1391\n",
      "Epoch 500/1000, Loss: 35.1382\n",
      "Epoch 600/1000, Loss: 31.1935\n",
      "Epoch 700/1000, Loss: 28.2587\n",
      "Epoch 800/1000, Loss: 26.1908\n",
      "Epoch 900/1000, Loss: 24.7619\n",
      "Epoch 1000/1000, Loss: 23.7538\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 80.7711\n",
      "Epoch 200/1000, Loss: 71.5863\n",
      "Epoch 300/1000, Loss: 63.0182\n",
      "Epoch 400/1000, Loss: 55.4972\n",
      "Epoch 500/1000, Loss: 49.4194\n",
      "Epoch 600/1000, Loss: 44.6612\n",
      "Epoch 700/1000, Loss: 40.8595\n",
      "Epoch 800/1000, Loss: 37.7146\n",
      "Epoch 900/1000, Loss: 35.0557\n",
      "Epoch 1000/1000, Loss: 32.8002\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 77.7027\n",
      "Epoch 200/1000, Loss: 68.6494\n",
      "Epoch 300/1000, Loss: 60.6287\n",
      "Epoch 400/1000, Loss: 54.1473\n",
      "Epoch 500/1000, Loss: 49.1525\n",
      "Epoch 600/1000, Loss: 45.0980\n",
      "Epoch 700/1000, Loss: 41.6196\n",
      "Epoch 800/1000, Loss: 38.5449\n",
      "Epoch 900/1000, Loss: 35.8184\n",
      "Epoch 1000/1000, Loss: 33.4333\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 78.7987\n",
      "Epoch 200/1000, Loss: 69.0448\n",
      "Epoch 300/1000, Loss: 60.3796\n",
      "Epoch 400/1000, Loss: 53.2852\n",
      "Epoch 500/1000, Loss: 47.9686\n",
      "Epoch 600/1000, Loss: 43.9800\n",
      "Epoch 700/1000, Loss: 40.8027\n",
      "Epoch 800/1000, Loss: 38.1092\n",
      "Epoch 900/1000, Loss: 35.7412\n",
      "Epoch 1000/1000, Loss: 33.6384\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 19.6357\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 19.7074\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 19.4262\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 24.0025\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 23.9411\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 23.6169\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 32.3759\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 33.1810\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 31.5210\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 19.4249\n",
      "Epoch 200/500, Loss: 15.6546\n",
      "Epoch 300/500, Loss: 13.3784\n",
      "Epoch 400/500, Loss: 11.7299\n",
      "Epoch 500/500, Loss: 10.3443\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 19.7566\n",
      "Epoch 200/500, Loss: 15.7479\n",
      "Epoch 300/500, Loss: 13.4120\n",
      "Epoch 400/500, Loss: 11.7303\n",
      "Epoch 500/500, Loss: 10.3145\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 19.7233\n",
      "Epoch 200/500, Loss: 15.9660\n",
      "Epoch 300/500, Loss: 13.8084\n",
      "Epoch 400/500, Loss: 12.2447\n",
      "Epoch 500/500, Loss: 10.8496\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 23.2589\n",
      "Epoch 200/500, Loss: 19.3687\n",
      "Epoch 300/500, Loss: 17.3488\n",
      "Epoch 400/500, Loss: 15.9101\n",
      "Epoch 500/500, Loss: 14.8050\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 23.7968\n",
      "Epoch 200/500, Loss: 19.5372\n",
      "Epoch 300/500, Loss: 17.3629\n",
      "Epoch 400/500, Loss: 15.7993\n",
      "Epoch 500/500, Loss: 14.5918\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 23.6256\n",
      "Epoch 200/500, Loss: 19.6563\n",
      "Epoch 300/500, Loss: 17.4338\n",
      "Epoch 400/500, Loss: 15.8628\n",
      "Epoch 500/500, Loss: 14.7061\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 33.6860\n",
      "Epoch 200/500, Loss: 23.1769\n",
      "Epoch 300/500, Loss: 20.6292\n",
      "Epoch 400/500, Loss: 19.0591\n",
      "Epoch 500/500, Loss: 17.8499\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 31.2024\n",
      "Epoch 200/500, Loss: 23.4246\n",
      "Epoch 300/500, Loss: 21.0712\n",
      "Epoch 400/500, Loss: 19.4858\n",
      "Epoch 500/500, Loss: 18.2218\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 32.9854\n",
      "Epoch 200/500, Loss: 23.3742\n",
      "Epoch 300/500, Loss: 20.6849\n",
      "Epoch 400/500, Loss: 18.9374\n",
      "Epoch 500/500, Loss: 17.5956\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 19.6849\n",
      "Epoch 200/1000, Loss: 15.8139\n",
      "Epoch 300/1000, Loss: 13.7957\n",
      "Epoch 400/1000, Loss: 12.3948\n",
      "Epoch 500/1000, Loss: 11.1706\n",
      "Epoch 600/1000, Loss: 10.0026\n",
      "Epoch 700/1000, Loss: 8.9307\n",
      "Epoch 800/1000, Loss: 8.0184\n",
      "Epoch 900/1000, Loss: 7.2933\n",
      "Epoch 1000/1000, Loss: 6.7305\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 19.6975\n",
      "Epoch 200/1000, Loss: 15.9293\n",
      "Epoch 300/1000, Loss: 13.7462\n",
      "Epoch 400/1000, Loss: 12.2301\n",
      "Epoch 500/1000, Loss: 10.9343\n",
      "Epoch 600/1000, Loss: 9.7234\n",
      "Epoch 700/1000, Loss: 8.6478\n",
      "Epoch 800/1000, Loss: 7.7651\n",
      "Epoch 900/1000, Loss: 7.0735\n",
      "Epoch 1000/1000, Loss: 6.5423\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 19.8281\n",
      "Epoch 200/1000, Loss: 16.0632\n",
      "Epoch 300/1000, Loss: 13.9381\n",
      "Epoch 400/1000, Loss: 12.4754\n",
      "Epoch 500/1000, Loss: 11.2416\n",
      "Epoch 600/1000, Loss: 10.0630\n",
      "Epoch 700/1000, Loss: 8.9608\n",
      "Epoch 800/1000, Loss: 8.0207\n",
      "Epoch 900/1000, Loss: 7.2794\n",
      "Epoch 1000/1000, Loss: 6.7176\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 23.0331\n",
      "Epoch 200/1000, Loss: 18.7892\n",
      "Epoch 300/1000, Loss: 16.6297\n",
      "Epoch 400/1000, Loss: 15.2032\n",
      "Epoch 500/1000, Loss: 14.1594\n",
      "Epoch 600/1000, Loss: 13.3294\n",
      "Epoch 700/1000, Loss: 12.6240\n",
      "Epoch 800/1000, Loss: 11.9856\n",
      "Epoch 900/1000, Loss: 11.3737\n",
      "Epoch 1000/1000, Loss: 10.7664\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 23.0004\n",
      "Epoch 200/1000, Loss: 19.4286\n",
      "Epoch 300/1000, Loss: 17.3734\n",
      "Epoch 400/1000, Loss: 15.8923\n",
      "Epoch 500/1000, Loss: 14.7756\n",
      "Epoch 600/1000, Loss: 13.8935\n",
      "Epoch 700/1000, Loss: 13.1568\n",
      "Epoch 800/1000, Loss: 12.5039\n",
      "Epoch 900/1000, Loss: 11.8895\n",
      "Epoch 1000/1000, Loss: 11.2834\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 23.5613\n",
      "Epoch 200/1000, Loss: 19.3696\n",
      "Epoch 300/1000, Loss: 17.1556\n",
      "Epoch 400/1000, Loss: 15.6057\n",
      "Epoch 500/1000, Loss: 14.4560\n",
      "Epoch 600/1000, Loss: 13.5468\n",
      "Epoch 700/1000, Loss: 12.7763\n",
      "Epoch 800/1000, Loss: 12.0784\n",
      "Epoch 900/1000, Loss: 11.4146\n",
      "Epoch 1000/1000, Loss: 10.7707\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 31.4303\n",
      "Epoch 200/1000, Loss: 23.2948\n",
      "Epoch 300/1000, Loss: 20.8140\n",
      "Epoch 400/1000, Loss: 19.1486\n",
      "Epoch 500/1000, Loss: 17.8626\n",
      "Epoch 600/1000, Loss: 16.8208\n",
      "Epoch 700/1000, Loss: 15.9554\n",
      "Epoch 800/1000, Loss: 15.2230\n",
      "Epoch 900/1000, Loss: 14.5922\n",
      "Epoch 1000/1000, Loss: 14.0387\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 35.3066\n",
      "Epoch 200/1000, Loss: 24.2209\n",
      "Epoch 300/1000, Loss: 21.3095\n",
      "Epoch 400/1000, Loss: 19.5635\n",
      "Epoch 500/1000, Loss: 18.2703\n",
      "Epoch 600/1000, Loss: 17.2406\n",
      "Epoch 700/1000, Loss: 16.3896\n",
      "Epoch 800/1000, Loss: 15.6690\n",
      "Epoch 900/1000, Loss: 15.0466\n",
      "Epoch 1000/1000, Loss: 14.4984\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 33.4380\n",
      "Epoch 200/1000, Loss: 23.0884\n",
      "Epoch 300/1000, Loss: 20.5905\n",
      "Epoch 400/1000, Loss: 18.9756\n",
      "Epoch 500/1000, Loss: 17.6958\n",
      "Epoch 600/1000, Loss: 16.6259\n",
      "Epoch 700/1000, Loss: 15.7136\n",
      "Epoch 800/1000, Loss: 14.9271\n",
      "Epoch 900/1000, Loss: 14.2427\n",
      "Epoch 1000/1000, Loss: 13.6399\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 8.1419\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 32\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 8.2842\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 11.9952\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 11.4225\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 11.5121\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 14.2516\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 14.2965\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 14.2526\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 8.5013\n",
      "Epoch 200/500, Loss: 5.4487\n",
      "Early stopping at epoch 238\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 8.7988\n",
      "Early stopping at epoch 195\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 8.1672\n",
      "Epoch 200/500, Loss: 5.4811\n",
      "Epoch 300/500, Loss: 4.4386\n",
      "Epoch 400/500, Loss: 3.7660\n",
      "Early stopping at epoch 444\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 11.3674\n",
      "Epoch 200/500, Loss: 7.0276\n",
      "Epoch 300/500, Loss: 5.6143\n",
      "Epoch 400/500, Loss: 4.8706\n",
      "Epoch 500/500, Loss: 4.3298\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 11.6238\n",
      "Epoch 200/500, Loss: 7.1752\n",
      "Epoch 300/500, Loss: 5.7127\n",
      "Epoch 400/500, Loss: 4.9022\n",
      "Epoch 500/500, Loss: 4.2988\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 11.1138\n",
      "Epoch 200/500, Loss: 6.8807\n",
      "Epoch 300/500, Loss: 5.4433\n",
      "Early stopping at epoch 341\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 13.9515\n",
      "Epoch 200/500, Loss: 9.9017\n",
      "Epoch 300/500, Loss: 7.3089\n",
      "Epoch 400/500, Loss: 6.0308\n",
      "Epoch 500/500, Loss: 5.3530\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 14.1708\n",
      "Epoch 200/500, Loss: 10.5953\n",
      "Epoch 300/500, Loss: 8.0794\n",
      "Epoch 400/500, Loss: 6.6214\n",
      "Epoch 500/500, Loss: 5.8318\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 14.5639\n",
      "Epoch 200/500, Loss: 10.5529\n",
      "Epoch 300/500, Loss: 7.8062\n",
      "Epoch 400/500, Loss: 6.4032\n",
      "Epoch 500/500, Loss: 5.6556\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 8.4378\n",
      "Epoch 200/1000, Loss: 5.5695\n",
      "Epoch 300/1000, Loss: 4.4933\n",
      "Early stopping at epoch 331\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 8.2192\n",
      "Epoch 200/1000, Loss: 5.4216\n",
      "Epoch 300/1000, Loss: 4.4215\n",
      "Early stopping at epoch 319\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 8.2967\n",
      "Epoch 200/1000, Loss: 5.4944\n",
      "Early stopping at epoch 203\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 11.6769\n",
      "Epoch 200/1000, Loss: 7.1821\n",
      "Early stopping at epoch 266\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 11.2121\n",
      "Epoch 200/1000, Loss: 7.0249\n",
      "Epoch 300/1000, Loss: 5.7265\n",
      "Epoch 400/1000, Loss: 4.9760\n",
      "Epoch 500/1000, Loss: 4.4061\n",
      "Epoch 600/1000, Loss: 3.9497\n",
      "Epoch 700/1000, Loss: 3.5736\n",
      "Epoch 800/1000, Loss: 3.2561\n",
      "Early stopping at epoch 829\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 11.1494\n",
      "Epoch 200/1000, Loss: 7.1321\n",
      "Epoch 300/1000, Loss: 5.6805\n",
      "Epoch 400/1000, Loss: 4.8678\n",
      "Early stopping at epoch 417\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 14.3493\n",
      "Epoch 200/1000, Loss: 10.7401\n",
      "Epoch 300/1000, Loss: 8.2084\n",
      "Epoch 400/1000, Loss: 6.5960\n",
      "Epoch 500/1000, Loss: 5.7596\n",
      "Epoch 600/1000, Loss: 5.2563\n",
      "Epoch 700/1000, Loss: 4.8833\n",
      "Epoch 800/1000, Loss: 4.5698\n",
      "Epoch 900/1000, Loss: 4.2914\n",
      "Epoch 1000/1000, Loss: 4.0392\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 14.2402\n",
      "Epoch 200/1000, Loss: 10.4329\n",
      "Epoch 300/1000, Loss: 7.7503\n",
      "Epoch 400/1000, Loss: 6.3805\n",
      "Epoch 500/1000, Loss: 5.6723\n",
      "Epoch 600/1000, Loss: 5.2128\n",
      "Epoch 700/1000, Loss: 4.8652\n",
      "Epoch 800/1000, Loss: 4.5773\n",
      "Epoch 900/1000, Loss: 4.3245\n",
      "Epoch 1000/1000, Loss: 4.0940\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 14.5121\n",
      "Epoch 200/1000, Loss: 10.2985\n",
      "Epoch 300/1000, Loss: 7.5098\n",
      "Epoch 400/1000, Loss: 6.0943\n",
      "Epoch 500/1000, Loss: 5.4107\n",
      "Early stopping at epoch 572\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 29.4932\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 29.2356\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 28.8599\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 38.1471\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 38.7922\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 40.6917\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 140.5346\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 174.0706\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 140.6289\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 26.7975\n",
      "Epoch 200/500, Loss: 18.2287\n",
      "Epoch 300/500, Loss: 13.7097\n",
      "Epoch 400/500, Loss: 10.7162\n",
      "Epoch 500/500, Loss: 8.6584\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 30.4103\n",
      "Epoch 200/500, Loss: 21.0924\n",
      "Epoch 300/500, Loss: 15.6235\n",
      "Epoch 400/500, Loss: 12.1001\n",
      "Epoch 500/500, Loss: 9.6340\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 27.4273\n",
      "Epoch 200/500, Loss: 17.9161\n",
      "Epoch 300/500, Loss: 13.1016\n",
      "Epoch 400/500, Loss: 10.2018\n",
      "Epoch 500/500, Loss: 8.3087\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 39.3374\n",
      "Epoch 200/500, Loss: 28.4336\n",
      "Epoch 300/500, Loss: 22.9417\n",
      "Epoch 400/500, Loss: 19.0902\n",
      "Epoch 500/500, Loss: 16.2194\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 39.3365\n",
      "Epoch 200/500, Loss: 29.2627\n",
      "Epoch 300/500, Loss: 23.8969\n",
      "Epoch 400/500, Loss: 20.0271\n",
      "Epoch 500/500, Loss: 17.1602\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 40.8434\n",
      "Epoch 200/500, Loss: 29.9450\n",
      "Epoch 300/500, Loss: 24.4372\n",
      "Epoch 400/500, Loss: 20.2528\n",
      "Epoch 500/500, Loss: 16.9967\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 155.6633\n",
      "Epoch 200/500, Loss: 35.7401\n",
      "Epoch 300/500, Loss: 30.1401\n",
      "Epoch 400/500, Loss: 26.6025\n",
      "Epoch 500/500, Loss: 23.8077\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 160.0896\n",
      "Epoch 200/500, Loss: 40.0920\n",
      "Epoch 300/500, Loss: 33.6427\n",
      "Epoch 400/500, Loss: 29.6385\n",
      "Epoch 500/500, Loss: 26.4094\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 161.2117\n",
      "Epoch 200/500, Loss: 37.5701\n",
      "Epoch 300/500, Loss: 31.5990\n",
      "Epoch 400/500, Loss: 27.9788\n",
      "Epoch 500/500, Loss: 25.0030\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 28.1856\n",
      "Epoch 200/1000, Loss: 18.8523\n",
      "Epoch 300/1000, Loss: 13.9196\n",
      "Epoch 400/1000, Loss: 10.7034\n",
      "Epoch 500/1000, Loss: 8.5441\n",
      "Epoch 600/1000, Loss: 7.0772\n",
      "Epoch 700/1000, Loss: 6.0456\n",
      "Epoch 800/1000, Loss: 5.2937\n",
      "Epoch 900/1000, Loss: 4.7292\n",
      "Epoch 1000/1000, Loss: 4.2936\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 28.4590\n",
      "Epoch 200/1000, Loss: 19.9321\n",
      "Epoch 300/1000, Loss: 15.1540\n",
      "Epoch 400/1000, Loss: 11.9156\n",
      "Epoch 500/1000, Loss: 9.5778\n",
      "Epoch 600/1000, Loss: 7.8840\n",
      "Early stopping at epoch 651\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 29.5014\n",
      "Epoch 200/1000, Loss: 19.9411\n",
      "Epoch 300/1000, Loss: 14.7561\n",
      "Epoch 400/1000, Loss: 11.5147\n",
      "Epoch 500/1000, Loss: 9.3052\n",
      "Epoch 600/1000, Loss: 7.7544\n",
      "Epoch 700/1000, Loss: 6.6359\n",
      "Epoch 800/1000, Loss: 5.8025\n",
      "Epoch 900/1000, Loss: 5.1624\n",
      "Epoch 1000/1000, Loss: 4.6584\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 41.2237\n",
      "Epoch 200/1000, Loss: 30.7117\n",
      "Epoch 300/1000, Loss: 25.2109\n",
      "Epoch 400/1000, Loss: 21.2474\n",
      "Epoch 500/1000, Loss: 18.2029\n",
      "Epoch 600/1000, Loss: 15.7899\n",
      "Epoch 700/1000, Loss: 13.8327\n",
      "Epoch 800/1000, Loss: 12.2150\n",
      "Epoch 900/1000, Loss: 10.8594\n",
      "Epoch 1000/1000, Loss: 9.7129\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 39.2067\n",
      "Epoch 200/1000, Loss: 27.8584\n",
      "Epoch 300/1000, Loss: 22.4448\n",
      "Epoch 400/1000, Loss: 18.7784\n",
      "Epoch 500/1000, Loss: 16.0606\n",
      "Epoch 600/1000, Loss: 13.9371\n",
      "Epoch 700/1000, Loss: 12.2354\n",
      "Epoch 800/1000, Loss: 10.8503\n",
      "Epoch 900/1000, Loss: 9.7025\n",
      "Epoch 1000/1000, Loss: 8.7372\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 40.9284\n",
      "Epoch 200/1000, Loss: 28.7127\n",
      "Epoch 300/1000, Loss: 22.8420\n",
      "Epoch 400/1000, Loss: 19.0108\n",
      "Epoch 500/1000, Loss: 16.3002\n",
      "Epoch 600/1000, Loss: 14.2105\n",
      "Epoch 700/1000, Loss: 12.5120\n",
      "Epoch 800/1000, Loss: 11.0956\n",
      "Epoch 900/1000, Loss: 9.8971\n",
      "Epoch 1000/1000, Loss: 8.8768\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 138.9584\n",
      "Epoch 200/1000, Loss: 36.4271\n",
      "Epoch 300/1000, Loss: 30.5457\n",
      "Epoch 400/1000, Loss: 26.7275\n",
      "Epoch 500/1000, Loss: 23.6926\n",
      "Epoch 600/1000, Loss: 21.2229\n",
      "Epoch 700/1000, Loss: 19.1781\n",
      "Epoch 800/1000, Loss: 17.4559\n",
      "Epoch 900/1000, Loss: 15.9826\n",
      "Epoch 1000/1000, Loss: 14.7038\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 131.2997\n",
      "Epoch 200/1000, Loss: 36.5420\n",
      "Epoch 300/1000, Loss: 31.2884\n",
      "Epoch 400/1000, Loss: 27.6519\n",
      "Epoch 500/1000, Loss: 24.6195\n",
      "Epoch 600/1000, Loss: 22.0783\n",
      "Epoch 700/1000, Loss: 19.9437\n",
      "Epoch 800/1000, Loss: 18.1423\n",
      "Epoch 900/1000, Loss: 16.6055\n",
      "Epoch 1000/1000, Loss: 15.2773\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 143.0322\n",
      "Epoch 200/1000, Loss: 37.4781\n",
      "Epoch 300/1000, Loss: 32.0966\n",
      "Epoch 400/1000, Loss: 28.3310\n",
      "Epoch 500/1000, Loss: 25.1305\n",
      "Epoch 600/1000, Loss: 22.4046\n",
      "Epoch 700/1000, Loss: 20.1535\n",
      "Epoch 800/1000, Loss: 18.2979\n",
      "Epoch 900/1000, Loss: 16.7337\n",
      "Epoch 1000/1000, Loss: 15.3930\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 5.1704\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 5.4960\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 5.1981\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 10.3703\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 9.9239\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 9.4387\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 15.8101\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 15.6924\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 16.3974\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 5.4678\n",
      "Epoch 200/500, Loss: 2.9282\n",
      "Epoch 300/500, Loss: 2.0866\n",
      "Epoch 400/500, Loss: 1.6228\n",
      "Early stopping at epoch 409\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 95\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 5.5474\n",
      "Epoch 200/500, Loss: 2.9108\n",
      "Epoch 300/500, Loss: 2.0273\n",
      "Early stopping at epoch 336\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 9.7681\n",
      "Epoch 200/500, Loss: 4.7396\n",
      "Epoch 300/500, Loss: 3.2399\n",
      "Epoch 400/500, Loss: 2.4899\n",
      "Epoch 500/500, Loss: 2.0133\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 9.2251\n",
      "Epoch 200/500, Loss: 4.8195\n",
      "Epoch 300/500, Loss: 3.2705\n",
      "Epoch 400/500, Loss: 2.5298\n",
      "Epoch 500/500, Loss: 2.0715\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 9.3412\n",
      "Early stopping at epoch 114\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 16.5549\n",
      "Epoch 200/500, Loss: 9.1099\n",
      "Epoch 300/500, Loss: 6.0435\n",
      "Epoch 400/500, Loss: 4.5977\n",
      "Epoch 500/500, Loss: 3.7831\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 16.2315\n",
      "Epoch 200/500, Loss: 8.6990\n",
      "Epoch 300/500, Loss: 5.5930\n",
      "Epoch 400/500, Loss: 4.1955\n",
      "Epoch 500/500, Loss: 3.4451\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 14.0043\n",
      "Epoch 200/500, Loss: 7.8762\n",
      "Epoch 300/500, Loss: 5.3354\n",
      "Epoch 400/500, Loss: 4.0922\n",
      "Epoch 500/500, Loss: 3.3617\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 5.5221\n",
      "Epoch 200/1000, Loss: 3.1827\n",
      "Epoch 300/1000, Loss: 2.3475\n",
      "Early stopping at epoch 349\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 5.6688\n",
      "Early stopping at epoch 198\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 5.1036\n",
      "Epoch 200/1000, Loss: 2.7196\n",
      "Epoch 300/1000, Loss: 1.9417\n",
      "Epoch 400/1000, Loss: 1.4807\n",
      "Early stopping at epoch 427\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 9.0379\n",
      "Epoch 200/1000, Loss: 4.9089\n",
      "Epoch 300/1000, Loss: 3.5209\n",
      "Epoch 400/1000, Loss: 2.7553\n",
      "Epoch 500/1000, Loss: 2.2561\n",
      "Epoch 600/1000, Loss: 1.8979\n",
      "Epoch 700/1000, Loss: 1.6260\n",
      "Epoch 800/1000, Loss: 1.4109\n",
      "Early stopping at epoch 889\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 10.0399\n",
      "Epoch 200/1000, Loss: 4.6866\n",
      "Epoch 300/1000, Loss: 3.2133\n",
      "Epoch 400/1000, Loss: 2.5091\n",
      "Early stopping at epoch 410\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 8.8868\n",
      "Early stopping at epoch 129\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 15.1153\n",
      "Epoch 200/1000, Loss: 8.2267\n",
      "Epoch 300/1000, Loss: 5.4781\n",
      "Epoch 400/1000, Loss: 4.2059\n",
      "Epoch 500/1000, Loss: 3.4745\n",
      "Epoch 600/1000, Loss: 2.9861\n",
      "Epoch 700/1000, Loss: 2.6253\n",
      "Epoch 800/1000, Loss: 2.3425\n",
      "Epoch 900/1000, Loss: 2.1137\n",
      "Epoch 1000/1000, Loss: 1.9242\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 15.5578\n",
      "Epoch 200/1000, Loss: 8.2701\n",
      "Epoch 300/1000, Loss: 5.4791\n",
      "Epoch 400/1000, Loss: 4.1583\n",
      "Epoch 500/1000, Loss: 3.4263\n",
      "Epoch 600/1000, Loss: 2.9497\n",
      "Early stopping at epoch 641\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 16.0695\n",
      "Epoch 200/1000, Loss: 8.7241\n",
      "Epoch 300/1000, Loss: 5.8813\n",
      "Epoch 400/1000, Loss: 4.4537\n",
      "Epoch 500/1000, Loss: 3.6193\n",
      "Early stopping at epoch 552\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 21\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 25\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 32\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 56\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 31\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 26\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 21\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 20\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 39\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 41\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 44\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 26\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 40\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 17\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 21\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 13\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 47\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 49\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'tanh', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 7\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 15.5271\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 16.0042\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 15.4925\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 19.6209\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 19.9447\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 20.1501\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 24.5233\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 22.4394\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 23.3168\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 16.2443\n",
      "Epoch 200/500, Loss: 12.5638\n",
      "Epoch 300/500, Loss: 10.3914\n",
      "Epoch 400/500, Loss: 8.8989\n",
      "Early stopping at epoch 416\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 15.9815\n",
      "Epoch 200/500, Loss: 12.8671\n",
      "Epoch 300/500, Loss: 10.7837\n",
      "Epoch 400/500, Loss: 9.2466\n",
      "Epoch 500/500, Loss: 8.0298\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 14.3352\n",
      "Epoch 200/500, Loss: 11.0298\n",
      "Epoch 300/500, Loss: 9.0746\n",
      "Epoch 400/500, Loss: 7.7522\n",
      "Early stopping at epoch 406\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 19.1530\n",
      "Epoch 200/500, Loss: 15.1033\n",
      "Epoch 300/500, Loss: 13.0456\n",
      "Epoch 400/500, Loss: 11.5856\n",
      "Epoch 500/500, Loss: 10.4363\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 18.2484\n",
      "Epoch 200/500, Loss: 14.8969\n",
      "Epoch 300/500, Loss: 13.0408\n",
      "Epoch 400/500, Loss: 11.7074\n",
      "Epoch 500/500, Loss: 10.6666\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 18.6222\n",
      "Epoch 200/500, Loss: 15.0689\n",
      "Epoch 300/500, Loss: 13.1348\n",
      "Epoch 400/500, Loss: 11.8051\n",
      "Epoch 500/500, Loss: 10.7442\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 26.2152\n",
      "Epoch 200/500, Loss: 19.7921\n",
      "Epoch 300/500, Loss: 16.9866\n",
      "Epoch 400/500, Loss: 15.2525\n",
      "Epoch 500/500, Loss: 14.0152\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 22.4216\n",
      "Epoch 200/500, Loss: 17.4459\n",
      "Epoch 300/500, Loss: 15.3950\n",
      "Epoch 400/500, Loss: 14.0354\n",
      "Epoch 500/500, Loss: 13.0139\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 25.1275\n",
      "Epoch 200/500, Loss: 18.9153\n",
      "Epoch 300/500, Loss: 16.3938\n",
      "Epoch 400/500, Loss: 14.8336\n",
      "Epoch 500/500, Loss: 13.6580\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 15.8227\n",
      "Epoch 200/1000, Loss: 11.8277\n",
      "Epoch 300/1000, Loss: 9.4651\n",
      "Epoch 400/1000, Loss: 7.9066\n",
      "Early stopping at epoch 419\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 15.7694\n",
      "Epoch 200/1000, Loss: 11.9048\n",
      "Epoch 300/1000, Loss: 9.6343\n",
      "Epoch 400/1000, Loss: 8.0743\n",
      "Early stopping at epoch 442\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 14.6521\n",
      "Epoch 200/1000, Loss: 11.2661\n",
      "Epoch 300/1000, Loss: 9.2837\n",
      "Early stopping at epoch 397\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 19.5983\n",
      "Epoch 200/1000, Loss: 16.2446\n",
      "Epoch 300/1000, Loss: 14.2400\n",
      "Epoch 400/1000, Loss: 12.7104\n",
      "Epoch 500/1000, Loss: 11.4703\n",
      "Epoch 600/1000, Loss: 10.4365\n",
      "Epoch 700/1000, Loss: 9.5425\n",
      "Epoch 800/1000, Loss: 8.7530\n",
      "Epoch 900/1000, Loss: 8.0451\n",
      "Epoch 1000/1000, Loss: 7.4157\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 20.1217\n",
      "Epoch 200/1000, Loss: 15.5092\n",
      "Epoch 300/1000, Loss: 13.1517\n",
      "Epoch 400/1000, Loss: 11.5145\n",
      "Epoch 500/1000, Loss: 10.2776\n",
      "Epoch 600/1000, Loss: 9.3024\n",
      "Early stopping at epoch 670\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 18.2063\n",
      "Epoch 200/1000, Loss: 14.6531\n",
      "Epoch 300/1000, Loss: 12.8133\n",
      "Epoch 400/1000, Loss: 11.5011\n",
      "Epoch 500/1000, Loss: 10.4570\n",
      "Epoch 600/1000, Loss: 9.5979\n",
      "Early stopping at epoch 638\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 24.1160\n",
      "Epoch 200/1000, Loss: 18.2977\n",
      "Epoch 300/1000, Loss: 16.0243\n",
      "Epoch 400/1000, Loss: 14.6382\n",
      "Epoch 500/1000, Loss: 13.5963\n",
      "Epoch 600/1000, Loss: 12.7319\n",
      "Epoch 700/1000, Loss: 11.9865\n",
      "Epoch 800/1000, Loss: 11.3423\n",
      "Epoch 900/1000, Loss: 10.7581\n",
      "Epoch 1000/1000, Loss: 10.2238\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 23.6803\n",
      "Epoch 200/1000, Loss: 18.6440\n",
      "Epoch 300/1000, Loss: 16.4236\n",
      "Epoch 400/1000, Loss: 14.9340\n",
      "Epoch 500/1000, Loss: 13.7941\n",
      "Epoch 600/1000, Loss: 12.8622\n",
      "Epoch 700/1000, Loss: 12.0754\n",
      "Epoch 800/1000, Loss: 11.3673\n",
      "Epoch 900/1000, Loss: 10.7592\n",
      "Epoch 1000/1000, Loss: 10.2220\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.0001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 23.3025\n",
      "Epoch 200/1000, Loss: 18.1498\n",
      "Epoch 300/1000, Loss: 16.0465\n",
      "Epoch 400/1000, Loss: 14.6306\n",
      "Epoch 500/1000, Loss: 13.4995\n",
      "Epoch 600/1000, Loss: 12.5560\n",
      "Epoch 700/1000, Loss: 11.7355\n",
      "Epoch 800/1000, Loss: 11.0253\n",
      "Epoch 900/1000, Loss: 10.4092\n",
      "Epoch 1000/1000, Loss: 9.8609\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 69\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 58\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 66\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 96\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 7.8654\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 7.3351\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/100, Loss: 10.9596\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/100, Loss: 10.5797\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/100, Loss: 10.5478\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 78\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 84\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 5.5094\n",
      "Epoch 200/500, Loss: 2.8872\n",
      "Early stopping at epoch 209\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 8.0965\n",
      "Early stopping at epoch 111\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 97\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 8.0138\n",
      "Early stopping at epoch 111\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/500, Loss: 11.0564\n",
      "Early stopping at epoch 176\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/500, Loss: 10.1447\n",
      "Early stopping at epoch 183\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/500, Loss: 10.4437\n",
      "Epoch 200/500, Loss: 7.0784\n",
      "Early stopping at epoch 224\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 56\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 5.5731\n",
      "Early stopping at epoch 109\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 67\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 7.8239\n",
      "Early stopping at epoch 124\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 80\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 7.6736\n",
      "Early stopping at epoch 125\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Epoch 100/1000, Loss: 10.2559\n",
      "Early stopping at epoch 121\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 11.1163\n",
      "Early stopping at epoch 182\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Epoch 100/1000, Loss: 10.5624\n",
      "Early stopping at epoch 173\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 35\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 11\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 24\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 26\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 5\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 24\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 9\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 36\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 11\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 23\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 51\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 39\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 5\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 27\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 15\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 500, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 6\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 34\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 8\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 49\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 29\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 14\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 32, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 36\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "Early stopping at epoch 16\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'batch'}\n",
      "Early stopping at epoch 32\n",
      "Testing configuration: {'hidden_sizes': [256, 128], 'activation': 'relu', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 64, 'optimizer': 'mini-batch'}\n",
      "Early stopping at epoch 32\n",
      "Best Model Configuration:\n",
      "{'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mse</td><td></td></tr><tr><td>r2_score</td><td></td></tr><tr><td>rmse</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mse</td><td>20.05143</td></tr><tr><td>r2_score</td><td>0.74772</td></tr><tr><td>rmse</td><td>4.47788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-river-6</strong> at: <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal/runs/vbd5arbi' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal/runs/vbd5arbi</a><br/> View project at: <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241010_021622-vbd5arbi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLPRegressor:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, activation='relu', \n",
    "                 learning_rate=0.01, epochs=100, batch_size=32, optimizer='sgd', patience=5, min_delta=0.001):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) * np.sqrt(2. / layer_sizes[i-1]))\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "        self.set_activation(activation)\n",
    "\n",
    "    def set_activation(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = self.sigmoid\n",
    "            self.activation_derivative = self.sigmoid_derivative\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = self.tanh\n",
    "            self.activation_derivative = self.tanh_derivative\n",
    "        elif activation == 'relu':\n",
    "            self.activation = self.relu\n",
    "            self.activation_derivative = self.relu_derivative\n",
    "        elif activation == 'linear':\n",
    "            self.activation = self.linear\n",
    "            self.activation_derivative = self.linear_derivative\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -709, 709)))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh_derivative(x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_derivative(x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_derivative(x):\n",
    "        return np.ones_like(x)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.layer_outputs = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(self.layer_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self.activation(z) if i < len(self.weights) - 1 else z\n",
    "            self.layer_outputs.append(a)\n",
    "        return self.layer_outputs[-1]\n",
    "\n",
    "    def backward_propagation(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        delta = self.layer_outputs[-1] - y.reshape(-1, 1)\n",
    "        gradients = []\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dW = np.dot(self.layer_outputs[i].T, delta) / m\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            gradients.append((dW, db))\n",
    "            if i > 0:\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.activation_derivative(self.layer_outputs[i])\n",
    "        return list(reversed(gradients))\n",
    "\n",
    "    def update_parameters(self, gradients):\n",
    "        for i, (dW, db) in enumerate(gradients):\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(0, X.shape[0], self.batch_size):\n",
    "                batch_X = X[i:i+self.batch_size]\n",
    "                batch_y = y[i:i+self.batch_size]\n",
    "                \n",
    "                y_pred = self.forward_propagation(batch_X)\n",
    "                gradients = self.backward_propagation(batch_X, batch_y)\n",
    "                self.update_parameters(gradients)\n",
    "            \n",
    "            loss = self.compute_loss(X, y)\n",
    "            self.losses.append(loss)\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_loss = self.compute_loss(X_val, y_val)\n",
    "                self.val_losses.append(val_loss)\n",
    "                \n",
    "                if val_loss < best_val_loss - self.min_delta:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward_propagation(X)\n",
    "\n",
    "    def compute_loss(self, X, y):\n",
    "        y_pred = self.forward_propagation(X)\n",
    "        return np.mean((y_pred - y.reshape(-1, 1))**2)\n",
    "\n",
    "    def gradient_checking(self, X, y, epsilon=1e-7):\n",
    "        gradients = self.backward_propagation(X, y)\n",
    "        for i, (dW, db) in enumerate(gradients):\n",
    "            for j in range(dW.shape[0]):\n",
    "                for k in range(dW.shape[1]):\n",
    "                    self.weights[i][j, k] += epsilon\n",
    "                    cost_plus = self.compute_loss(X, y)\n",
    "                    self.weights[i][j, k] -= 2 * epsilon\n",
    "                    cost_minus = self.compute_loss(X, y)\n",
    "                    self.weights[i][j, k] += epsilon\n",
    "                    \n",
    "                    grad_approx = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "                    grad_backprop = dW[j, k]\n",
    "                    \n",
    "                    rel_error = abs(grad_backprop - grad_approx) / max(abs(grad_backprop), abs(grad_approx))\n",
    "                    if rel_error > 1e-5:\n",
    "                        print(f\"Gradient Check Failed for W[{i}][{j},{k}]. Relative Error: {rel_error:.6f}\")\n",
    "                        return False\n",
    "        \n",
    "        print(\"Gradient Check Passed!\")\n",
    "        return True\n",
    "    \n",
    "\n",
    "\n",
    "import wandb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from itertools import product\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, config):\n",
    "    model = MLPRegressor(\n",
    "        input_size=X_train.shape[1],\n",
    "        hidden_sizes=config['hidden_sizes'],\n",
    "        output_size=1,\n",
    "        activation=config['activation'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        epochs=config['epochs'],\n",
    "        batch_size=config['batch_size'],\n",
    "        optimizer=config['optimizer']\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return model, mse, rmse, r2\n",
    "\n",
    "def hyperparameter_tuning(X_train_standardized, y_train, X_val_standardized, y_val, X_test_standardized, y_test):\n",
    "    # Define hyperparameters to tune\n",
    "    hidden_sizes_list = [[64, 32], [128, 64], [256, 128]]\n",
    "    activations = ['sigmoid', 'tanh', 'relu']\n",
    "    learning_rates = [0.0001, 0.001, 0.01]\n",
    "    epochs_list = [100, 500, 1000]\n",
    "    batch_sizes = [16, 32, 64]\n",
    "    optimizers = ['sgd', 'batch', 'mini-batch']\n",
    "\n",
    "    best_model = None\n",
    "    best_mse = float('inf')\n",
    "    best_config = None\n",
    "\n",
    "    wandb.init(project='regression_test_prefinal', entity='vishnuvarun-iiit-hyderabad')\n",
    "\n",
    "    for hidden_sizes, activation, lr, epochs, batch_size, optimizer in product(hidden_sizes_list, activations, learning_rates, epochs_list, batch_sizes, optimizers):\n",
    "        config = {\n",
    "            'hidden_sizes': hidden_sizes,\n",
    "            'activation': activation,\n",
    "            'learning_rate': lr,\n",
    "            'epochs': epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'optimizer': optimizer\n",
    "        }\n",
    "        \n",
    "        print(f\"Testing configuration: {config}\")\n",
    "        \n",
    "        model, mse, rmse, r2 = train_and_evaluate(X_train_standardized, y_train, X_val_standardized, y_val, X_test_standardized, y_test, config)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"mse\": mse,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2_score\": r2\n",
    "        })\n",
    "        \n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_model = model\n",
    "            best_config = config\n",
    "\n",
    "    print(\"Best Model Configuration:\")\n",
    "    print(best_config)\n",
    "    wandb.finish()\n",
    "    return best_model\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "best_model = hyperparameter_tuning(X_train_standardized, y_train, X_val_standardized, y_val, X_test_standardized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishnuvarun\u001b[0m (\u001b[33mvishnuvarun-iiit-hyderabad\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srivishnuvarun/3rd year/SMAI/smai-m24-assignments-Vishnuvarun077/assignments/3/wandb/run-20241011_001300-eork2wvt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best/runs/eork2wvt' target=\"_blank\">gallant-dust-1</a></strong> to <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best/runs/eork2wvt' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best/runs/eork2wvt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing configuration: {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
      "Epoch 100/1000, Loss: 7.3085\n",
      "Epoch 200/1000, Loss: 5.0206\n",
      "Epoch 300/1000, Loss: 4.1276\n",
      "Early stopping at epoch 315\n",
      "Best Model Configuration:\n",
      "{'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mse</td><td></td></tr><tr><td>r2_score</td><td></td></tr><tr><td>rmse</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mse</td><td>14.46291</td></tr><tr><td>r2_score</td><td>0.81803</td></tr><tr><td>rmse</td><td>3.80301</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-dust-1</strong> at: <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best/runs/eork2wvt' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best/runs/eork2wvt</a><br/> View project at: <a href='https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best' target=\"_blank\">https://wandb.ai/vishnuvarun-iiit-hyderabad/regression_test_prefinal_best</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_001300-eork2wvt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Best Model Configuration:\n",
    "# {'hidden_sizes': [64, 32], 'activation': 'sigmoid', 'learning_rate': 0.01, 'epochs': 1000, 'batch_size': 16, 'optimizer': 'batch'}\n",
    "import numpy as np\n",
    "\n",
    "class MLPRegressor:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, activation='relu', \n",
    "                 learning_rate=0.01, epochs=100, batch_size=32, optimizer='sgd', patience=5, min_delta=0.001):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) * np.sqrt(2. / layer_sizes[i-1]))\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "        self.set_activation(activation)\n",
    "\n",
    "    def set_activation(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = self.sigmoid\n",
    "            self.activation_derivative = self.sigmoid_derivative\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = self.tanh\n",
    "            self.activation_derivative = self.tanh_derivative\n",
    "        elif activation == 'relu':\n",
    "            self.activation = self.relu\n",
    "            self.activation_derivative = self.relu_derivative\n",
    "        elif activation == 'linear':\n",
    "            self.activation = self.linear\n",
    "            self.activation_derivative = self.linear_derivative\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -709, 709)))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh_derivative(x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_derivative(x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_derivative(x):\n",
    "        return np.ones_like(x)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.layer_outputs = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(self.layer_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self.activation(z) if i < len(self.weights) - 1 else z\n",
    "            self.layer_outputs.append(a)\n",
    "        return self.layer_outputs[-1]\n",
    "\n",
    "    def backward_propagation(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        delta = self.layer_outputs[-1] - y.reshape(-1, 1)\n",
    "        gradients = []\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dW = np.dot(self.layer_outputs[i].T, delta) / m\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            gradients.append((dW, db))\n",
    "            if i > 0:\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.activation_derivative(self.layer_outputs[i])\n",
    "        return list(reversed(gradients))\n",
    "\n",
    "    def update_parameters(self, gradients):\n",
    "        for i, (dW, db) in enumerate(gradients):\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(0, X.shape[0], self.batch_size):\n",
    "                batch_X = X[i:i+self.batch_size]\n",
    "                batch_y = y[i:i+self.batch_size]\n",
    "                \n",
    "                y_pred = self.forward_propagation(batch_X)\n",
    "                gradients = self.backward_propagation(batch_X, batch_y)\n",
    "                self.update_parameters(gradients)\n",
    "            \n",
    "            loss = self.compute_loss(X, y)\n",
    "            self.losses.append(loss)\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_loss = self.compute_loss(X_val, y_val)\n",
    "                self.val_losses.append(val_loss)\n",
    "                \n",
    "                if val_loss < best_val_loss - self.min_delta:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward_propagation(X)\n",
    "\n",
    "    def compute_loss(self, X, y):\n",
    "        y_pred = self.forward_propagation(X)\n",
    "        return np.mean((y_pred - y.reshape(-1, 1))**2)\n",
    "\n",
    "    def gradient_checking(self, X, y, epsilon=1e-7):\n",
    "        gradients = self.backward_propagation(X, y)\n",
    "        for i, (dW, db) in enumerate(gradients):\n",
    "            for j in range(dW.shape[0]):\n",
    "                for k in range(dW.shape[1]):\n",
    "                    self.weights[i][j, k] += epsilon\n",
    "                    cost_plus = self.compute_loss(X, y)\n",
    "                    self.weights[i][j, k] -= 2 * epsilon\n",
    "                    cost_minus = self.compute_loss(X, y)\n",
    "                    self.weights[i][j, k] += epsilon\n",
    "                    \n",
    "                    grad_approx = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "                    grad_backprop = dW[j, k]\n",
    "                    \n",
    "                    rel_error = abs(grad_backprop - grad_approx) / max(abs(grad_backprop), abs(grad_approx))\n",
    "                    if rel_error > 1e-5:\n",
    "                        print(f\"Gradient Check Failed for W[{i}][{j},{k}]. Relative Error: {rel_error:.6f}\")\n",
    "                        return False\n",
    "        \n",
    "        print(\"Gradient Check Passed!\")\n",
    "        return True\n",
    "    \n",
    "\n",
    "\n",
    "import wandb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from itertools import product\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, config):\n",
    "    model = MLPRegressor(\n",
    "        input_size=X_train.shape[1],\n",
    "        hidden_sizes=config['hidden_sizes'],\n",
    "        output_size=1,\n",
    "        activation=config['activation'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        epochs=config['epochs'],\n",
    "        batch_size=config['batch_size'],\n",
    "        optimizer=config['optimizer']\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return model, mse, rmse, r2\n",
    "\n",
    "def hyperparameter_tuning(X_train_standardized, y_train, X_val_standardized, y_val, X_test_standardized, y_test):\n",
    "    # Define hyperparameters to tune\n",
    "    hidden_sizes_list = [[64, 32]]\n",
    "    activations = ['sigmoid']\n",
    "    learning_rates = [0.01]\n",
    "    epochs_list = [1000]\n",
    "    batch_sizes = [16]\n",
    "    optimizers = ['batch']\n",
    "\n",
    "    best_model = None\n",
    "    best_mse = float('inf')\n",
    "    best_config = None\n",
    "\n",
    "    wandb.init(project='regression_test_prefinal_best', entity='vishnuvarun-iiit-hyderabad')\n",
    "\n",
    "    for hidden_sizes, activation, lr, epochs, batch_size, optimizer in product(hidden_sizes_list, activations, learning_rates, epochs_list, batch_sizes, optimizers):\n",
    "        config = {\n",
    "            'hidden_sizes': hidden_sizes,\n",
    "            'activation': activation,\n",
    "            'learning_rate': lr,\n",
    "            'epochs': epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'optimizer': optimizer\n",
    "        }\n",
    "        \n",
    "        print(f\"Testing configuration: {config}\")\n",
    "        \n",
    "        model, mse, rmse, r2 = train_and_evaluate(X_train_standardized, y_train, X_val_standardized, y_val, X_test_standardized, y_test, config)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"mse\": mse,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2_score\": r2\n",
    "        })\n",
    "        \n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_model = model\n",
    "            best_config = config\n",
    "\n",
    "    print(\"Best Model Configuration:\")\n",
    "    print(best_config)\n",
    "    wandb.finish()\n",
    "    return best_model\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "best_model = hyperparameter_tuning(X_train_standardized, y_train, X_val_standardized, y_val, X_test_standardized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters:\n",
      "Hidden Sizes: [64, 32]\n",
      "Activation Function: <function MLPRegressor.sigmoid at 0x7f3f2de3f4c0>\n",
      "Learning Rate: 0.01\n",
      "Optimizer: batch\n",
      "Batch Size: 16\n",
      "Number of Epochs: 1000\n",
      "\n",
      "Validation Set Metrics:\n",
      "Validation MSE: 5.5323\n",
      "Validation MAE: 1.7457\n",
      "Validation RMSE: 2.3521\n",
      "Validation R-squared: 0.9202\n",
      "\n",
      "Test Set Metrics:\n",
      "Test MSE: 14.4629\n",
      "Test MAE: 2.1931\n",
      "Test RMSE: 3.8030\n",
      "Test R-squared: 0.8180\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# def evaluate_best_model(X_test, y_test, best_model):\n",
    "#     print(\"Best Model Parameters:\")\n",
    "#     print(f\"Hidden Sizes: {best_model.hidden_sizes}\")\n",
    "#     print(f\"Activation Function: {best_model.activation}\")\n",
    "#     print(f\"Learning Rate: {best_model.learning_rate}\")\n",
    "#     print(f\"Optimizer: {best_model.optimizer}\")\n",
    "#     print(f\"Batch Size: {best_model.batch_size}\")\n",
    "#     print(f\"Number of Epochs: {best_model.epochs}\")\n",
    "    \n",
    "    \n",
    "#     y_pred = best_model.predict(X_test)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "#     print(\"\\nTest Set Metrics:\")\n",
    "#     print(f\"Test MSE: {mse:.4f}\")\n",
    "#     print(f\"Test MAE: {mae:.4f}\")\n",
    "\n",
    "\n",
    "# # Evaluate the best model\n",
    "# evaluate_best_model(X_test_standardized, y_test, best_model)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "def evaluate_best_model(X_test, y_test, X_val, y_val, best_model):\n",
    "    print(\"Best Model Parameters:\")\n",
    "    print(f\"Hidden Sizes: {best_model.hidden_sizes}\")\n",
    "    print(f\"Activation Function: {best_model.activation}\")\n",
    "    print(f\"Learning Rate: {best_model.learning_rate}\")\n",
    "    print(f\"Optimizer: {best_model.optimizer}\")\n",
    "    print(f\"Batch Size: {best_model.batch_size}\")\n",
    "    print(f\"Number of Epochs: {best_model.epochs}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_pred_val = best_model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    rmse_val = root_mean_squared_error(y_val, y_pred_val)\n",
    "    r2_val = r_squared(y_val, y_pred_val)\n",
    "    \n",
    "    print(\"\\nValidation Set Metrics:\")\n",
    "    print(f\"Validation MSE: {mse_val:.4f}\")\n",
    "    print(f\"Validation MAE: {mae_val:.4f}\")\n",
    "    print(f\"Validation RMSE: {rmse_val:.4f}\")\n",
    "    print(f\"Validation R-squared: {r2_val:.4f}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse_test = root_mean_squared_error(y_test, y_pred_test)\n",
    "    r2_test = r_squared(y_test, y_pred_test)\n",
    "    \n",
    "    print(\"\\nTest Set Metrics:\")\n",
    "    print(f\"Test MSE: {mse_test:.4f}\")\n",
    "    print(f\"Test MAE: {mae_test:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"Test R-squared: {r2_test:.4f}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "evaluate_best_model(X_test_standardized, y_test, X_val_standardized, y_val, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 data points with the highest MSE:\n",
      "    Index         MSE    True             Predicted\n",
      "2       2  488.918032  [50.0]  [27.888509040623738]\n",
      "20     20  123.138755  [36.2]  [25.103209692614975]\n",
      "54     54  113.539083  [27.5]  [16.844528032560167]\n",
      "4       4   46.244871  [16.1]   [22.90035817800608]\n",
      "9       9   41.981568  [29.8]  [23.320681516109907]\n",
      "\n",
      "Top 5 data points with the lowest MSE:\n",
      "    Index       MSE    True             Predicted\n",
      "43     43  0.021786  [15.0]  [14.852399524781287]\n",
      "44     44  0.020199  [15.1]  [14.957875795481648]\n",
      "69     69  0.010699  [19.3]   [19.19656589211712]\n",
      "1       1  0.001424  [17.1]  [17.137735414903293]\n",
      "42     42  0.000554  [16.1]   [16.07645449580251]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_mse_per_datapoint(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2, axis=1)\n",
    "\n",
    "def analyze_mse_loss(X_test, y_test, best_model):\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse_per_datapoint = calculate_mse_per_datapoint(y_test, y_pred)\n",
    "    \n",
    "    # Create a DataFrame to store the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Index': np.arange(len(y_test)),\n",
    "        'MSE': mse_per_datapoint,\n",
    "        'True': y_test.tolist(),\n",
    "        'Predicted': y_pred.tolist()\n",
    "    })\n",
    "    \n",
    "    # Sort the DataFrame by MSE\n",
    "    results_df = results_df.sort_values(by='MSE', ascending=False)\n",
    "    \n",
    "    # Display the top 5 data points with the highest MSE\n",
    "    print(\"Top 5 data points with the highest MSE:\")\n",
    "    print(results_df.head())\n",
    "    \n",
    "    # Display the top 5 data points with the lowest MSE\n",
    "    print(\"\\nTop 5 data points with the lowest MSE:\")\n",
    "    print(results_df.tail())\n",
    "    \n",
    "    # Plot the MSE distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(mse_per_datapoint, bins=50, edgecolor='k')\n",
    "    plt.title('Distribution of MSE Loss per Data Point')\n",
    "    plt.xlabel('MSE Loss')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig('figures/3/q3_6_mse_distribution.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the data points with the highest and lowest MSE\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(results_df['Index'], results_df['MSE'], alpha=0.5)\n",
    "    plt.title('MSE Loss per Data Point')\n",
    "    plt.xlabel('Data Point Index')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.savefig('figures/3/q3_6_mse_per_datapoint.png')\n",
    "    plt.show()\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Analyze the MSE loss for each data point in the test dataset\n",
    "results_df = analyze_mse_loss(X_test_standardized, y_test, best_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 0.1716\n",
      "Early stopping at epoch 114\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAAHWCAYAAADUwLIxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACrWElEQVR4nOzdd1gU1/4G8Hd36R3pKIKigiiComAvkViDxmhENGKJsURNLDGRXNFEo6gxxsSaGHssGFsSuxI1FiIKdrEiVapKl7Y7vz/U/WUDKiAwLLyf55nnuc6emX1nufee/e6cOUciCIIAIiIiIiIiIlILUrEDEBEREREREVHpsZAnIiIiIiIiUiMs5ImIiIiIiIjUCAt5IiIiIiIiIjXCQp6IiIiIiIhIjbCQJyIiIiIiIlIjLOSJiIiIiIiI1AgLeSIiIiIiIiI1wkKeiIiIiIiISI2wkCciqmTR0dGQSCRYsmSJ2FGIiIiogm3cuBESiQQXL14UOwrVIizkiV7hxf8xSyQSnDlzptjrgiDAzs4OEokE77zzjspr2dnZmDNnDpo3bw59fX2YmZnB3d0dn376KR4+fKhs99VXXynfo6QtKSnplRkdHByKvXdt86JQftm2cOFCsSMSEVE19u/+/sVmaWmJbt264dChQyUek5ycjM8++wzOzs7Q09ODvr4+PDw88M033yA9PV3ZrmvXri/tn5ydnV+Ziz8EP1PS3+ff2z///CN2RKIqpyF2ACJ1oKOjg23btqFjx44q+0+dOoX4+Hhoa2ur7C8sLETnzp1x69YtjBgxApMnT0Z2djZu3LiBbdu2YcCAAbC1tVU5ZvXq1TAwMCj23iYmJpV0VTWPn58f+vTpU2x/y5YtRclDRETqZe7cuWjQoAEEQUBycjI2btyIPn364M8//1T50fzChQvo06cPsrOz8cEHH8DDwwMAcPHiRSxcuBB///03jh49qmxfr149BAUFFXs/Y2PjKrqymuHF3+e/GjVqJEoeIjGxkCcqhT59+uC3337Djz/+CA2N//+fzbZt2+Dh4YG0tDSV9vv27cOlS5ewdetWDB06VOW1vLw8FBQUFHuPQYMGwdzcvBKvouZr1aoVPvjgA7FjEBGRmurduzdat26t/PeHH34IKysrbN++XVnIp6enY8CAAZDJZLh06VKxu+rz58/H2rVrVfYZGxuzf6oA//37ENVmHFpPVAp+fn549OgRjh07ptxXUFCAXbt2FSvUAeD+/fsAgA4dOhR7TUdHB0ZGRpWcWFVRURHmzZsHR0dHaGtrw8HBAV9++SXy8/NV2l28eBE9e/aEubk5dHV10aBBA4wePVqlzY4dO+Dh4QFDQ0MYGRnB1dUVP/zww0vfu7CwEHXq1MGoUaOKvZaZmQkdHR189tlnyn3Lly9Hs2bNoKenB1NTU7Ru3Rrbtm2rkM8B/3oU4ejRo3B3d4eOjg5cXFywZ8+eYm2joqLw/vvvo06dOtDT00Pbtm1x4MCBYu3y8vLw1VdfoUmTJtDR0YGNjQ3ee+895X8P/u3nn39W/h3atGmDCxcuqLyelJSEUaNGoV69etDW1oaNjQ369++P6OjoCvsMiIiodExMTKCrq6vyI/5PP/2EhIQELF26tMSh8VZWVpg1a1aV5kxJSVH+6KCjowM3Nzds2rSpWLvX9eGFhYX4+uuv0bhxY+jo6MDMzAwdO3ZU+f7zXxcvXoREIinx/Y4cOQKJRIL9+/cDALKysjBlyhQ4ODhAW1sblpaWePvttxEREVEhn8O/H0X4/vvvYW9vD11dXXTp0gXXr18v1v6vv/5Cp06doK+vDxMTE/Tv3x+RkZHF2iUkJODDDz+Era0ttLW10aBBA0yYMKHYjZn8/HxMmzYNFhYW0NfXx4ABA5CamqrSpjTftYhKg3fkiUrBwcEB7dq1w/bt29G7d28AwKFDh5CRkYEhQ4bgxx9/VGlvb28PANi8eTNmzZoFiUTy2vd4/PhxsX0aGhoVMrR+zJgx2LRpEwYNGoTp06fj/PnzCAoKQmRkJPbu3Qs8/xLQo0cPWFhYYObMmTAxMUF0dLRKgXvs2DH4+fmhe/fuWLRoEQAgMjISZ8+exaefflrie2tqamLAgAHYs2cPfvrpJ2hpaSlf27dvH/Lz8zFkyBAAwNq1a/HJJ59g0KBB+PTTT5GXl4erV6/i/PnzJf5g8l+5ubnFRkfg+Rexf38Ju3v3Lnx9fTF+/HiMGDECGzZswPvvv4/Dhw/j7bffBp4/+9i+fXvk5ubik08+gZmZGTZt2oR+/fph165dGDBgAABALpfjnXfeQUhICIYMGYJPP/0UWVlZOHbsGK5fvw5HR0fl+27btg1ZWVkYN24cJBIJFi9ejPfeew9RUVHQ1NQEAAwcOBA3btzA5MmT4eDggJSUFBw7dgyxsbFwcHB47WdARETll5GRgbS0NAiCgJSUFCxfvlw5fP6FP/74A7q6uhg0aFCpzyuXy0vsn3R1daGvr/9GmZ8+fYquXbvi3r17mDRpEho0aIDffvsNI0eORHp6urJ/Lk0f/tVXXyEoKAhjxoyBp6cnMjMzcfHiRURERCj7x/9q3bo1GjZsiJ07d2LEiBEqrwUHB8PU1BQ9e/YEAIwfPx67du3CpEmT4OLigkePHuHMmTOIjIxEq1atXnutL/4+/yaRSGBmZqayb/PmzcjKysLEiRORl5eHH374AW+99RauXbsGKysrAMDx48fRu3dvNGzYEF999RWePn2K5cuXo0OHDoiIiFD2uQ8fPoSnpyfS09MxduxYODs7IyEhAbt27UJubq7K95rJkyfD1NQUc+bMQXR0NJYtW4ZJkyYhODgYKOV3LaJSE4jopTZs2CAAEC5cuCCsWLFCMDQ0FHJzcwVBEIT3339f6NatmyAIgmBvby/07dtXeVxubq7g5OQkABDs7e2FkSNHCuvWrROSk5OLvcecOXMEACVuTk5Or8343/f+r8uXLwsAhDFjxqjs/+yzzwQAwl9//SUIgiDs3btXea0v8+mnnwpGRkZCUVHRa3P925EjRwQAwp9//qmyv0+fPkLDhg2V/+7fv7/QrFmzMp1bEAThwYMHL/0MAQihoaHKtvb29gIAYffu3cp9GRkZgo2NjdCyZUvlvilTpggAhNOnTyv3ZWVlCQ0aNBAcHBwEuVwuCIIgrF+/XgAgLF26tFguhUKhks/MzEx4/Pix8vXff/9d5XN58uSJAED49ttvy/wZEBFR+b3o7/+7aWtrCxs3blRpa2pqKri5uZX63F26dHlp/zRu3LhXHvui/3hVv7Bs2TIBgPDrr78q9xUUFAjt2rUTDAwMhMzMTEEoZR/u5ub2yu8ULxMQECBoamqq9HH5+fmCiYmJMHr0aOU+Y2NjYeLEiWU+/8v+Pi/+Ri+8+Lx0dXWF+Ph45f7z588LAISpU6cq97m7uwuWlpbCo0ePlPuuXLkiSKVSwd/fX7nP399fkEqlJX4/etHPv8jn7e2t3CcIgjB16lRBJpMJ6enpglDK71pEpcWh9USlNHjwYDx9+hT79+9HVlYW9u/f/9K7xLq6ujh//jxmzJgBPJ9t9cMPP4SNjQ0mT55cbEg7AOzevRvHjh1T2TZs2PDGuQ8ePAgAmDZtmsr+6dOnA4ByqPiLO//79+9HYWFhiecyMTFBTk7OK4fYleStt96Cubm58hdpAHjy5AmOHTsGX19flfPHx8cXG25eWmPHji32GR47dgwuLi4q7WxtbZV31AHAyMgI/v7+uHTpknKVgIMHD8LT01NlgkMDAwOMHTsW0dHRuHnzJvD872Zubo7JkycXy/PfkRi+vr4wNTVV/rtTp07A8yH8eP7fGy0tLZw8eRJPnjwp12dARETlt3LlSmXf8euvv6Jbt24YM2aMyh3TzMxMGBoalum8Dg4OJfZPU6ZMeePMBw8ehLW1Nfz8/JT7NDU18cknnyA7OxunTp0CStmHm5iY4MaNG7h7926ZMvj6+qKwsFDlczp69CjS09OL9fPnz59XWb2nLP7993mxlbSqwLvvvou6desq/+3p6QkvLy/ld6LExERcvnwZI0eORJ06dZTtWrRogbffflvZTqFQYN++ffDx8Snx2fz/9vNjx45V2depUyfI5XLExMQorx+v+a5FVFos5IlKycLCAt7e3ti2bRv27NkDuVz+ymF1xsbGWLx4MaKjoxEdHY1169bByckJK1aswLx584q179y5M7y9vVW2du3avXHumJgYSKXSYjO6Wltbw8TERNm5dOnSBQMHDsTXX38Nc3Nz9O/fHxs2bFD50eHjjz9GkyZN0Lt3b9SrVw+jR4/G4cOHX5tBQ0MDAwcOxO+//6483549e1BYWKjSwX/xxRcwMDCAp6cnGjdujIkTJ+Ls2bOlvtbGjRsX+wy9vb2LzUnQqFGjYp1vkyZNgOfP17343JycnIq9R9OmTZWv4/l8CE5OTipD91+mfv36Kv9+UdS/KNq1tbWxaNEiHDp0CFZWVujcuTMWL1782iUIiYioYnh6eir7jmHDhuHAgQNwcXHBpEmTlM9DGxkZISsrq0zn1dfXL7F/et3yc6URExODxo0bQypV/Vr/3/6qNH343LlzkZ6ejiZNmsDV1RUzZszA1atXX5vBzc0Nzs7OKj/YBwcHw9zcHG+99ZZy3+LFi3H9+nXY2dnB09MTX331lfLH7NL499/nxdatW7di7Ro3blxsX5MmTVT6eAAv7efT0tKQk5OD1NRUZGZmonnz5qXK97p+vjTftYhKi4U8URkMHToUhw4dwpo1a9C7d+9SP79ub2+P0aNH4+zZszAxMcHWrVsrPet/ve45fYlEgl27diE0NBSTJk1CQkICRo8eDQ8PD2RnZwMALC0tcfnyZfzxxx/o168fTpw4gd69exd7Jq4kQ4YMQVZWlvKX8507d8LZ2Rlubm7KNk2bNsXt27exY8cOdOzYEbt370bHjh0xZ86cN77+6kAmk5W4XxAE5X+eMmUK7ty5g6CgIOjo6CAwMBBNmzbFpUuXqjApEREBgFQqRbdu3ZCYmKi8S+3s7Iw7d+6UuAJNdVaaPrxz5864f/8+1q9fj+bNm+OXX35Bq1at8Msvv7z2/L6+vjhx4gTS0tKQn5+PP/74AwMHDlT5oXvw4MGIiorC8uXLYWtri2+//RbNmjUr8a66OnpdP1+a71pEpcVCnqgMBgwYAKlUin/++adUk6/9l6mpKRwdHZGYmFgp+Upib28PhUJRbJhccnIy0tPTlRPzvdC2bVvMnz8fFy9exNatW3Hjxg3s2LFD+bqWlhZ8fHywatUq3L9/H+PGjcPmzZtx7969V+bo3LkzbGxsEBwcjLS0NPz1118qd+Nf0NfXh6+vLzZs2IDY2Fj07dsX8+fPR15e3ht/Fi/cu3dPpXgGgDt37gDPhz/i+ed2+/btYsfeunVL+ToAODo64vbt2xU6RM7R0RHTp0/H0aNHcf36dRQUFOC7776rsPMTEVHpFRUVAYCy0PLx8cHTp0+xe/dukZM9Y29vj7t370KhUKjs/29/hVL24S9Wmtm+fTvi4uLQokULfPXVV6/N4evri6KiIuzevRuHDh1CZmamcjLbf7OxscHHH3+Mffv24cGDBzAzM8P8+fPf8FNQVdKjAXfu3FHp4wG8tJ83NzeHvr4+LCwsYGRkVOKM92/idd+1iEqDhTxRGRgYGGD16tX46quv4OPj89J2V65cKXF22piYGNy8ebPEoVyVpU+fPgCAZcuWqexfunQpAKBv377A82Ff/y1u3d3dgefLqQDAo0ePVF6XSqVo0aKFSpuXkUqlGDRoEP78809s2bIFRUVFxQr5/55fS0sLLi4uEAShQgvlhw8fKmfrx/PnHTdv3gx3d3dYW1sDzz+3sLAwhIaGKtvl5OTg559/hoODg/K5+4EDByItLQ0rVqwo9j7//TxfJzc3t9gPFo6OjjA0NOSwOyIiERQWFuLo0aPQ0tJSDlUfP348bGxsMH36dOWPwP+WkpKCb775psoy9unTB0lJSSrD2ouKirB8+XIYGBigS5cuQCn78P+2MTAwQKNGjUrVBzVt2hSurq4IDg5GcHAwbGxs0LlzZ+XrcrkcGRkZKsdYWlrC1ta2wvu4ffv2ISEhQfnvsLAwnD9/XrnykI2NDdzd3bFp0yakp6cr212/fh1Hjx5VfneSSqV499138eeff+LixYvF3qes/XxpvmsRlRaXnyMqo9IMIz927BjmzJmDfv36oW3btjAwMEBUVBTWr1+P/Pz8En/Z3rVrFwwMDIrtf/vtt5VLpbzMvXv3SvzS0LJlS/Tt2xcjRozAzz//jPT0dHTp0gVhYWHYtGkT3n33XeWzZZs2bcKqVaswYMAAODo6IisrC2vXroWRkZGyQxszZgweP36Mt956C/Xq1UNMTAyWL18Od3d35RecV/H19cXy5csxZ84cuLq6FjumR48esLa2RocOHWBlZYXIyEisWLECffv2LdXEQhEREfj111+L7Xd0dFSZb6BJkyb48MMPceHCBVhZWWH9+vVITk5WmVxw5syZyuUGP/nkE9SpUwebNm3CgwcPsHv3buWziP7+/ti8eTOmTZuGsLAwdOrUCTk5OTh+/Dg+/vhj9O/f/7W5X7hz5w66d++OwYMHw8XFBRoaGti7dy+Sk5NLvKtBREQV69ChQ8o72SkpKdi2bRvu3r2LmTNnKudbMTU1xd69e9GnTx+4u7vjgw8+gIeHB/C8H9q+fXuxOW4yMjJK7J8AqCxt9zIhISEljkx79913MXbsWPz0008YOXIkwsPD4eDggF27duHs2bNYtmyZsv8sTR/u4uKCrl27wsPDA3Xq1MHFixeVy8WVhq+vL2bPng0dHR18+OGHKs/tZ2VloV69ehg0aBDc3NxgYGCA48eP48KFC6Uedfbvv8+/tW/fHg0bNlT+u1GjRujYsSMmTJiA/Px8LFu2DGZmZvj888+Vbb799lv07t0b7dq1w4cffqhcfs7Y2Fjle9qCBQtw9OhRdOnSBWPHjkXTpk2RmJiI3377DWfOnCnTMsGl+a5FVGpiT5tPVJ39e/m5V/nvEnBRUVHC7NmzhbZt2wqWlpaChoaGYGFhIfTt21e53NsLr1p+DoBw4sSJ1773y4798MMPBUEQhMLCQuHrr78WGjRoIGhqagp2dnZCQECAkJeXpzxPRESE4OfnJ9SvX1/Q1tYWLC0thXfeeUe4ePGiss2uXbuEHj16CJaWloKWlpZQv359Ydy4cUJiYmKpPk+FQiHY2dkJAIRvvvmm2Os//fST0LlzZ8HMzEzQ1tYWHB0dhRkzZggZGRmvPO/rlp8bMWKEyufVt29f4ciRI0KLFi0EbW1twdnZWfjtt9+Knff+/fvCoEGDBBMTE0FHR0fw9PQU9u/fX6xdbm6u8L///U/5+VpbWwuDBg0S7t+/r5KvpOWDAAhz5swRBEEQ0tLShIkTJwrOzs6Cvr6+YGxsLHh5eQk7d+4s1edLRETlU9LyZjo6OoK7u7uwevVqlSXFXnj48KEwdepUoUmTJoKOjo6gp6cneHh4CPPnz1fpt161/Nzrvoq/rn/bsmWLIAiCkJycLIwaNUowNzcXtLS0BFdXV2HDhg0q5ypNH/7NN98Inp6egomJiaCrqys4OzsL8+fPFwoKCkr1Od69e1eZ7cyZMyqv5efnCzNmzBDc3NwEQ0NDQV9fX3BzcxNWrVr12vO+avk5AMpr/Xd/+9133wl2dnaCtra20KlTJ+HKlSvFznv8+HGhQ4cOgq6urmBkZCT4+PgIN2/eLNYuJiZG8Pf3FywsLARtbW2hYcOGwsSJE4X8/HyVfP/9vnjixAmV73Kl+a5FVFoSoaxjQoiI1JiDgwOaN2+O/fv3ix2FiIiIKlB0dDQaNGiAb7/9Fp999pnYcYgqFZ+RJyIiIiIiIlIjLOSJiIiIiIiI1AgLeSIiIiIiIiI1wmfkiYiIiIiIiNQI78gTERERERERqREW8kRERERERERqREPsANWRQqHAw4cPYWhoCIlEInYcIiIiCIKArKws2NraQirl7/Bvin09ERFVN2Xp61nIl+Dhw4ews7MTOwYREVExcXFxqFevntgx1B77eiIiqq5K09ezkC+BoaEh8PwDNDIyEjsOERERMjMzYWdnp+yj6M2wryciouqmLH09C/kSvBhiZ2RkxM6diIiqFQ4Drxjs64mIqLoqTV/Ph+yIiIiIiIiI1AgLeSIiIqp0K1euhIODA3R0dODl5YWwsLBXtl+2bBmcnJygq6sLOzs7TJ06FXl5ecrXs7KyMGXKFNjb20NXVxft27fHhQsXquBKiIiIxMdCnoiIiCpVcHAwpk2bhjlz5iAiIgJubm7o2bMnUlJSSmy/bds2zJw5E3PmzEFkZCTWrVuH4OBgfPnll8o2Y8aMwbFjx7BlyxZcu3YNPXr0gLe3NxISEqrwyoiIiMQhEQRBEDtEdZOZmQljY2NkZGTwuTkiUiuCIKCoqAhyuVzsKFRGMpkMGhoaL30uTp37Ji8vL7Rp0wYrVqwAni/9Zmdnh8mTJ2PmzJnF2k+aNAmRkZEICQlR7ps+fTrOnz+PM2fO4OnTpzA0NMTvv/+Ovn37Ktt4eHigd+/e+Oabb16bSZ0/TyIiAJDL5SgsLBQ7BpVBRfb1nOyOiKiGKCgoQGJiInJzc8WOQuWkp6cHGxsbaGlpiR2lwhQUFCA8PBwBAQHKfVKpFN7e3ggNDS3xmPbt2+PXX39FWFgYPD09ERUVhYMHD2L48OEAoPyxSkdHR+U4XV1dnDlzpsRz5ufnIz8/X/nvzMzMCrpCIqKql52djfj4ePCerPqpqL6ehTwRUQ2gUCjw4MEDyGQy2NraQktLi7ObqxFBEFBQUIDU1FQ8ePAAjRs3hlRaM55+S0tLg1wuh5WVlcp+Kysr3Lp1q8Rjhg4dirS0NHTs2FE5ymT8+PHKofWGhoZo164d5s2bh6ZNm8LKygrbt29HaGgoGjVqVOI5g4KC8PXXX1fCFRIRVS25XI74+Hjo6enBwsKC/b2aqOi+noU8EVENUFBQoByurKenJ3YcKgddXV1oamoiJiYGBQUFxe421yYnT57EggULsGrVKnh5eeHevXv49NNPMW/ePAQGBgIAtmzZgtGjR6Nu3bqQyWRo1aoV/Pz8EB4eXuI5AwICMG3aNOW/X6zVS0SkbgoLCyEIAiwsLKCrqyt2HCqDiuzrWcgTEdUgNeUubm1VE/9+5ubmkMlkSE5OVtmfnJwMa2vrEo8JDAzE8OHDMWbMGACAq6srcnJyMHbsWPzvf/+DVCqFo6MjTp06hZycHGRmZsLGxga+vr5o2LBhiefU1taGtrZ2JVwhEZE4eCdePVVUX1/zvjEQERFRtaGlpQUPDw+ViesUCgVCQkLQrl27Eo/Jzc0t9kVHJpMBz4cm/pu+vj5sbGzw5MkTHDlyBP3796+U6yAiIqpOeEeeiIiIKtW0adMwYsQItG7dGp6enli2bBlycnIwatQoAIC/vz/q1q2LoKAgAICPjw+WLl2Kli1bKofWBwYGwsfHR1nQHzlyBIIgwMnJCffu3cOMGTPg7OysPCcREVFNxkKeiIiIKpWvry9SU1Mxe/ZsJCUlwd3dHYcPH1ZOgBcbG6tyB37WrFmQSCSYNWsWEhISYGFhAR8fH8yfP1/ZJiMjAwEBAYiPj0edOnUwcOBAzJ8/H5qamqJcIxERUVXi0HoiIhLNyJEjIZFIMH78+GKvTZw4ERKJBCNHjlTuS01NxYQJE1C/fn1oa2vD2toaPXv2xNmzZ5VtHBwcIJFIim0LFy58aY6uXbtiypQplXCF9MKkSZMQExOD/Px8nD9/Hl5eXsrXTp48iY0bNyr/raGhgTlz5uDevXt4+vQpYmNjsXLlSpiYmCjbDB48GPfv30d+fj4SExOxYsUKGBsbV/l1ERFR6bzo819sZmZm6NWrF65evarSThAE/Pzzz/Dy8oKBgQFMTEzQunVrLFu2TLnE7ldffVViX+/s7PzS99+4caNKP6LuWMhXgbxCudgRiIiqLTs7O+zYsQNPnz5V7svLy8O2bdtQv359lbYDBw7EpUuXsGnTJty5cwd//PEHunbtikePHqm0mzt3LhITE1W2yZMnV9k1Ue0kV3A9ZyKiV+nVq5eyXw4JCYGGhgbeeecdlTbDhw/HlClT0L9/f5w4cQKXL19GYGAgfv/9dxw9elTZrlmzZsX6+jNnzohwVeJgIV/JFh++Ba8FIbiekCF2FCKqRQRBQG5BkSjbfycje51WrVrBzs4Oe/bsUe7bs2cP6tevj5YtWyr3paen4/Tp01i0aBG6desGe3t7eHp6IiAgAP369VM5p6GhIaytrVU2fX39cn+eu3fvRrNmzaCtrQ0HBwd89913Kq+vWrUKjRs3ho6ODqysrDBo0CDla7t27YKrqyt0dXVhZmYGb29v5OTklDsLVT+/X05Aj+9PYdnxO2JHIaJaSJ36/Bej6aytreHu7o6ZM2ciLi4OqampAICdO3di69at2L59O7788ku0adMGDg4O6N+/P/766y9069ZNeS4NDY1ifb25uXm5P8fY2Fj0798fBgYGMDIywuDBg1VWXLly5Qq6desGQ0NDGBkZwcPDAxcvXgQAxMTEwMfHB6amptDX10ezZs1w8ODBcmcpDT4jX8ninzxFxtNCbDoXjW/fdxM7DhHVEk8L5XCZfUSU9745tyf0tMrWvYwePRobNmzAsGHDAADr16/HqFGjcPLkSWUbAwMDGBgYYN++fWjbtm2VLSUWHh6OwYMH46uvvoKvry/OnTuHjz/+GGZmZhg5ciQuXryITz75BFu2bEH79u3x+PFjnD59GgCQmJgIPz8/LF68GAMGDEBWVhZOnz5d5i8+VL0VyQXcSc6GTJqC6T2cxI5DRLWMuvX5L2RnZ+PXX39Fo0aNYGZmBgDYunUrnJycSlyBRCKRVNojVAqFQlnEnzp1CkVFRZg4cSJ8fX2V30WGDRuGli1bYvXq1ZDJZLh8+bJyXpaJEyeioKAAf//9N/T19XHz5k0YGBhUStYXWMhXshHtHfDHlYf4/cpDfNmnKUz1tcSORERU7XzwwQcICAhATEwMAODs2bPYsWOHSiGvoaGBjRs34qOPPsKaNWvQqlUrdOnSBUOGDEGLFi1UzvfFF19g1qxZKvsOHTqETp06lTnb0qVL0b17dwQGBgIAmjRpgps3b+Lbb7/FyJEjERsbC319fbzzzjswNDSEvb29ciRBYmIiioqK8N5778He3h54viY61SzdnC0hlQCRiZlISH+Kuia6YkciIqqW9u/fryxwc3JyYGNjg/379ysnPL179y6cnEr3g+i1a9eKFcsffPAB1qxZU+ZcISEhuHbtGh48eAA7OzsAwObNm9GsWTNcuHABbdq0QWxsrHKFFABo3Lix8vjY2FgMHDhQ2cc3bNiwzBnKioV8JWtV3wTN6xrhekImgi/GYXwXR7EjEVEtoKspw825PUV777KysLBA3759sXHjRgiCgL59+5Y4PG7gwIHo27cvTp8+jX/++QeHDh3C4sWL8csvv6hMijdjxgyVfwNA3bp1y3U9kZGRxe4MdOjQAcuWLYNcLsfbb78Ne3t7NGzYEL169UKvXr0wYMAA6Onpwc3NDd27d4erqyt69uyJHj16YNCgQTA1NS1XFqqe6uhroVV9U1yMeYK/IpMxvJ2D2JGIqBZRpz6/W7duWL16NQDgyZMnWLVqFXr37o2wsDDY29uXacSak5MT/vjjD5V9RkZGZcrzQmRkJOzs7JRFPAC4uLjAxMQEkZGRaNOmDaZNm4YxY8Zgy5Yt8Pb2xvvvvw9Hx2e13SeffIIJEybg6NGj8Pb2xsCBA4vdZKhofEa+kkkkEvg/79C3hMZwIhwiqhISiQR6WhqibBKJpFyZR48ejY0bN2LTpk0YPXr0S9vp6Ojg7bffRmBgIM6dO4eRI0dizpw5Km3Mzc3RqFEjlU1Xt3LukhoaGiIiIgLbt2+HjY0NZs+eDTc3N6Snp0Mmk+HYsWM4dOgQXFxcsHz5cjg5OeHBgweVkoXE073ps6X0jkemiB2FiGoZderz9fX1lf1ymzZt8MsvvyAnJwdr164Fno96u3XrVqnOpaWlVayvt7S0LNdnWBpfffUVbty4gb59++Kvv/6Ci4sL9u7dCwAYM2YMoqKiMHz4cFy7dg2tW7fG8uXLKy0LWMhXjX5utjDV00RC+lOERCaX4ggiotqnV69eKCgoQGFhIXr2LP2dBRcXl0qdPK5p06Yqy9vh+dD/Jk2aQCZ7didCQ0MD3t7eWLx4Ma5evYro6Gj89ddfwPMvWB06dMDXX3+NS5cuQUtLS9nxU83h3fTZl8fQ+4+Qk18kdhwiIrUgkUgglUqVK9cMHToUd+7cwe+//16srSAIyMionAnEmzZtiri4OMTFxSn33bx5E+np6XBxcVHua9KkCaZOnYqjR4/ivffew4YNG5Sv2dnZYfz48dizZw+mT5+u/HGisnBofRXQ0ZTBt019rDl1H5tDY9CjmbXYkYiIqh2ZTIbIyEjlf/6vR48e4f3338fo0aPRokULGBoa4uLFi1i8eHGxoe9ZWVlISkpS2aenp/fKIXepqam4fPmyyj4bGxtMnz4dbdq0wbx58+Dr64vQ0FCsWLECq1atAp4/7xcVFYXOnTvD1NQUBw8ehEKhgJOTE86fP4+QkBD06NEDlpaWOH/+PFJTU9G0adM3+qyo+mlkaYD6dfQQ+zgXp++moVdz9vVERP+Vn5+v7J+fPHmCFStWIDs7Gz4+PgCAwYMHY+/evfDz88OsWbPQo0cPWFhY4Nq1a/j+++8xefJkvPvuuwCAoqKiYn29RCKBlZXVS99fLpcX6+u1tbXh7e0NV1dXDBs2DMuWLUNRURE+/vhjdOnSBa1bt8bTp08xY8YMDBo0CA0aNEB8fDwuXLiAgQMHAgCmTJmC3r17o0mTJnjy5AlOnDhR6X09C/kqMsyrPn7++z7O3EvDvZQsNLI0FDsSEVG186pC28DAAF5eXvj+++9x//59FBYWws7ODh999BG+/PJLlbazZ8/G7NmzVfaNGzfulRPgbNu2Ddu2bVPZN2/ePMyaNQs7d+7E7NmzMW/ePNjY2GDu3LnKZ/BNTEywZ88efPXVV8jLy0Pjxo2xfft2NGvWDJGRkfj777+xbNkyZGZmwt7eHt999x169+5dzk+IqiuJRILuTS2x4Ww0QiKTWcgTEZXg8OHDsLGxAZ4/mubs7IzffvsNXbt2BZ7/f+m2bdvw888/Y/369Zg/fz40NDTQuHFj+Pv7q4zYu3HjhvJcL2hrayMvL++l75+dna2ytC0AODo64t69e/j9998xefJkdO7cGVKpFL169VIOj5fJZHj06BH8/f2RnJwMc3NzvPfee/j666+B5z8QTJw4EfHx8TAyMkKvXr3w/fffV+AnV5xE4Bo4xWRmZsLY2BgZGRnlnjChJB9tvohjN5Ph384ec/s3r7DzEhHl5eXhwYMHaNCgAXR0dMSOQ+X0qr9jZfVNtVVlfJ5n76Vh2C/nYW6ghbAvvSGVlm++CCKiV2Gfr94qqq/nM/JVaGT7Z5Pe7Q6PR2ZeodhxiIiIqAK1cagDQ20NpGUX4Ep8uthxiIioBmMhX4XaO5qhsaUBcgrk+O1ivNhxiIiIqAJpaUjRuYkFACCEs9cTEVElYiFfhSQSCUZ2eHZXftO5aC5FR0REVMN0fz57/XGuUkNERJWIhXwVG9CyLox0NBD7OBcnb/PXeiIiopqkm5MlpBLgVlIW4p/kih2HiIhqKBbyVUxPSwNDPOsDADacjRY7DhHVMJy/VL3x76f+TPW14GFvCgD46xZ/sCeiysM+Qz1V1N+NhbwIhre1h1QCnLmXhrvJWWLHIaIaQFNTEwCQm8s7gOrsxd/vxd+T1FP3ps/WMD7O5+SJqBLIZDIAQEFBgdhRqBwqqq/nOvIisKujB++mVjh6Mxkbz0Vj/gBXsSMRkZqTyWQwMTFBSsqzwkFPTw8SCZe+UheCICA3NxcpKSkwMTFRfkkj9eTd1BILD93CP/cfITu/CAba/LpFRBVHQ0MDenp6SE1NhaamJqRS3ptVBxXd17NnEcmoDg1w9GYy9kQk4POezjDW490XInoz1tbWAKAs5kn9mJiYKP+OpL4cLQxgb6aHmEe5OHM3Fb2a24gdiYhqEIlEAhsbGzx48AAxMTFix6Eyqqi+noW8SNo2rANna0PcSsrCjguxGNfFUexIRKTmXnTslpaWKCwsFDsOlZGmpibvxNcQEokE3Z2tsP7sAxyPTGEhT0QVTktLC40bN+bwejVTkX09C3mRSCQSjO7QAJ/vvopN56LxYccG0JBxWAwRvTmZTMaCkEhk3k0tsf7sA5y4lQK5QoBMykddiKhiSaVS6OjoiB2DRMLKUUT93G1hpq+Fhxl5OHKD680SERHVFG0a1IGhjgYe5RTgcly62HGIiKiGYSEvIh1NGYa1tQcArD/7QOw4REREVEE0ZVJ0aWIBAPjrFn+sJyKiisVCXmQftK0PTZkE4TFP+Is9ERFRDdK9qSUAIITL0BERUQVjIS8yS0Md+LjZAgDWn+FdeSIiopqiaxNLSCXAraQsxD/JFTsOERHVICzkq4HRHRoAAA5eS0RixlOx4xAREVEFMNXXQmv7OgDvyhMRUQVjIV8NNK9rDM8GdVCkELA5lGtBEhER1RQvhtcfj+Rz8kREVHGqRSG/cuVKODg4QEdHB15eXggLC3tp27Vr16JTp04wNTWFqakpvL29S2wfGRmJfv36wdjYGPr6+mjTpg1iY2Mr+UrK78OOz+7Kbzsfi9yCIrHjEBERUQXo3tQKAHA+6jGy89m/ExFRxRC9kA8ODsa0adMwZ84cREREwM3NDT179kRKSslD0E6ePAk/Pz+cOHECoaGhsLOzQ48ePZCQkKBsc//+fXTs2BHOzs44efIkrl69isDAwGq9zqJ3Uys4mOkh42khdoXHix2HiIiIKoCjhT4czPRQIFfg9J1UseMQEVENIREEQRAzgJeXF9q0aYMVK1YAABQKBezs7DB58mTMnDnztcfL5XKYmppixYoV8Pf3BwAMGTIEmpqa2LJlS7kyZWZmwtjYGBkZGTAyMirXOcpjc2g0Zv9+Aw5megiZ3hUyqaTK3puIiKo3sfqmmqoqP895+29i3ZkHGNiqHr4b7Fap70VEROqrLH2TqHfkCwoKEB4eDm9v7/8PJJXC29sboaGhpTpHbm4uCgsLUafOs8lkFAoFDhw4gCZNmqBnz56wtLSEl5cX9u3b99Jz5OfnIzMzU2UTwyCPejDW1UT0o1yE8Fk6IiKiGuHFc/InbqdArhD1/gkREdUQohbyaWlpkMvlsLKyUtlvZWWFpKSkUp3jiy++gK2trfLHgJSUFGRnZ2PhwoXo1asXjh49igEDBuC9997DqVOnSjxHUFAQjI2NlZudnV0FXF3Z6WlpYKhXfQDAL1yKjoiIqEZo41AHhjoaeJxTgMtxT8SOQ0RENYDoz8i/iYULF2LHjh3Yu3ev8vl3hUIBAOjfvz+mTp0Kd3d3zJw5E++88w7WrFlT4nkCAgKQkZGh3OLi4qr0Ov5tRDsHaEglCHvwGFfj00XLQURERBVDUyZFV6cXs9dzGToiInpzohby5ubmkMlkSE5WHUaenJwMa2vrVx67ZMkSLFy4EEePHkWLFi1UzqmhoQEXFxeV9k2bNn3prPXa2towMjJS2cRibawDHzdbAMAvp3lXnoiIqCbwfj68no/OERFRRRC1kNfS0oKHhwdCQkKU+xQKBUJCQtCuXbuXHrd48WLMmzcPhw8fRuvWrYuds02bNrh9+7bK/jt37sDe3r4SrqLivViK7sC1RCSkPxU7DhEREb2hLk0sIJNKcCc5G3GPc8WOQ0REak70ofXTpk3D2rVrsWnTJkRGRmLChAnIycnBqFGjAAD+/v4ICAhQtl+0aBECAwOxfv16ODg4ICkpCUlJScjOzla2mTFjBoKDg7F27Vrcu3cPK1aswJ9//omPP/5YlGssq+Z1jdHe0QxyhYANfFaeiIhI7ZnoacHD3hTgXXkiIqoAohfyvr6+WLJkCWbPng13d3dcvnwZhw8fVk6AFxsbi8TERGX71atXo6CgAIMGDYKNjY1yW7JkibLNgAEDsGbNGixevBiurq745ZdfsHv3bnTs2FGUayyPsZ0bAgC2h8Ui42mh2HGIiIjoDSmH19/ic/JERPRmRF9HvjqqDmv1CoKAXstO43ZyFgJ6O2NcF0dRchARUfVQHfqmmkSMz/N+aja6f3cKmjIJIgLfhqGOZpW8LxERqQe1WUeeXk4ikWBMp2fPym84G42CIoXYkYiIiOgNOFoYoIG5PgrlAk7fTRM7DhERqTEW8tVYf/e6sDLSRlJmHv688lDsOERERPSGuju/WIaOz8kTEVH5sZCvxrQ0pBjZ/tld+bWno8CnIIiIiNRb96bP5gA6eTsVcgX7dSIiKh8W8tXcUK/60NeS4VZSFk7dSRU7DhEREb2B1g6mMNLRwOOcAlyKfSJ2HCIiUlMs5Ks5Y11NDPGsDwD46VSU2HGIiIjKZeXKlXBwcICOjg68vLwQFhb2yvbLli2Dk5MTdHV1YWdnh6lTpyIvL0/5ulwuR2BgIBo0aABdXV04Ojpi3rx51X70mqZMiq5OL4bXc/Z6IiIqHxbyauDDjg2gIZUgNOoRrsSlix2HiIioTIKDgzFt2jTMmTMHERERcHNzQ8+ePZGSUnIhu23bNsycORNz5sxBZGQk1q1bh+DgYHz55ZfKNosWLcLq1auxYsUKREZGYtGiRVi8eDGWL19ehVdWPt1fLEPH5+SJiKicWMirAVsTXfRztwUA/PT3fbHjEBERlcnSpUvx0UcfYdSoUXBxccGaNWugp6eH9evXl9j+3Llz6NChA4YOHQoHBwf06NEDfn5+Knfxz507h/79+6Nv375wcHDAoEGD0KNHj9fe6a8OujaxhEwqwd2UbMQ+yhU7DhERqSEW8mpiXOdn68gfup6E6LQcseMQERGVSkFBAcLDw+Ht7a3cJ5VK4e3tjdDQ0BKPad++PcLDw5VFeVRUFA4ePIg+ffqotAkJCcGdO3cAAFeuXMGZM2fQu3fvEs+Zn5+PzMxMlU0sxnqaaONgCnD2eiIiKicW8mrCydoQbzlbQhCAn0/zWXkiIlIPaWlpkMvlsLKyUtlvZWWFpKSkEo8ZOnQo5s6di44dO0JTUxOOjo7o2rWrytD6mTNnYsiQIXB2doampiZatmyJKVOmYNiwYSWeMygoCMbGxsrNzs6ugq+0bLo7P/s8Qm6xkCciorJjIa9GxnVuCADYFR6PlKy817YnIiJSRydPnsSCBQuwatUqREREYM+ePThw4ADmzZunbLNz505s3boV27ZtQ0REBDZt2oQlS5Zg06ZNJZ4zICAAGRkZyi0uLq4Kr6i4F8/Jn496jKy8QlGzEBGR+tEQOwCVnmeDOnC3M8HluHRsPBuNz3s5ix2JiIjolczNzSGTyZCcrHrnOTk5GdbW1iUeExgYiOHDh2PMmDEAAFdXV+Tk5GDs2LH43//+B6lUihkzZijvyr9oExMTg6CgIIwYMaLYObW1taGtrV0p11geDS0M0NBcH1FpOfj7Thr6trAROxIREakR3pFXIxKJBOO7PHtWfss/MfwFn4iIqj0tLS14eHggJCREuU+hUCAkJATt2rUr8Zjc3FxIpapfUWQyGQAol5d7WRuFQlEJV1E5OHs9ERGVFwt5NdPDxQqOFvrIyivCr//Eih2HiIjotaZNm4a1a9di06ZNiIyMxIQJE5CTk4NRo0YBAPz9/REQEKBs7+Pjg9WrV2PHjh148OABjh07hsDAQPj4+CgLeh8fH8yfPx8HDhxAdHQ09u7di6VLl2LAgAGiXWdZdW/67Dn5E7dTIFcIYschIiI1wqH1akYqfXZXfsauq1h35gFGdXCAjqZM7FhEREQv5evri9TUVMyePRtJSUlwd3fH4cOHlRPgxcbGqtxdnzVrFiQSCWbNmoWEhARYWFgoC/cXli9fjsDAQHz88cdISUmBra0txo0bh9mzZ4tyjeXR2t4UxrqaeJJbiIjYJ2jjUEfsSEREpCYkwosxaqSUmZkJY2NjZGRkwMjISOw4xRQUKdD12xN4mJGHb95tjg/a2osdiYiIKll175vUTXX5PD/dcQm/X36IcV0aIqB3U9FyEBGR+MrSN3FovRrS0pDio+cz2P/0930UydXneUAiIiL6fy+G14dEpogdhYiI1AgLeTXl28YOpnqaiHv8FAeuJYodh4iIiMqhSxMLaEgluJeSjZhHOWLHISIiNcFCXk3paWlgVIcGAIDVJ++DT0gQERGpH2NdTeWz8cd5V56IiEqJhbwaG9HOAfpaMtxKyuKQPCIiIjXFZeiIiKisWMirMWM9TXzQ7tlEdytO3ONdeSIiIjXk/fw5+bAHj5GZVyh2HCIiUgMs5NXcmI4Noa0hxeW4dJy7/0jsOERERFRGDub6aGihjyKFgFO3U8WOQ0REaoCFvJqzMNTGkDZ2AIAVf90TOw4RERGVw4u78n/d4qNyRET0eizka4CxXRyhIZUgNOoRwmOeiB2HiIiIyqi787Pn5E/cTuGyskRE9Fos5GuAuia6eK9VXQDAyhO8K09ERKRuPOxNYayrifTcQkTEposdh4iIqjkW8jXEhK6NIJU8G5J342GG2HGIiIioDDRkUnRzsgA4ez0REZUCC/kaooG5Pvq2sAX4rDwREZFa6v78OfnjLOSJiOg1WMjXIJPfagQAOHQ9CbeTssSOQ0RERGXQxckCGlIJ7qfmIDotR+w4RERUjbGQr0GaWBmid3Nr4Pm68kRERKQ+jHQ04dmgDsC78kRE9Bos5GuYSc/vyu+/+hD3UrLFjkNERERl8GJ4fUgkl6EjIqKXYyFfwzSzNYZ3UysIArCKd+WJiIjUytvPC/nzDx4hNStf7DhERFRNsZCvgT7p/uyu/O9XHvIZOyIiIjVS30wPbvWMoRCAg9cSxY5DRETVFAv5GqhFPRN0dbKAXCFwXXkiIiI14+P2bBWaP648FDsKERFVUyzka6hPujcGAOy5lIDYR7lixyEiIqJS8nGzhUQChMc8Qdxj9uFERFQcC/kaqlV9U3Ru8uyu/IoTd8WOQ0RERKVkZaSDtg3MAAB/XuVdeSIiKo6FfA326fO78rsjeFeeiIhInfRzfz68/jILeSIiKo6FfA3mYc+78kREROqod3NraMokuJWUhbvJWWLHISKiaoaFfA3Hu/JERETqx0RPC50bWwCc9I6IiErAQr6G4115IiIi9aQcXn/lIQRBEDsOERFVIyzka4F/35WPecR15YmIiNTB2y5W0NWUIeZRLq7EZ4gdh4iIqhEW8rWAh70pujy/K/9jCNeVJyIiUgd6WhrwdrECOOkdERH9Bwv5WmLa200AAHsvxeN+arbYcYiIiKgU+rk9G16//+pDyBUcXk9ERM+wkK8l3OxM4N3UEgoB+DGEz8oTERGpg85NzGGko4GUrHycf/BI7DhERFRNsJCvRaZ4P7sr/8eVh7jDpWyIiIiqPW0NGfq42gAcXk9ERP/CQr4WaV7XGL2aWUMQgGXH74gdh4iIiErhxfD6Q9eTUFCkEDsOERFVAyzka5mpbzeBRAIcvJaEmw8zxY5DREREr+HV0AyWhtrIeFqIv++kih2HiIiqARbytYyTtSHeafHsl/2lx26LHYeIiIheQyaVoG+L58Prr3B4PRERsZCvlaZ4N4ZUAhyPTEFE7BOx4xAREdFr9HevCwA4djMZuQVFYschIiKRsZCvhRwtDDDIox4A4LujvCtPRERU3bnVM4a9mR6eFspx7Gay2HGIiEhkLORrqU+6N4amTIKz9x7h3L00seMQERHRK0gkEvg8fzTuTw6vJyKq9VjI11L1TPUw1LM+AODbo7chCILYkYiIiOgV+rk/K+RP3UlFem6B2HGIiEhELORrsYlvNYKOphSXYtMREpkidhwiIiJ6hSZWhnC2NkShXMDh60lixyEiIhGxkK/FLA11MLJ9AwDAkqO3oVDwrjwREVF19uKu/O+XObyeiKg2YyFfy43v0hCGOhq4lZSFP6/ySwEREVF19uI5+X8ePEJyZp7YcYiISCQs5Gs5Ez0tjO/iCAD47ugdFBQpxI5EREREL2FXRw+t6ptAEID9VxPFjkNERCJhIU8Y1cEB5gbaiH2cix0XYsWOQ0RERK/Qz+3ZXfk/OHs9EVGtxUKeoKelgU+7NwIA/BhyDzn5RWJHIiIiopfo28IWUglwJS4dMY9yxI5DREQiYCFPAADfNvVRv44e0rLzseHsA7HjEBFRDbNy5Uo4ODhAR0cHXl5eCAsLe2X7ZcuWwcnJCbq6urCzs8PUqVORl/f/z4Q7ODhAIpEU2yZOnFgFVyMuC0NtdGhkDgD4g5PeERHVSizkCQCgpSHF9B5NAAA/nYrCkxyuT0tERBUjODgY06ZNw5w5cxAREQE3Nzf07NkTKSklL326bds2zJw5E3PmzEFkZCTWrVuH4OBgfPnll8o2Fy5cQGJionI7duwYAOD999+vsusSk8+/htcLAledISKqbVjIk5JPC1s0tTFCVn4RVpy4J3YcIiKqIZYuXYqPPvoIo0aNgouLC9asWQM9PT2sX7++xPbnzp1Dhw4dMHToUDg4OKBHjx7w8/NTuYtvYWEBa2tr5bZ//344OjqiS5cuJZ4zPz8fmZmZKps669nMGloyKe6mZONWUpbYcYiIqIpVi0K+LMPt1q5di06dOsHU1BSmpqbw9vZ+Zfvx48dDIpFg2bJllZS+5pBKJZjZ2xkAsCU0BnGPc8WOREREaq6goADh4eHw9vZW7pNKpfD29kZoaGiJx7Rv3x7h4eHK/j0qKgoHDx5Enz59Xvoev/76K0aPHg2JRFJim6CgIBgbGys3Ozu7Crk+sRjraqKbswXASe+IiGol0Qv5sg63O3nyJPz8/HDixAmEhobCzs4OPXr0QEJCQrG2e/fuxT///ANbW9squJKaoXNjc3RoZIYCuQLfHb0tdhwiIlJzaWlpkMvlsLKyUtlvZWWFpKSkEo8ZOnQo5s6di44dO0JTUxOOjo7o2rWrytD6f9u3bx/S09MxcuTIl+YICAhARkaGcouLi3vDKxNfP7e6wPPn5Dm8noiodhG9kC/rcLutW7fi448/hru7O5ydnfHLL79AoVAgJCREpV1CQgImT56MrVu3QlNT85UZatpwuzchkUgws1dTAMC+yw9xPSFD7EhERFTLnDx5EgsWLMCqVasQERGBPXv24MCBA5g3b16J7detW4fevXu/8od7bW1tGBkZqWzqrntTS+hryZCQ/hQRsU/EjkNERFVI1EK+PMPt/is3NxeFhYWoU6eOcp9CocDw4cMxY8YMNGvW7LXnqGnD7d6Uaz1j5Rq1iw7fEjsOERGpMXNzc8hkMiQnJ6vsT05OhrW1dYnHBAYGYvjw4RgzZgxcXV0xYMAALFiwAEFBQVAoFCptY2JicPz4cYwZM6ZSr6M60tGUoUezZ58hZ68nIqpdRC3kyzPc7r+++OIL2NraqvwYsGjRImhoaOCTTz4p1Tlq4nC7NzWjpxM0ZRKcvpuGv++kih2HiIjUlJaWFjw8PFRGzr0YSdeuXbsSj8nNzYVUqvoVRSaTAUCxIeQbNmyApaUl+vbtWyn5q7sXP7wfuJaIIrnite2JiKhm0BA7wJtYuHAhduzYgZMnT0JHRwcAEB4ejh9++AEREREvnfDmv7S1taGtrV3JadWLXR09fNDWHhvORmPBwUh0aGQOmbR0nycREdG/TZs2DSNGjEDr1q3h6emJZcuWIScnB6NGjQIA+Pv7o27duggKCgIA+Pj4YOnSpWjZsiW8vLxw7949BAYGwsfHR1nQ4/kPAhs2bMCIESOgoaHWX2nKrWNjc5jqaSItuwChUY/QqbGF2JGIiKgKiNrrlWe43QtLlizBwoULcfz4cbRo0UK5//Tp00hJSUH9+vWV++RyOaZPn45ly5YhOjq6Eq6kZpr8VmPsCo/HraQs7ImIx/uta/cjB0REVD6+vr5ITU3F7NmzkZSUBHd3dxw+fFg5Ii82NlblDvysWbMgkUgwa9YsJCQkwMLCAj4+Ppg/f77KeY8fP47Y2FiMHj26yq+putCUSdHH1QZbz8fi98sPWcgTEdUSEkHkaU69vLzg6emJ5cuXA89/Xa9fvz4mTZqEmTNnlnjM4sWLMX/+fBw5cgRt27ZVee3Ro0dITExU2dezZ08MHz4co0aNgpOT02szZWZmwtjYGBkZGTViMpw38dOp+wg6dAtWRto4+Vk36GrJSnEUERFVNPZNFasmfZ7nox7B9+d/YKitgQuzvKGjyb6aiEgdlaVvEn0cWlmH2y1atAizZ8/Gtm3b4ODgoHyW3sDAAAYGBjAzM4OZmZnKe2hqasLa2rpURTypGtHeAZtDY5CQ/hTrzkRh0luNxY5ERERE/9LGoQ5sjHWQmJGHk7dT0av5q0c1EhGR+hN9+TlfX18sWbIEs2fPhru7Oy5fvlxsuN2/77CvXr0aBQUFGDRoEGxsbJTbkiVLRLyKmktHU4bPez37AWT1yftIzcoXOxIRERH9i1Qqgc/zSe/+vMLZ64mIagPRh9ZXRzVpuF1FUCgEDFh1FlfiMzDUqz4WDHAVOxIRUa3Dvqli1bTP83pCBt5ZfgbaGlKEB74NA23RB10SEVEZlaVvEv2OPFV/UqkE/+vrAgDYERaL20lZYkciIiKif2lma4SG5vrIL1Lg6I3SLeFLRETqi4U8lYpngzro1cwaCgH45sDNYuv4EhERkXgkkv8fXv8Hh9cTEdV4LOSp1AL6OENLJsXpu2k4eTtV7DhERET0L/3cnxXyZ+6m4XFOgdhxiIioErGQp1KzN9PHyA4OAJ7dlS+UK8SORERERM85WhigeV0jFCkEHLyWWIojiIhIXbGQpzKZ9FYj1NHXwv3UHGw7Hyt2HCIiIvqXfi+G11/m8HoiopqMhTyViZGOJqa+3QQA8P3xO8jILRQ7EhERET33TotnhXxY9GM8TH8qdhwiIqokLOSpzPza2KGJlQHScwuxLOSO2HGIiIjoOVsTXXg61AEA7L/Ku/JERDUVC3kqMw2ZFIHvPFuObnNoDO4mczk6IiKi6uLFpHecvZ6IqOZiIU/l0qmxBd52sYJcIWDufi5HR0REVF30cbWBhlSC6wmZuJ+aLXYcIiKqBCzkqdz+16epcjm6kMgUseMQERERgDr6WujY2BzgpHdERDUWC3kqNwdzfYzu2AB4vhxdfpFc7EhERET0r9nr/7zykKPmiIhqIBby9EYmvdUIFobaiH6Uiw1no8WOQ0RERAB6NLOGtoYUUWk5uPEwU+w4RERUwVjI0xsx0NbAF72cAQDLQ+4iOTNP7EhERES1noG2BrybWgGc9I6IqEZiIU9v7L2WddGyvglyCuQIOhgpdhwiIiIC4PN8eP0flx9CoeDweiKimoSFPL0xqVSCuf2aQyIB9l1+iLAHj8WOREREVOt1dbKAoY4GkjLzcOZemthxiIioArGQpwrhWs8YQ9rUBwDM/v06iuQKsSMRERHVajqaMgxsVQ8A8Os/MWLHISKiCsRCnirMjJ5OMNbVxK2kLGwLixU7DhERUa03zOvZj+wht1KQmPFU7DhERFRBWMhThamjr4XPejQBACw5chuPsvPFjkRERFSrNbYyhGeDOpArBARfiBM7DhERVRAW8lShhnrZw8XGCJl5RVh46JbYcYiIiGq9F3fld4TF8dE3IqIagoU8VSiZVIJ57zYHAPwWHo+L0Zz4joiISEy9mlvDTF8LSZl5CLmVInYcIiKqACzkqcJ52JticOtnk+sE/n6Dv/4TERGJSFtDhvdb2wGc9I6IqMZgIU+V4otezjDW1URkYia28EsDERGRqIZ61odEApy+m4aYRzlixyEiojfEQp4qhZmBNmb0dAIALD16BymZeWJHIiIiqrXqm+mhc2MLAMC281xZhohI3bGQp0rj51kfLeoZIyu/CN8ciBQ7DhERUa32YtK7nRfjkF8kFzsOERG9ARbyVGlkUgnmv+sKqQT448pDnL6bKnYkIiKiWustZ0vYGOvgSW4hDl9PEjsOERG9ARbyVKlc6xnDv50DACBw33XkFfIOABERkRg0ZFIMafPsrjwnvSMiUm8s5KnSTe/RBJaG2oh+lItVJ++LHYeIiKjWGuJpB5lUggvRT3A7KUvsOEREVE4s5KnSGepoYo5PMwDAmpP3cT81W+xIREREtZKVkQ7ebmoFANh6nnfliYjUFQt5qhJ9XK3R1ckCBXIFZu29DkEQxI5ERERUK33Q1h4AsCciATn5RWLHISKicmAhT1VCIpFgbr/m0NGUIjTqEXaFx4sdiYiIqFZq72gGBzM9ZOcX4c8rD8WOQ0RE5cBCnqpMfTM9TPVuAgCYfzASj7LzxY5ERERU60ilEgx9vhTdr+djOEqOiEgNsZCnKvVhxwZwsTFCem4h15YnIiISySAPO2hpSHE9IRNX4zPEjkNERGXEQp6qlIZMiqD3nq0tv/dSAv6+w7XliYiIqlodfS30dbUBuBQdEZFaYiFPVc7NzgQj2j9bW/5/+67haQHXliciIqpqH7R9Nrz+z6sPkZFbKHYcIiIqAxbyJIrpPZxga6yDuMdPsfTYbbHjEBER1Tqt6pvC2doQeYUK7I7gJLREROqEhTyJwkBbA/MHuAIA1p15gCtx6WJHIiIiqlUkEgmGPZ/0bisnvSMiUiss5Ek03Zwt8a67LRQC8MXuqygoUogdiYiIqFZ5t2Vd6GnJcD81B+cfPBY7DhERlRILeRLVbJ9mqKOvhVtJWVhz6r7YcYiIiGoVQx1N9HevC3DSOyIitcJCnkRVR18Lc3xcAADL/7qLu8lZYkciIqJKsHLlSjg4OEBHRwdeXl4ICwt7Zftly5bByckJurq6sLOzw9SpU5GXl6fSJiEhAR988AHMzMygq6sLV1dXXLx4sZKvpOZ5Mbz+yI0kpGblix2HiIhKgYU8ia6fmy26O1uiUC5gxq6rkCv4jB4RUU0SHByMadOmYc6cOYiIiICbmxt69uyJlJSUEttv27YNM2fOxJw5cxAZGYl169YhODgYX375pbLNkydP0KFDB2hqauLQoUO4efMmvvvuO5iamlbhldUMzesaw93OBIVyATsvxokdh4iISoGFPIlOIpHgmwHNYaitgctx6Vh3JkrsSEREVIGWLl2Kjz76CKNGjYKLiwvWrFkDPT09rF+/vsT2586dQ4cOHTB06FA4ODigR48e8PPzU7mLv2jRItjZ2WHDhg3w9PREgwYN0KNHDzg6OpZ4zvz8fGRmZqps9P8+aGsPANgeFssf1ImI1AALeaoWbIx1MeudpgCA747ewf3UbLEjERFRBSgoKEB4eDi8vb2V+6RSKby9vREaGlriMe3bt0d4eLiycI+KisLBgwfRp08fZZs//vgDrVu3xvvvvw9LS0u0bNkSa9eufWmOoKAgGBsbKzc7O7sKvU51904LGxjpaCD+yVP8fTdV7DhERPQaLOSp2hjc2g6dGpsjv0iBzznEnoioRkhLS4NcLoeVlZXKfisrKyQlJZV4zNChQzF37lx07NgRmpqacHR0RNeuXVWG1kdFRWH16tVo3Lgxjhw5ggkTJuCTTz7Bpk2bSjxnQEAAMjIylFtcHIeQ/5uOpgyDPJ79uLGVk94REVV7LOSp2pBIJFg4sAUMtDUQHvMEG89Fix2JiIhEcPLkSSxYsACrVq1CREQE9uzZgwMHDmDevHnKNgqFAq1atcKCBQvQsmVLjB07Fh999BHWrFlT4jm1tbVhZGSkspGqYW2fTXr3160UJKQ/FTsOERG9Agt5qlbqmugioI8zAODbI7cQxSH2RERqzdzcHDKZDMnJySr7k5OTYW1tXeIxgYGBGD58OMaMGQNXV1cMGDAACxYsQFBQEBQKBQDAxsYGLi4uKsc1bdoUsbGxlXg1NZujhQHaNTSDQgB2hPFzJCKqzljIU7Uz1LM+OjYyR16hAp/9doVD7ImI1JiWlhY8PDwQEhKi3KdQKBASEoJ27dqVeExubi6kUtWvKDKZDAAgCM/6hA4dOuD27dsqbe7cuQN7e/tKuIra48WkdzsuxKFQrhA7DhERvQQLeap2JBIJFg1qAUNtDUTEpmPtac5iT0SkzqZNm4a1a9di06ZNiIyMxIQJE5CTk4NRo0YBAPz9/REQEKBs7+Pjg9WrV2PHjh148OABjh07hsDAQPj4+CgL+qlTp+Kff/7BggULcO/ePWzbtg0///wzJk6cKNp11gRvu1jB3EAbqVn5OHYzuRRHEBGRGDTEDkBUkromugj0ccHnu65i6dE7eMvZEk2sDMWORURE5eDr64vU1FTMnj0bSUlJcHd3x+HDh5UT4MXGxqrcgZ81axYkEglmzZqFhIQEWFhYwMfHB/Pnz1e2adOmDfbu3YuAgADMnTsXDRo0wLJlyzBs2DBRrrGm0NKQwrdNPaw8cR9bz8egj6uN2JGIiKgEEuHFGDVSyszMhLGxMTIyMjgZjogEQcCYTRcRcisFzesaYe/HHaAp4yASIqqd2DdVLH6eLxf/JBedFp+AIAB/Te+ChhYGYkciIqoVytI3sSqiaksikSDoPVcY62riekImVvx1T+xIRERENV49Uz10c7IEAGw7z0nviIiqIxbyVK1ZGulg3rvNAQArTtzD5bh0sSMRERHVeB88X4puV0Q88grlYschIqL/YCFP1V4/N1v4uNlCrhAwLfgynhbwCwUREVFl6tLEEnVNdJGeW4gDVxPFjkNERP/BQp7Uwrz+zWBlpI2otBwEHYoUOw4REVGNJpNK4OdpBwDYej5G7DhERPQfLORJLZjoaeHbQW4AgM2hMTh1J1XsSERERDXa4DZ20JBKEBGbjpsPM8WOQ0RE/8JCntRG5yYW8G9nDwCY8dsVPM4pEDsSERFRjWVpqIOezawB3pUnIqp2WMiTWgno3RSOFvpIycpHwJ6r4OqJRERElWfY80nv9l1KQHZ+kdhxiIjoORbypFZ0tWT4YUhLaMokOHIjGTsvxokdiYiIqMZq19AMDS30kVMgx75LCWLHISKi51jIk9ppXtcY03s4AQC+/vMmHqTliB2JiIioRpJIJBjm9eyxtq3nYzkSjoiomqgWhfzKlSvh4OAAHR0deHl5ISws7KVt165di06dOsHU1BSmpqbw9vZWaV9YWIgvvvgCrq6u0NfXh62tLfz9/fHw4cMquhqqCmM7NUS7hmbILZBjyo5LKJQrxI5ERERUIw1sVRfaGlJEJmbiUly62HGIiKi8hXxcXBzi4+OV/w4LC8OUKVPw888/l/lcwcHBmDZtGubMmYOIiAi4ubmhZ8+eSElJKbH9yZMn4efnhxMnTiA0NBR2dnbo0aMHEhKeDffKzc1FREQEAgMDERERgT179uD27dvo169feS6VqimpVILvBrvBSEcDV+IzsPTYHbEjERHVOBXZ35P6MtHTwjstbAEAv/7DSe+IiKoDiVCOMVKdOnXC2LFjMXz4cCQlJcHJyQnNmjXD3bt3MXnyZMyePbvU5/Ly8kKbNm2wYsUKAIBCoYCdnR0mT56MmTNnvvZ4uVwOU1NTrFixAv7+/iW2uXDhAjw9PRETE4P69eu/9pyZmZkwNjZGRkYGjIyMSn0tVPUOXUvEhK0RkEiAXz/0QodG5mJHIiKqFGL0TRXZ31c37OvL5lLsEwxYdQ5aGlKcD+gOU30tsSMREdU4ZembynVH/vr16/D09AQA7Ny5E82bN8e5c+ewdetWbNy4sdTnKSgoQHh4OLy9vf8/kFQKb29vhIaGluocubm5KCwsRJ06dV7aJiMjAxKJBCYmJiW+np+fj8zMTJWN1ENvVxv4edaHIABTgy/jUXa+2JGIiGqMiurvSf2525nAxcYIBUUKLkVHRFQNlKuQLywshLa2NgDg+PHjymHrzs7OSExMLPV50tLSIJfLYWVlpbLfysoKSUlJpTrHF198AVtbW5UfA/4tLy8PX3zxBfz8/F76q0ZQUBCMjY2Vm52dXamvgcQ3+x0XNLI0QEpWPmbs4pJ0REQVpaL6e1J/EokE47o0BACsO/MAOVyKjohIVOUq5Js1a4Y1a9bg9OnTOHbsGHr16gUAePjwIczMzCo640stXLgQO3bswN69e6Gjo1Ps9cLCQgwePBiCIGD16tUvPU9AQAAyMjKUW1wclzRTJ7paMiz3awktDSn+upWCDWejxY5ERFQjVJf+nqqHvq42sDfTw5PcQmwPixU7DhFRrVauQn7RokX46aef0LVrV/j5+cHNzQ0A8McffyiH4JWGubk5ZDIZkpOTVfYnJyfD2tr6lccuWbIECxcuxNGjR9GiRYtir78o4mNiYnDs2LFXPmOgra0NIyMjlY3US1MbI/yvT1MAQNChSFyN56y6RERvqqL6e6oZNGRSfNzVEQDw899RyCuUix2JiKjWKtdkd3g+yVxmZiZMTU2V+6Kjo6GnpwdLS8tSn8fLywuenp5Yvnw58Hyyu/r162PSpEkvnexu8eLFmD9/Po4cOYK2bdsWe/1FEX/37l2cOHECFhYWZbo2ToCjngRBwPhfw3HkRjLszfSwf3JHGOpoih2LiKhCiNU3VVR/X92wry+fgiIFun57Ag8z8jDv3eYY3tZe7EhERDVGpU929/TpU+Tn5ys79ZiYGCxbtgy3b98uc6c+bdo0rF27Fps2bUJkZCQmTJiAnJwcjBo1CgDg7++PgIAAZftFixYhMDAQ69evh4ODA5KSkpCUlITs7GzgeRE/aNAgXLx4EVu3boVcLle2KSgoKM/lkpqQSCRYPNANdU10EfMoFwF7rvF5eSKiN1CR/T3VDFoaUozt/OxZ+TUn76NQrhA7EhFRrVSuQr5///7YvHkzACA9PR1eXl747rvv8O67777yWfSS+Pr6YsmSJZg9ezbc3d1x+fJlHD58WDkBXmxsrMqEOqtXr0ZBQQEGDRoEGxsb5bZkyRIAQEJCAv744w/Ex8fD3d1dpc25c+fKc7mkRoz1NLF8aEtoSCXYfzUR28M43wERUXlVZH9PNccQz/owN9BCQvpT/H75odhxiIhqpXIV8hEREejUqRMAYNeuXbCyskJMTAw2b96MH3/8scznmzRpEmJiYpCfn4/z58/Dy8tL+drJkydVlriJjo6GIAjFtq+++goA4ODgUOLrgiCga9eu5blcUjOt6pvis55OAICv/ryBGw8zxI5ERKSWKrq/p5pBR1OGMZ2e3ZVfdeIe5AqOfiMiqmrlKuRzc3NhaGgIADh69Cjee+89SKVStG3bFjExXFuUxDe2U0N0c7JAQZECE7dGICuvUOxIRERqh/09vcwHbe1hrKuJqLQcHLrOpQiJiKpauQr5Ro0aYd++fYiLi8ORI0fQo0cPAEBKSgonjKFqQSqVYOlgd9Q10UX0o1zM3M3n5YmIyor9Pb2MgbYGRnVwAACs+Ose+1gioipWrkJ+9uzZ+Oyzz+Dg4ABPT0+0a9cOeP5rfcuWLSs6I1G5mOprYcXQltCUSXDgWiI2neP68kREZcH+nl5lZHsH6GvJcCspCyGRKWLHISKqVcq9/FxSUhISExPh5uYGqfTZ7wFhYWEwMjKCs7NzReesUlySpmZZf+YB5u6/CU2ZBDvHtUPL+qalOIqIqHoRq2+qqf09+/qKEXQoEj+dioK7nQn2ftweEolE7EhERGqr0pefAwBra2u0bNkSDx8+RHx8PADA09NTrTt1qplGdXBA7+bWKJQL+HhrBB5l54sdiYhIbbC/p1cZ07EhtDWkuByXjnP3H4kdh4io1ihXIa9QKDB37lwYGxvD3t4e9vb2MDExwbx586BQcD1Rql4kEgkWD2qBhhb6SMzIw6c7LnOGXSKiUmB/T69jYagNP8/6AIDlf90VOw4RUa1RrkL+f//7H1asWIGFCxfi0qVLuHTpEhYsWIDly5cjMDCw4lMSvSFDHU2s+cADupoynLmXhu+P3RE7EhFRtcf+nkpjbOeG0JRJ8E/UY4THPBY7DhFRrVCuZ+RtbW2xZs0a9OvXT2X/77//jo8//hgJCQkVmbHK8bm5muv3ywn4dMdlAMAv/q3h7WIldiQiolIRo2+qyf09+/qKNXP3Vey4EIduThbYMMpT7DhERGqp0p+Rf/z4cYnPxjk7O+PxY/4SS9VXf/e6GNn+2XI5U4MvIyo1W+xIRETVFvt7Kq3xXRwhlQAnbqfiekKG2HGIiGq8chXybm5uWLFiRbH9K1asQIsWLSoiF1Gl+V/fpmjjYIqs/CKM2xKO7PwisSMREVVL7O+ptBzM9eHjZgsAWHninthxiIhqPI3yHLR48WL07dsXx48fV64pGxoairi4OBw8eLCiMxJVKE2ZFCuHtYLP8jO4m5KNGb9dwaphrbhkDhHRf7C/p7L4uGsj/H75IQ7fSMK9lCw0sjQUOxIRUY1VrjvyXbp0wZ07dzBgwACkp6cjPT0d7733Hm7cuIEtW7ZUfEqiCmZpqINVwzygKZPg0PUkrDp5X+xIRETVDvt7Kgsna0P0bGYFQQBWnWC/SkRUmco12d3LXLlyBa1atYJcLq+oU4qCE+DUHlvPx+B/e69DIgHWj2iDbs6WYkciIipRdeqbakJ/X50+z5rkWnwGfFacgUwqwYnpXVHfTE/sSEREaqPSJ7sjqimGetaHn2d9CALwyfZLuM/J74iIiMrNtZ4xOjexgFwhYPUp3pUnIqosLOSpVpNIJPi6XzO0tn82+d1Hmy4i42mh2LGIiIjU1uS3GgEAdofHIzHjqdhxiIhqJBbyVOtpaUix+gMP2BjrICotB1N2XIJcUWFPnBAREdUqbRzqwLNBHRTIFfj57yix4xAR1UhlmrX+vffee+Xr6enpb5qHSBQWhtr4eXhrDFpzDidup2Lx4VsI6NNU7FhERKJgf09valK3RvB/EIbtYbGY2K0RzA20xY5ERFSjlKmQNzY2fu3r/v7+b5qJSBSu9Yzx7ftu+GT7Jfz0dxQaWRrg/dZ2YsciIqpy7O/pTXVqbA63esa4Ep+B9Wce4PNezmJHIiKqUSp01vqagjPZ1m7fHb2N5X/dg5ZMim0feaG1Qx2xIxERsW+qYPw8K9/RG0kYuyUcBtoaOPvFWzDW0xQ7EhFRtcZZ64newFTvJujd3BoFcgXGbQlH3ONcsSMRERGpHe+mVnCyMkR2fhE2hUaLHYeIqEZhIU/0H1KpBN8NdoOLjREe5RRgzKaLyMrjTPZERG9i5cqVcHBwgI6ODry8vBAWFvbK9suWLYOTkxN0dXVhZ2eHqVOnIi8vT/n6V199BYlEorI5O3P4dnUilUow8fkM9uvPPkBOfpHYkYiIagwW8kQl0NPSwC8jWsPCUBu3k7MwadslFMkVYsciIlJLwcHBmDZtGubMmYOIiAi4ubmhZ8+eSElJKbH9tm3bMHPmTMyZMweRkZFYt24dgoOD8eWXX6q0a9asGRITE5XbmTNnquiKqLT6utqggbk+0nMLsfV8jNhxiIhqDBbyRC9ha6KLX/xbQ0dTilN3UjFv/02xIxERqaWlS5fio48+wqhRo+Di4oI1a9ZAT08P69evL7H9uXPn0KFDBwwdOhQODg7o0aMH/Pz8it3F19DQgLW1tXIzNzevoiui0pJJJZjQxREAsPb0A+QVysWORERUI7CQJ3oFNzsTLPN1BwBsCo3BhrMPxI5ERKRWCgoKEB4eDm9vb+U+qVQKb29vhIaGlnhM+/btER4erizco6KicPDgQfTp00el3d27d2Fra4uGDRti2LBhiI2NfWmO/Px8ZGZmqmxUNd5tWRd1TXSRmpWP3y7GiR2HiKhGYCFP9Bq9mttgZu9nz13O238Tx28mix2JiEhtpKWlQS6Xw8rKSmW/lZUVkpKSSjxm6NChmDt3Ljp27AhNTU04Ojqia9euKkPrvby8sHHjRhw+fBirV6/GgwcP0KlTJ2RlZZV4zqCgIBgbGys3OzsuL1pVtDSkGNelIQBgzakoFPJRNSKiN8ZCnqgUxnVuiCFt7KAQgMnbL+FqfLrYkYiIaqyTJ09iwYIFWLVqFSIiIrBnzx4cOHAA8+bNU7bp3bs33n//fbRo0QI9e/bEwYMHkZ6ejp07d5Z4zoCAAGRkZCi3uDjeGa5Kg1vbwdxAGwnpT7H3UoLYcYiI1B4LeaJSkEgkmPduc3RuYoGnhXKM3niRy9IREZWCubk5ZDIZkpNVRzMlJyfD2tq6xGMCAwMxfPhwjBkzBq6urhgwYAAWLFiAoKAgKBQl3801MTFBkyZNcO/evRJf19bWhpGRkcpGVUdHU4axnRsAAFafvA+5QhA7EhGRWmMhT1RKmjIpVg5tCWdrQ6Rl52PkhjBk5HJZOiKiV9HS0oKHhwdCQkKU+xQKBUJCQtCuXbsSj8nNzYVUqvoVRSaTAQAEoeQCMDs7G/fv34eNjU2F5qeKM8zLHiZ6mniQloMD1xLFjkNEpNZYyBOVgaGOJjaMagNrIx3cT83BR5svcgZeIqLXmDZtGtauXYtNmzYhMjISEyZMQE5ODkaNGgUA8Pf3R0BAgLK9j48PVq9ejR07duDBgwc4duwYAgMD4ePjoyzoP/vsM5w6dQrR0dE4d+4cBgwYAJlMBj8/P9Guk15NX1sDo9o/uyu/6sQ9KHhXnoio3DTEDkCkbmyMdbFhVBsMXhOKsOjHmLbzMpb7tYJMKhE7GhFRteTr64vU1FTMnj0bSUlJcHd3x+HDh5UT4MXGxqrcgZ81axYkEglmzZqFhIQEWFhYwMfHB/Pnz1e2iY+Ph5+fHx49egQLCwt07NgR//zzDywsLES5Riqdke0dsPZ0FG4lZSHkVgredrEqxVFERPRfEuFlY9RqsczMTBgbGyMjI4PP0NFLnbufhhHrw1AoFzCyvQPm+LhAImExT0SVg31TxeLnKZ5Fh29h9cn7cKtnjH0TO7DvJCJ6rix9E4fWE5VTe0dzfDf42RrzG89F46e/o8SOREREVO192LEBdDSluBKfgdN308SOQ0SklljIE72Bfm62mNW3KQBg4aFb2BUeL3YkIiKias3cQBt+nvWB530nZ7AnIio7FvJEb2hMp4b4qNOzyXu+2H0VIZHJrz2GiIioNpvUrREMdTRwMzETv12MEzsOEZHaYSFPVAECejfFey3rQq4Q8PHWCFyMfix2JCIiomrLzEAbn3ZvDABYcvQ2svK4nCsRUVmwkCeqAFKpBIsGtUA3JwvkFykweuMFRCZmih2LiIio2vJv54CG5vpIyy7Air/uiR2HiEitsJAnqiCaMilWDmuFVvVNkJlXBP/1YYhOyxE7FhERUbWkpSHFrHeezTOz/uwDPGCfSURUaizkiSqQnpYGNoz0hLO1IVKz8vHBuvNIysgTOxYREVG11M3JEl2aWKBQLmD+gUix4xARqQ0W8kQVzFhPE5s/9IS9mR7inzzF8HXn8SSnQOxYRERE1Y5EIkHgO00hk0pwPDIZZ7gcHRFRqbCQJ6oEloY6+PVDL1gZaeNuSjb814chkxP5EBERFdPI0hDD29oDAObuv4EiuULsSERE1R4LeaJKYldHD1vHeKGOvhauJWTgw40XkFtQJHYsIiKiameKd2OY6GniTnI2tofFih2HiKjaYyFPVIkaWRpi82hPGOpo4EL0E4zbEo68QrnYsYiIiKoVEz0tTH+7CQBg6bE7SM/lI2lERK/CQp6okjWva4yNozyhpyXD6btpmLQtAgVFHDZIRET0b36e9eFkZYgnuYVYdvyu2HGIiKo1FvJEVcDD3hS/jGgNbQ0pjkem4NMdl/gMIBER0b9oyKQIfMcFALDlnxjcS8kSOxIRUbXFQp6oirR3NMdPwz2gJZPi0PUkTN15BXKFIHYsIiKiaqNjY3N4N7WCXCFg3n4uR0dE9DIs5ImqUFcnS6z+oBU0ZRL8eeUhZuxiMU9ERPRvs/o2haZMglN3UnHiVorYcYiIqiUW8kRVrHtTKyz3awWZVII9EQmYufsqFCzmiYiIAAAO5voY3aEBAGDegZucV4aIqAQs5IlE0Ku5NX4c0hIyqQS/hcfjCxbzRERESpPeagRzAy1EpeZgc2i02HGIiKodFvJEIunbwgY/DHFnMU9ERPQfhjqa+KyHEwDgh5C7eJSdL3YkIqJqhYU8kYjeaWGLZb7/X8zP2HWVz8wTEREBeL+1HZrZGiErrwhLj90ROw4RUbXCQp5IZD5u/1/M746Ix/Sdl7k0HRER1XoyqQRzfJoBALaHxSIyMVPsSERE1QYLeaJqwMfNFsv9WkJDKsG+yw8xJfgyClnMExFRLefZoA76utpAIQBz/7wJQeCoNSIisJAnqj76uNpg5bBnS9Ptv5qISdsiOFMvERHVejN7O0NLQ4rQqEc4ciNZ7DhERNUCC3miaqRnM2us+cADWjIpjtxIxrgtF5FXKBc7FhERkWjs6uhhbKeGAIAFByORX8R+kYiIhTxRNdO9qRV+GdEaOppSnLiditEbLyAnv0jsWERERKKZ0NURVkbaiH2ci/VnuBwdERELeaJqqHMTC2wa5Ql9LRnO3X8E//VhyHhaKHYsIiIiUehra+CLXs4AgBV/3UVKVp7YkYiIRMVCnqia8mpohq0ftYWRjgbCY57A7+d/kMZ1dImIqJZ6170u3OxMkFMgx7eHb4sdh4hIVCzkiaoxdzsT7BjbDuYGWriZmInBa0KRkP5U7FhERERVTiqVYI6PCwBgV0Q8rsVniB2JiEg0LOSJqjkXWyPsHNcOdU10EZWWg/dXn0NUarbYsYiIiKpcq/qmGNCyLgQB+PrPG1yOjohqrWpRyK9cuRIODg7Q0dGBl5cXwsLCXtp27dq16NSpE0xNTWFqagpvb+9i7QVBwOzZs2FjYwNdXV14e3vj7t27VXAlRJWjoYUBfhvfDg0t9PEwIw/vrwnlnQgiIqqVvujlDF1NGS7GPMH+q4lixyEiEoXohXxwcDCmTZuGOXPmICIiAm5ubujZsydSUlJKbH/y5En4+fnhxIkTCA0NhZ2dHXr06IGEhARlm8WLF+PHH3/EmjVrcP78eejr66Nnz57Iy+PEKKS+bE10sXNcOzSva4RHOQXwW/sPzt1LEzsWERFRlbI21sGEro4AgIWHbuFpAZejI6LaRyKIPCbJy8sLbdq0wYoVKwAACoUCdnZ2mDx5MmbOnPna4+VyOUxNTbFixQr4+/tDEATY2tpi+vTp+OyzzwAAGRkZsLKywsaNGzFkyJDXnjMzMxPGxsbIyMiAkZFRBVwlUcXJyivE2M3hCI16BC2ZFD8McUdvVxuxYxFRJWPfVLH4eaq3vEI5un93CgnpTzHVuwk+9W4sdiQiojdWlr5J1DvyBQUFCA8Ph7e39/8Hkkrh7e2N0NDQUp0jNzcXhYWFqFOnDgDgwYMHSEpKUjmnsbExvLy8XnrO/Px8ZGZmqmxE1ZWhjiY2jGqDXs2sUSBX4ONtEdjyT4zYsYiIiKqMjqYMAX2eLUe35tR9JGZwIlgiql1ELeTT0tIgl8thZWWlst/KygpJSUmlOscXX3wBW1tbZeH+4riynDMoKAjGxsbKzc7OrpxXRFQ1dDRlWDmsFYZ61YcgAIH7rmPJkduc9IeIiGqNvq428HSog6eFciw6dEvsOEREVUr0Z+TfxMKFC7Fjxw7s3bsXOjo65T5PQEAAMjIylFtcXFyF5iSqDDKpBPPfbY6p3k0AACtO3MPnu66iUK4QOxoREVGlk0gkmO3jAokE2Hf5ISJin4gdiYioyohayJubm0MmkyE5OVllf3JyMqytrV957JIlS7Bw4UIcPXoULVq0UO5/cVxZzqmtrQ0jIyOVjUgdSCQSfOrdGAvfc4VUAvwWHo8xmy4iO79I7GhERESVrnldY7zvUQ8A8L+915FfxInviKh2ELWQ19LSgoeHB0JCQpT7FAoFQkJC0K5du5cet3jxYsybNw+HDx9G69atVV5r0KABrK2tVc6ZmZmJ8+fPv/KcROpsiGd9rPVvDV1NGU7dScXgNaFIzuQqDUREVPPN6OmMOvpaiEzMxLLjXG6YiGoH0YfWT5s2DWvXrsWmTZsQGRmJCRMmICcnB6NGjQIA+Pv7IyAgQNl+0aJFCAwMxPr16+Hg4ICkpCQkJSUhOzsbeH6HcsqUKfjmm2/wxx9/4Nq1a/D394etrS3effdd0a6TqLJ1b2qFHWPbwtxACzcTMzFg5VncSc4SOxYREVGlsjDUxoIBrsDzie8uRD8WOxIRUaUTvZD39fXFkiVLMHv2bLi7u+Py5cs4fPiwcrK62NhYJCYmKtuvXr0aBQUFGDRoEGxsbJTbkiVLlG0+//xzTJ48GWPHjkWbNm2QnZ2Nw4cPv9Fz9ETqwM3OBHs/7oCGFvp4mJGHgavO4cxdrjVPREQ1W6/m1njfox4EAZgafBlZeYViRyIiqlSiryNfHXFtWVJ3T3IKMG5LOMKiH0MmleCbd5vDz7O+2LGI6A2wb6pY/Dxrnqy8QvT+4TTinzzF4Nb1sHiQm9iRiIjKRG3WkSeiymGqr4UtYzzxrrst5AoBAXuuIehgJBQK/m5HREQ1k6GOJpYOdodEAuy8GI+jN0q3lDERkTpiIU9UQ2lryPC9rzumeDcGAPz0dxTG/xqOHM5oT0RENZRngzoY19kRABCw5xpSs/LFjkREVClYyBPVYBKJBFO8m2CZrzu0ZFIcvZmM99eE4mH6U7GjEVEts3LlSjg4OEBHRwdeXl4ICwt7Zftly5bByckJurq6sLOzw9SpU5GXV/JqHAsXLlROdks09e3GaGpjhEc5BQjYcxV8ipSIaiIW8kS1wLst62L7v2a077fiLC7FPhE7FhHVEsHBwZg2bRrmzJmDiIgIuLm5oWfPnkhJSSmx/bZt2zBz5kzMmTMHkZGRWLduHYKDg/Hll18Wa3vhwgX89NNPaNGiRRVcCakDbQ2Z8gfs45EpCL4QJ3YkIqIKx0KeqJbwsDfFvokd4GxtiLTsfPj+/A/2RMSLHYuIaoGlS5fio48+wqhRo+Di4oI1a9ZAT08P69evL7H9uXPn0KFDBwwdOhQODg7o0aMH/Pz8it3Fz87OxrBhw7B27VqYmppW0dWQOnCyNsSMnk4AgLn7byLmUY7YkYiIKhQLeaJapJ6pHnZNaI+3XaxQUKTAtJ1XEHQwEnJOgkdElaSgoADh4eHw9vZW7pNKpfD29kZoaGiJx7Rv3x7h4eHKwj0qKgoHDx5Enz59VNpNnDgRffv2VTn3y+Tn5yMzM1Nlo5rtw44N0LZhHeQWyDE1+DKK5AqxIxERVRgW8kS1jIG2Bn76wAOT32oEPJ8Eb/TGC8jI5Zq7RFTx0tLSIJfLYWVlpbLfysoKSUklzyo+dOhQzJ07Fx07doSmpiYcHR3RtWtXlaH1O3bsQEREBIKCgkqVIygoCMbGxsrNzs7uDa+MqjupVIIl77vBUFsDEbHp+OnvKLEjERFVGBbyRLWQVCrB9B5OWO7XEjqaUpy6k4r+K8/gTnKW2NGIiHDy5EksWLAAq1atQkREBPbs2YMDBw5g3rx5AIC4uDh8+umn2Lp1K3R0dEp1zoCAAGRkZCi3uDg+N10b1DPVw9f9mwEAvj92B9cTMsSORERUIVjIE9ViPm622DW+Peqa6CL6US7eXXkWh68nih2LiGoQc3NzyGQyJCcnq+xPTk6GtbV1iccEBgZi+PDhGDNmDFxdXTFgwAAsWLAAQUFBUCgUCA8PR0pKClq1agUNDQ1oaGjg1KlT+PHHH6GhoQG5XF7snNra2jAyMlLZqHYY0LIu+rhao0ghYErwZeQVFv/vBxGRumEhT1TLNa9rjD8nd0R7RzPkFsgx/tcILDp8i8/NE1GF0NLSgoeHB0JCQpT7FAoFQkJC0K5duxKPyc3NhVSq+hVFJpMBAARBQPfu3XHt2jVcvnxZubVu3RrDhg3D5cuXlW2J8Hwp1vnvusLSUBv3UrKx6PAtsSMREb0xFvJEhDr6Wtg82hMfdmwAAFh98j5GrA/D45wCsaMRUQ0wbdo0rF27Fps2bUJkZCQmTJiAnJwcjBo1CgDg7++PgIAAZXsfHx+sXr0aO3bswIMHD3Ds2DEEBgbCx8cHMpkMhoaGaN68ucqmr68PMzMzNG/eXMQrperKVF8Liwc9W6Jww9lonLmbJnYkIqI3oiF2ACKqHjRkUgS+4wI3OxN8sesqztxLg8/yM1g1rBXc7EzEjkdEaszX1xepqamYPXs2kpKS4O7ujsOHDysnwIuNjVW5Az9r1ixIJBLMmjULCQkJsLCwgI+PD+bPny/iVZC66+pkieFt7bHlnxh89tsVHJnSGcZ6mmLHIiIqF4kgCBw/+x+ZmZkwNjZGRkYGn6GjWul2UhbG/xqOB2k50JJJEejjgg+86kMikYgdjajWYt9Usfh51k65BUV458cziErLQT83W/zo11LsSERESmXpmzi0noiKcbI2xO+TOjxbb16uQOC+65gafBm5BUViRyMiIio3PS0NLPV1h0wqwR9XHuL3ywliRyIiKhcW8kRUIiMdTfw83ANf9nGGTCrBvssP0X/FWdzlEnVERKTG3O1MMPmtRgCAwH3XkZjxVOxIRERlxkKeiF5KIpFgbGdHbP+oLSwNtXE3JRv9VpzF7vB4saMRERGV28RujeBmZ4LMvCJ89tsVKLhSCxGpGRbyRPRang3q4MAnndChkRmeFsox/bcr+HzXFTwt4Fq8RESkfjRlUnw/2A06mlKcvfcIm0KjxY5ERFQmLOSJqFQsDLWxebQXpno3gUQC7LwYj34rzuB2EofaExGR+mloYYD/9XUBACw8dIuPjhGRWmEhT0SlJpNK8Kl3Y2wd4wUL5VD7M9h2PhZcAIOIiNTNB1710aWJBfKLFJi68zIKihRiRyIiKhUW8kRUZu0dzXHo007KLz9f7r2GidsikJFbKHY0IiKiUpNIJPh2UAuY6GniekImfgy5K3YkIqJSYSFPROVibqCNDSPb4Ms+ztCQSnDwWhJ6//A3wh48FjsaERFRqVka6SBogCsAYNXJewiPYT9GRNUfC3kiKjep9Nms9rsntIeDmR4eZuRhyM+hWHr0NorkHJ5IRETqoberDd5rVRcKAZgafAU5+UViRyIieiUW8kT0xtzsTLD/k04Y5FEPCgH48a97GLQmFNFpOWJHIyIiKpWv+jVDXRNdxD7Oxdw/b4odh4jolVjIE1GFMNDWwJL33bDcryWMdDRwOS4dfX48jR1hnAiPiIiqPyMdTXw32A0SCRB8MQ6bznFJOiKqvljIE1GF8nGzxeEpndG2YR3kFsgxc881fLQ5HKlZ+WJHIyIieqW2Dc3weU9nAMDXf97AiVspYkciIioRC3kiqnC2JrrYNqYtAno7Q1MmwfHIZPRa9jeO3EgSOxoREdErje/SEINbP3tUbNK2CEQmZoodiYioGBbyRFQppFIJxnVxxB+TOsLZ2hCPcgowbks4pu+8gsw8LlNHRETVk0QiwTfvuqJdQzPkFMjx4cYLSMnMEzsWEZEKFvJEVKma2hjh90kdML6LIyQSYHdEPHp+/zf+vpMqdjQiIqISaWlIseYDDzS00MfDjDyM2XwRTwvkYsciIlJiIU9ElU5bQ4aZvZ2xc1w72JvpITEjD/7rw/Dl3mvI5hI/RERUDRnraWLDyDYw1dPE1fgMTA2+DIWCk7cSUfXAQp6Iqkwbhzo49GknjGhnDwDYdj4WPb//G6fv8u48ERFVP/Zm+vjZvzW0ZFIcvpGERUduiR2JiAhgIU9EVU1PSwNf92+ObR95wa6OLhLSn2L4ujDM3H2Vz84TEVG108ahDhYPagEA+OlUFHaExYodiYiIhTwRiaO9ozkOf9pZeXd+x4U49Fj6N47fTBY7GhERkYp3W9bFp90bAwBm7buOs/fSxI5ERLUcC3kiEo2+9rO78zvGtoW9mR6SMp9NKPTJ9kt4lM1154mIqPqY4t0Y/d1tUaQQMP7XcNxLyRI7EhHVYizkiUh0bRua4fCnnTGuc0NIJcAfVx7Ce+kp7A6PhyBwYiEiIhKfRCLBooEt0NreFFl5RRi18QJ/dCYi0bCQJ6JqQVdLhoA+TbFvYgc4WxviSW4hpv92BcPXhSHmUY7Y8YiIiKCjKcNPwz1Qv44e4h4/xdgt4cgr5LJ0RFT1WMgTUbXSop4J/pzcEZ/3coK2hhRn7qWhx/d/Y+WJeygoUogdj4iIajkzA22sH9kGRjoaCI95gs93XeXoMSKqcizkiaja0ZRJ8XHXRjgypTM6NDJDfpEC3x65jXeWn8aF6MdixyMiolqukaUB1nzgAQ2pBH9ceYhlx++KHYmIahkW8kRUbTmY6+PXD72wdLAb6uhr4U5yNt5fE4ovdl3Fk5wCseMREVEt1r6ROeYPaA4A+CHkLvZdShA7EhHVIizkiahak0gkeK9VPfw1vQuGtLEDAARfjMNb353EjrBYKBQczkhEROLwbVMf47s4AgA+33UVYQ84aoyIqgYLeSJSCyZ6Wlg4sAV2jW+nnAxv5p5rGLjmHK4nZIgdj4iIaqnPezqhd3NrFMgVGLflIqLTOEErEVU+FvJEpFZaO9TBn5M7YlbfptDXkuFSbDp8VpzBrH3XkJ7L4fZERFS1pFIJlg52h1s9YzzJLcTojReQkVsodiwiquFYyBOR2tGUSTGmU0OETO+Kfm62EATg139i0W3JSWw7Hws5h9sTEVEV0tWSYe2I1qhroouotByM/zWcK60QUaViIU9EasvaWAc/+rXE9o/aoomVAZ7kFuLLvdfQb8UZzm5PRERVytJQB+tGtoaBtgZCox7hf3uvcVk6Iqo0LOSJSO21czTDgU86YfY7LjDU0cCNh5l4f00oPtl+CQ/Tn4odj4iIaglnayMsH9oSUgnwW3g8Vp+6L3YkIqqhWMgTUY2gKZNidMcGOPlZV/h52kEiAf648hBvfXcS3x+7g6cFcrEjEhFRLdDNyRJf92sGAFh8+DYOXksUOxIR1UAs5ImoRjEz0EbQey3w56SOaONgirxCBX4IuYu3vjuJvZfiuVwdERFVuuHtHDCqgwMAYGrwZZy4nSJ2JCKqYVjIE1GN1LyuMXaOa4eVQ1uhrokuEjPyMDX4Ct5ddZbr/BIRUaWb1dcFPVyskF+kwNjNF3HgKu/ME1HFYSFPRDWWRCJB3xY2CJneBZ/3coKBtgauxmdg8E+hGLflIqJSs8WOSERENZRMKsHKYa3g42aLQrmAydsjEHwhVuxYRFRDsJAnohpPR1OGj7s2wonPumKoV31IJcCRG8no8f3fmP37daRl54sdkYiIaiBNmRTLfN3h51kfCgH4Yvc1/HI6SuxYRFQDsJAnolrDwlAbCwa44vCUznjL2RJFCgGbQ2PQ9duT+DHkLnLyi8SOSERENYxMKsGCAc0xrnNDAMA3ByKx9NgdLk1HRG+EhTwR1TpNrAyxfmQbbPvIC651jZGdX4Slx+6gy7cn8es/MSiUK8SOSERENYhEIsHM3s6Y0dMJAPBjyF18/edNTsBKROXGQp6Iaq32jub4fWIHLPdrifp19JCWnY9Z+67j7aWn8PvlBH7BIiKiCiORSDCxWyPM7f9sabqN56Lx+e6rKOKPx0RUDizkiahWk0ol8HGzxfFpXfB1v2YwN9BC9KNcfLrjMvouP4O/biVz+CMREVUY/3YOWDrYDTKpBLvC4zF5+yXkF8nFjkVEaoaFPBERAC0NKUa0d8CpGd0w/e0mMNTWQGRiJkZvvIiBq8/h3P00sSMSEVEN8V6relg1rBW0ZFIcup6EMZsuIreA87QQUemxkCci+hd9bQ1M7t4Yf3/eDWM7N4S2hhQRsekYuvY8hq79B+ExXIOeqDxWrlwJBwcH6OjowMvLC2FhYa9sv2zZMjg5OUFXVxd2dnaYOnUq8vLylK+vXr0aLVq0gJGREYyMjNCuXTscOnSoCq6EqGL0bGaN9SPbQE9LhtN30+C/LgwZTwvFjkVEaoKFPBFRCUz1tfBln6b4+/Nu8G9nD02ZBOfuP8LA1aEYsT4Ml+PSxY5IpDaCg4Mxbdo0zJkzBxEREXBzc0PPnj2RkpJSYvtt27Zh5syZmDNnDiIjI7Fu3ToEBwfjyy+/VLapV68eFi5ciPDwcFy8eBFvvfUW+vfvjxs3blThlRG9mY6NzbHlQy8Y6WjgYswT+P38D5dEJaJSkQh8+LOYzMxMGBsbIyMjA0ZGRmLHIaJqIO5xLlaeuIffwuMhfz4JXndnS3zq3Rgt6pmIHY9qAXXum7y8vNCmTRusWLECAKBQKGBnZ4fJkydj5syZxdpPmjQJkZGRCAkJUe6bPn06zp8/jzNnzrz0ferUqYNvv/0WH3744WszqfPnSTXPzYeZ8F9/HmnZBWhoro9fx3jB1kRX7FhEVMXK0jfxjjwRUSnY1dHDwoEt8Nf0LhjYqh6kEiDkVgr6rTiL0Rsv4Arv0BOVqKCgAOHh4fD29lbuk0ql8Pb2RmhoaInHtG/fHuHh4crh91FRUTh48CD69OlTYnu5XI4dO3YgJycH7dq1K7FNfn4+MjMzVTai6sLF1gi/jW+Puia6iErLwftrQvEgLUfsWERUjbGQJyIqA3szfXw32A0h07vivVZ1IZUAf91KQf+VZzFifRifoSf6j7S0NMjlclhZWanst7KyQlJSUonHDB06FHPnzkXHjh2hqakJR0dHdO3aVWVoPQBcu3YNBgYG0NbWxvjx47F37164uLiUeM6goCAYGxsrNzs7uwq8SqI318BcH7+Nb4eG5vpISH+K99eEIjKRPzgRUclEL+TLMvnNjRs3MHDgQDg4OEAikWDZsmXF2sjlcgQGBqJBgwbQ1dWFo6Mj5s2bx+WjiKhCNTDXx9LB7giZ3hUDW9WDTCrBqTupGLg6FEPX/oNz99P4/ztE5XTy5EksWLAAq1atQkREBPbs2YMDBw5g3rx5Ku2cnJxw+fJlnD9/HhMmTMCIESNw8+bNEs8ZEBCAjIwM5RYXF1dFV0NUerYmutg5vh1cbIyQlp0P359CERH7ROxYRFQNiVrIl3Xym9zcXDRs2BALFy6EtbV1iW0WLVqE1atXY8WKFYiMjMSiRYuwePFiLF++vJKvhohqowbmz+7Qn5jeFUPa2CknxRu69jwGrj6HkEiuQ0+1m7m5OWQyGZKTk1X2Jycnv7QvDwwMxPDhwzFmzBi4urpiwIABWLBgAYKCgqBQKJTttLS00KhRI3h4eCAoKAhubm744YcfSjyntra2cob7FxtRdWRuoI3tY9vCw94UmXlF+OCX8zhzl0ugEpEqUQv5pUuX4qOPPsKoUaPg4uKCNWvWQE9PD+vXry+xfZs2bfDtt99iyJAh0NbWLrHNuXPn0L9/f/Tt2xcODg4YNGgQevTo8dplboiI3kR9s2fP0J+c0Q0j2tlD6/mydR9uuojeP5zG75cTUCRXlOJMRDWLlpYWPDw8VCauUygUCAkJeenz7Lm5uZBKVb+iyGQyAHjlD2MKhQL5+Zzxm9Sfsa4mtnzoiU6NzZFbIMfojRdw5EbJj6IQUe0kWiFfnslvSqN9+/YICQnBnTt3AABXrlzBmTNn0Lt375cewwlwiKii1DXRxdf9m+PMF90wrnND6GvJcCspC5/uuIy3vjuFLf/EIK9QLnZMoio1bdo0rF27Fps2bUJkZCQmTJiAnJwcjBo1CgDg7++PgIAAZXsfHx+sXr0aO3bswIMHD3Ds2DEEBgbCx8dHWdAHBATg77//RnR0NK5du4aAgACcPHkSw4YNE+06iSqSnpYGfhnRGr2aWaNArsDHWyOwJyJe7FhEVE1oiPXGr5r85tatW+U+78yZM5GZmQlnZ2fIZDLI5XLMnz//lR17UFAQvv7663K/JxHRf1ka6iCgT1NM6OqIzaEx2HD2AWIf5yJw33X8cPwORrZ3wPC2DjDW0xQ7KlGl8/X1RWpqKmbPno2kpCS4u7vj8OHDyu8AsbGxKnfgZ82aBYlEglmzZiEhIQEWFhbw8fHB/PnzlW1SUlLg7++PxMREGBsbo0WLFjhy5AjefvttUa6RqDJoa8iwYmhLzNxzDbvC4zFt5xVEpeZgindjaMhEn+qKiEQk2jryDx8+RN26dXHu3DmVoXWff/45Tp06hfPnz7/yeAcHh/9r797joqrz/4G/ZoCB4X6/3xXQEIhECS/Zput1LcsuGutil3V1sZXt8s2tzPr1c6ns67pZS/X9ptWmWe5qpmYu4t1IFPCOgMpV5H4Huc18vn+Ao8NFUWaYC6/n4zEPh3M+M7zP22He5z3nzOcgISEBCQkJass3b96MV155BatXr0ZoaChOnjyJhIQErFmzBnFxcb0+V2trq9qpePX19fDx8eG1ZYlIY5rbOvDt8SL87+E8XKm9BgCwlJlg3hhfPDvBH94OlroOkfQcr3uuWcwnGRKlUmDVj1n4/EgeACDKzwF/nx8JL15rnsio3Elt0tkR+buZ/KY/XnnlFSxfvhzz5s0DAISFhaGgoACJiYl9NvLm5uZ9fueeiEgTLGWmeGZ8AH57vx92nb6KTw5ewoXSBqw/mocvU/MxM8wDv58YgHBve12HSkREekYqlWDFb+7BvT72eG3rGZwoqMHMvx/G+4+HY1ro3e83E5Hh0tk5OXcz+U1/9DVBzs2z3BIR6YqZiRRzIr2we9lEfPXsWEwY7gyFUmDHqRI8/NFRPPlpKv5zrhQKJWe6JyIidbMjPLHrTxMR4W2Humvt+MM/07Fy+1nOvUI0BOnsiDy6Jr+Ji4tDVFQUxo4di7Vr1/aY/MbLywuJiYlA1wR5168P29bWhitXruDkyZOwtrbG8OHDga4JclatWgVfX1+EhoYiMzMTa9aswbPPPqvDLSUiUieRSPBAsAseCHbBuZI6/O/hPOw4VYK0vGqk5VXDz8kSz4zzx+NRPrA21+lbNRER6RFfJ0tsWTwOH/wnG58duowvUwtwPL8G656OxDAXa12HR0SDRGffkb/uo48+wurVq1WT33z44YeIjo4GADz44IPw9/fHF198AQDIz89HQEBAj+eYNGkSDhw4AABoaGjAihUrsG3bNpSXl8PT0xPz58/Hm2++CZlM1q+Y+L05ItKF0roWfJmaj42/FKC+pQMAYGNuiifH+CAuxh++Tvwe/VDG2qRZzCcZg/3Z5Xjpu1OobmqDpcwE7zwyCnNHe+s6LCK6S3dSm3TeyOsjFnci0qXmtg78O+MKNhzNw+WKJgCARAJMHuGGZ8b7Y9wwJ0gkEl2HSYOMtUmzmE8yFmX1LUjYfBKpl6sAAI9FeuH/zRnFs7mIDBAb+QFicScifaBUChzMrcD6I3k4nFupWj7c1RpxMX549D5v7qgNIaxNmsV8kjFRKAX+sf8i/rY3B0oBBDhbYd38SIzystN1aER0B9jIDxCLOxHpm4vljfgqNR//Ti9GU1vnpEbW5qaYe58XFsT4Ybirja5DJC1jbdIs5pOM0fH8avzpm0xcrWuBzESKv8wcgYXj/HkWF5GBYCM/QCzuRKSv6lvasTW9GF+lFuByZZNqeUygExbE+OHX97jBzERnFyQhLWJt0izmk4xVbXMbXvnXaSSf77zE85SRrlj9eAQcrPo3VxQR6Q4b+QFicScifadUChy5WIl//lKAlKwyXL9anYuNOeaN8cG8sb7wspfrOkzSINYmzWI+yZgJIfBVagFW7cpCm0IJDzsL/H1eJMYGOOo6NCK6BTbyA8TiTkSG5ErtNWxOK8Q3aUWobGwFAEglwIMhrnh6rC8eDHGBKY/SGzzWJs1iPmkoOFdShxc2ZeJyZROkEiBhSjDifzUcJlKeak+kj9jIDxCLOxEZorYOJZLPl2HjsQL8fKlKtdzd1gJPjvHBk1He8HbgJewMFWuTZjGfNFQ0tXZgxfaz2JpxBQBwf6Aj/j4vEm62FroOjYi6YSM/QCzuRGToLlU04tvjRfhXejGqm9qArkvYTQxywfwxPpg80g0yUx6lNySsTZrFfNJQ8+/0YqzYfhbNbQo4WsnwwRPheGiEm67DIqKbsJEfIBZ3IjIWrR0K7DlXhs1phWpH6Z2sZHg00gtPjfFBkBtnvDcErE2axXzSUHS5ohFLN2Xi/NV6AMATo73x8rQQHp0n0hNs5AeIxZ2IjFFBVRO+O1GELSeKUd7Qqlp+r489nojyxuwIT9hamOk0Ruoba5NmMZ80VLV2KJD44wV88XM+AEBuZoJFDwTiD5MCYSkz1XV4REMaG/kBYnEnImPWoVDiYE4Fvj1ehH0XytHRNeW9uakU00e5Y+593hg/3JmTIekZ1ibNYj5pqMsorMH/33keGYW1AABXG3O8PDUEc0d78/2fSEfYyA8QizsRDRUVDa34PvMKtqQXIaesUbXc3dYCcyK98PhoLwx35an3+oC1SbOYT6LOy9T9eKYU7/6UhaLqawCAEe42eH3WSEwMctF1eERDDhv5AWJxJ6KhRgiBM1fqsOVEMX44VYK6a+2qdeHedng00gsPR3jCydpcp3EOZaxNmsV8Et3Q2qHAP1ML8GFKLupbOgAAD4a44LWZIxHMeVSIBg0b+QFicSeioay1Q4F9WeX4d0YxDmRXqE69N5FKMCnYBXMivfDrkW6Qy0x0HeqQwtqkWcwnUU81TW34cF8u/plagA6lgFQCPDXGFy/+OhguNvwgl0jb2MgPEIs7EVGnqsZW7DhVgm2ZV3CquE613Epmgmmh7nj4Xk9MGO4MUxNeyk7bWJs0i/kk6lteZRPe230BP50rBbre8xdPGobnJwbyQ1wiLWIjP0As7kREPV2qaMT3mVewLfMKimuuqZY7WckwK9wDD0d44j5fB0g5SZJWsDZpFvNJdHtpedVYteu86oNcDzsLvDw1BI9GevG9nkgL2MgPEIs7EVHfhBBIL6jBD6dKsPP0VVQ3tanWednL8ZsID8wO90Sopy0kEu7oaQprk2Yxn0T9o1QK7Dhdgvd/ysaV2s4PcUd52eL1mfcgZpiTrsMjMips5AeIxZ2IqH/aFUocuViJHSdL8J/zZWhs7VCtC3C2wm/CPfCbcE8Eu1mzqR8g1ibNYj6J7kxLuwIbjubjH/svoqHrvX7KSFcsnzESw12tdR0ekVFgIz9ALO5ERHeupV2B/RfKseN0CVKyytHaoVStG+5qjZlhHvhNuAdnQL5LrE2axXwS3Z2qxlb8PSUXG48VQqEUMJFKEBvtixceCuKEeEQDxEZ+gFjciYgGprG1AylZZdhx6ioO5VSgTdGtqR/ljhlhHhjhbsMj9f3E2qRZzCfRwFwsb8S7u7OwN6scAGBmIsG0UHfERvvh/kBHvrfTkCKE0Mhrno38ALG4ExFpTn1LO1KyyrDz1FUczq1Ua+r9nSwxfZQHZoxyR7i3HXf8boG1SbOYTyLN+PlSJVbvyUZmYa1qWaCLFZ4e64vHR3vD3lKm0/iItKGxtQMZBTU4kV+NtPxqNLUqsOOFCQN+XjbyA8TiTkSkHfUt7diXVY4fz1zFwZwKtdPvPe0sMDXUHdNC3THG34GXtOuGtUmzmE8izTp7pQ6b0gqxPfMKmtoUAACZqRSzwjwQG+2L0X4O/LCWDFZ5QwtO5NcgLa8aJwqqcb6kHspuXXTGil/D0WpgH1yxkR8gFnciIu1rau3A/uxy7D5biv0XytHcteMHAA6WZpg80g3TQt0xMcgZFma8bjFrk2Yxn0Ta0djage0nr2DjL4U4f7VetTzEzQZPR/vi0fu8YGthptMYiW5FCIG8yiYcz6/G8fzOo+75Vc09xvk4yjHGzxFR/o4YG+CAQGfrAV+WkY38ALG4ExENrpZ2BQ7nVmLPuVLszSpDbXO7ap3czAQTg5zx63vcMHmk24A/7TZUrE2axXwSaZcQAqeK67DpWAF+OFWClvbOM7DkZiaYHeGB2Gg/fqWK9EKHQolzJfU4nl+NE/k1OFFQjcrGNrUxEgkwwt0WY/0dEOXviCh/B3jYyTUeCxv5AWJxJyLSnQ6FEmn51fjPuTL851wpSupaVOukEiDKzxGTR7piyj1uGOYydC55xNqkWcwn0eCpu9aObRnF2JRWiJyyRtXyUE9bxEb74eF7PWFtbqrTGGnoqG9px+miOpwoqMbx/GpkFtaqnRWIrq+F3OtjjzFdjftoP4dBOZOEjfwAsbgTEekHIQTOldQj+XwZks+XqZ2mia5r1U8e4YqHRrpijL8jzIz4e/WsTZrFfBINPiEEThTUYNOxQuw6cxVtXfOkWMlMMCfSC09H+yLU007XYZIRaWlX4FxJPU4X1+JUUS1OF9fhcmVTj3F2cjNE+TlgTIAjxvg7YJSXHcxNB/9rfWzkB4jFnYhIPxXXNGPfhXIkny/DL5er0K64UcJsLEzxQLALHgpxxYMhLnCyNq7rGbM2aRbzSaRbNU1t+HdGMTYeK0TeTY3VvT72eHy0NyYFu8DH0VKnMZJh6VAokVPW2Nm0F9fhVFEtcsoa0NF9Vrqu77eP9u082j7G3xFBrgP/frsmsJEfIBZ3IiL919DSjsO5lUjJKsf+7HJUN934PptEAkR42+NXIa741QgXjPK004sCPRCsTZrFfBLpByEEUi9VYWNaIfacLVVrugKcrTAxyBkTg1xwf6AjbDhJHnURQiC/qrnrSHsdThXX4lxJnWouhps5W5sjwtsOET72CPe2Q7i3vd7Ot8NGfoBY3ImIDItCKXCyqBb7L5Rj34XyHqfgO1vL8ECwCyYFu+CBIBc46GkBvxXWJs1iPon0T0VDK/6VXoyUrDJkFtVCcVNTbyqV4D5fh87GPtgFYV52MDHwD2ipf5RKgeKaa8gq7TxF/nTX0fb6lo4eY23MTRHW1azf69P5r4edhcFMqshGfoBY3ImIDFtpXQsOZHceqT+SW6m6pjG6JswL97bHpGAXTApxQYS3vUHsDLI2aRbzSaTf6lvakXqpCodzK3Akt7LH5b/s5GaYMNxZ1dh72Wt+BnEaXEIIVDS2Iqe0ERdK65FT1oDsskbkljX0mIwOXRPShXraIsL7xpH2QGcrgz4Dj438ALG4ExEZj7YOJU7kV+NATgUOZJerzZiMrp3B8cOd8ECQi17vDLI2aRbzSWRYCquacfhiBQ7nVOLopUo0dDsaG+hi1fk+HuSM+wOdYMVZ8PVafUs7ckobkF3WgJzSBlwobUBOWQNqbrr87M1kJlIMc7VGuJcdwn3sEOFtj2A3G8hMjWuSWzbyA8TiTkRkvEpqr+FwbgUO5nQe5el+al6gixUmDu/6TuYwJ725JBJrk2Yxn0SGq0OhxKniOhzKqcDh3AqcLKrFzfOZmZl0nob/QLAL7g90QrCbNb9fryMt7QpcLG/sPLp+U+N+86VlbyaVAP5OVgh2s0Gwuw1GuNsg2M0G/k6WMDXiK9Ncx0Z+gFjciYiGhus7g4dzK3Aop+fOoKlUgnt97DEhyBkThjsjwsdeZ5e4Y23SLOaTyHjUXWtH6qVKHMqtxKGcChTXXOsxxsPOAsNdrVW3IFcbDHe11ttJzwyFEAIVDa0oqmlGUfU1FFU3o7C6WfXz1bpr6GXSeKDr/yTYzQYh7jYI6fp3uKs1LMwG/7Jv+oKN/ACxuBMRDU3XdwYP51biyMVKFHT7TqaVzARjAxwxfrgzxg1zxgh3m0H7Lh5rk2Yxn0TGSQiBgqrmzg9ocyuRWViLysbWPsc7WckwzNUaQd0afDdbc4OZIE3b6q61o6i6GcVdzfmNRr0ZxTXX0NrRc6b4m9nJzRBy09H1EHcbBLvawM6SZ0l0x0Z+gFjciYgIAIqqm3H0YiUOX6xE6qUqtUvcAYCDpRlihjkhZpgzYgKdMMzFSms7fqxNmsV8Eg0ddc3tuFjRgNyyRlwsb0Rueee/V2p7Hrm/zsbcVL3Bd7NGoLM1HK1lsDE3NfgmXwiB+pYO1Da3obqpDbXN7ajpul/e0IrCqhvNem+zw99MKgE87OTwdpDDx9ESPg6W8HWSd/7raAkXG34o0l9s5AeIxZ2IiLpTKgWySuvx88UqHL1UibS86h6z6LrYmCMm0An3BzohZpgT/J0sNbbzwtqkWcwnETW1duByRRNyyxtUDf6l8kbkVzX1eTo4uhpXO7nZjZulDHZyM9irLTO7sUx1XwYLM6nG6oIQAkrReQnWxtYO1DS3oaapDTVdTbnqflMbapo7m/Xq5jbUdt3vuNVGduNkJYO3oyV8HOTwdbRUNew+jnJ42MmNbtI5XWEjP0As7kREdDvtCiVOF9fi54tVSL1chRMFNWjrdnqhm605ZozywFsPhw7497E2aRbzSUR9ae1QIL+yudcGv6X91qeR347MRAo7SzPYWphCKpFAIQSUyhsNuVJ03hRKdP3btUwpOscKqO5roouzlJnAwVIGe0szOFrJYG8pg4u1OXwc5V2NuiW8HeS8CsAguZPaxP8RIiKiu2BmIsVoP0eM9nPEC5OD0NKuQGZhLVIvV+HY5SpkFtairL4V5Q29z8w71Hz88cdYvXo1SktLERERgXXr1mHs2LF9jl+7di2SkpJQWFgIZ2dnPP7440hMTISFhQUAIDExEVu3bsWFCxcgl8sxbtw4vPfeewgJCRnErSIiY2RuatI5AZu7TY91Le0K1F9rR+21dtRda0dd883321B307ra5na1sQqlQJtCiYqGVlQ09P29/btlY2EKB0sZHKxkcLA067xv2Xnf3koGx677nes7m/ehPLGcoWMjT0REpAEWZiZd35d3Arp29jIKayDnThK+/fZbvPjii/jkk08QHR2NtWvXYtq0acjOzoarq2uP8Zs2bcLy5cuxfv16jBs3Djk5OVi4cCEkEgnWrFkDADh48CDi4+MxZswYdHR04LXXXsPUqVNx/vx5WFlZ6WAriWgosDAzgYWZCVxtLe7ocUIINLUpUNvV7Ndd67xeulQigYlUctO/N5Z1/1kqkUAqlcBEIoFUis5/u5ZZykx0dlUV0g2eWt8Lnm5HRET6xpBrU3R0NMaMGYOPPvoIAKBUKuHj44MXXngBy5cv7zF+6dKlyMrKQkpKimrZSy+9hGPHjuHIkSO9/o6Kigq4urri4MGDeOCBB24bkyHnk4iIjNOd1CZ+bENERERa09bWhvT0dEyZMkW1TCqVYsqUKUhNTe31MePGjUN6ejrS0tIAAJcvX8aPP/6ImTNn9vl76urqAACOjo69rm9tbUV9fb3ajYiIyFDx1HoiIiLSmsrKSigUCri5uaktd3Nzw4ULF3p9zNNPP43KykpMmDABQgh0dHRg8eLFeO2113odr1QqkZCQgPHjx2PUqFG9jklMTMTbb7+tgS0iIiLSPR6RJyIiIr1y4MAB/PWvf8U//vEPZGRkYOvWrdi1axfeeeedXsfHx8fj7Nmz2Lx5c5/P+Ze//AV1dXWqW1FRkRa3gIiISLt4RJ6IiIi0xtnZGSYmJigrK1NbXlZWBnd3914fs2LFCixYsADPP/88ACAsLAxNTU1YtGgRXn/9dUilN45DLF26FDt37sShQ4fg7e3dZxzm5uYwNzfX2HYRERHpEo/IExERkdbIZDKMHj1abeI6pVKJlJQUxMTE9PqY5uZmtWYdAExMOmf/vz5HrxACS5cuxbZt27Bv3z4EBARodTuIiIj0CY/IExERkVa9+OKLiIuLQ1RUFMaOHYu1a9eiqakJzzzzDADgd7/7Hby8vJCYmAgAmD17NtasWYPIyEhER0fj4sWLWLFiBWbPnq1q6OPj47Fp0yZs374dNjY2KC0tBQDY2dlBLpfrcGuJiIi0j408ERERadVTTz2FiooKvPnmmygtLcW9996Ln376STUBXmFhodoR+DfeeAMSiQRvvPEGrly5AhcXF8yePRurVq1SjUlKSgIAPPjgg2q/a8OGDVi4cOGgbRsREZEu8DryveC1ZYmISN+wNmkW80lERPqG15EnIiIiIiIiMlJs5ImIiIiIiIgMCBt5IiIiIiIiIgPCRp6IiIiIiIjIgLCRJyIiIiIiIjIgbOSJiIiIiIiIDAivI9+L61fkq6+v13UoREREwE01iVeN1QzWeiIi0jd3UuvZyPeioaEBAODj46PrUIiIiNQ0NDTAzs5O12EYPNZ6IiLSV/2p9RLBj/Z7UCqVKCkpgY2NDSQSyYCeq76+Hj4+PigqKoKtra3GYjRUzMcNzIU65uMG5uIG5uIGIQQaGhrg6ekJqZTfjBsoTdZ6GMFrlfHrFuPXLcavW4z/hjup9Twi3wupVApvb2+NPqetra1BvjC1hfm4gblQx3zcwFzcwFx04pF4zdFGrYcRvFYZv24xft1i/LrF+Dv1t9bzI30iIiIiIiIiA8JGnoiIiIiIiMiAsJHXMnNzc6xcuRLm5ua6DkUvMB83MBfqmI8bmIsbmAsyFIb+WmX8usX4dYvx6xbjvzuc7I6IiIiIiIjIgPCIPBEREREREZEBYSNPREREREREZEDYyBMREREREREZEDbyRERERERERAaEjbyWffzxx/D394eFhQWio6ORlpam65C0LjExEWPGjIGNjQ1cXV0xZ84cZGdnq41paWlBfHw8nJycYG1tjblz56KsrExnMQ+Wd999FxKJBAkJCaplQy0XV65cwW9/+1s4OTlBLpcjLCwMJ06cUK0XQuDNN9+Eh4cH5HI5pkyZgtzcXJ3GrA0KhQIrVqxAQEAA5HI5hg0bhnfeeQc3zz9qzLk4dOgQZs+eDU9PT0gkEnz//fdq6/uz7dXV1YiNjYWtrS3s7e3x3HPPobGxcZC3hIaSO63pW7ZswYgRI2BhYYGwsDD8+OOPgxbrzfpTl7v74osvIJFI1G4WFhaDFvPN3nrrrR6xjBgx4paP0ZfcA4C/v3+P+CUSCeLj43sdr+vca+L9uTeDtU98q/jb29vx6quvIiwsDFZWVvD09MTvfvc7lJSU3PI57+Y1qI34AWDhwoU9Ypk+ffptn1cf8g+g178FiUSC1atX9/mcg5l/bfUx2tinYyOvRd9++y1efPFFrFy5EhkZGYiIiMC0adNQXl6u69C06uDBg4iPj8cvv/yC5ORktLe3Y+rUqWhqalKN+fOf/4wdO3Zgy5YtOHjwIEpKSvDYY4/pNG5tO378OD799FOEh4erLR9KuaipqcH48eNhZmaG3bt34/z58/jv//5vODg4qMa8//77+PDDD/HJJ5/g2LFjsLKywrRp09DS0qLT2DXtvffeQ1JSEj766CNkZWXhvffew/vvv49169apxhhzLpqamhAREYGPP/641/X92fbY2FicO3cOycnJ2LlzJw4dOoRFixYN4lbQUHKnNf3nn3/G/Pnz8dxzzyEzMxNz5szBnDlzcPbs2UGPvT91uTe2tra4evWq6lZQUDBoMXcXGhqqFsuRI0f6HKtPuUdX/b859uTkZADAE0880edjdJl7Tbw/dzeY+8S3ir+5uRkZGRlYsWIFMjIysHXrVmRnZ+Phhx++7fPeyWtQW/FfN336dLVYvvnmm1s+p77kH4Ba3FevXsX69eshkUgwd+7cWz7vYOVfW32MVvbpBGnN2LFjRXx8vOpnhUIhPD09RWJiok7jGmzl5eUCgDh48KAQQoja2lphZmYmtmzZohqTlZUlAIjU1FQdRqo9DQ0NIigoSCQnJ4tJkyaJZcuWCTEEc/Hqq6+KCRMm9LleqVQKd3d3sXr1atWy2tpaYW5uLr755ptBinJwzJo1Szz77LNqyx577DERGxsrxBDLBQCxbds21c/92fbz588LAOL48eOqMbt37xYSiURcuXJlkLeAhoI7relPPvmkmDVrltqy6Oho8Yc//EHrsd5O97rcmw0bNgg7O7tBjasvK1euFBEREf0er8+5F0KIZcuWiWHDhgmlUtnren3K/d28P/dGV/vE3ePvTVpamgAgCgoK+hxzp69BTekt/ri4OPHII4/c0fPoc/4feeQR8dBDD91yjK7yLzTUx2hrn45H5LWkra0N6enpmDJlimqZVCrFlClTkJqaqtPYBltdXR0AwNHREQCQnp6O9vZ2tdyMGDECvr6+Rpub+Ph4zJo1S22bMQRz8cMPPyAqKgpPPPEEXF1dERkZif/5n/9Rrc/Ly0NpaalaPuzs7BAdHW10+Rg3bhxSUlKQk5MDADh16hSOHDmCGTNmAEMsF931Z9tTU1Nhb2+PqKgo1ZgpU6ZAKpXi2LFjOombjNfd1PTU1NQe7/nTpk3Ti7/f7nW5L42NjfDz84OPjw8eeeQRnDt3bpAi7Ck3Nxeenp4IDAxEbGwsCgsL+xyrz7lva2vD119/jWeffRYSiaTPcfqU+5vdTW3S933iuro6SCQS2Nvb33LcnbwGte3AgQNwdXVFSEgIlixZgqqqqj7H6nP+y8rKsGvXLjz33HO3Haur/Guij9HWPh0beS2prKyEQqGAm5ub2nI3NzeUlpbqLK7BplQqkZCQgPHjx2PUqFEAgNLSUshksh5vmMaam82bNyMjIwOJiYk91g21XFy+fBlJSUkICgrCnj17sGTJEvzpT3/Cl19+CXTlA13bfzNjzMfy5csxb948jBgxAmZmZoiMjERCQgJiY2OBIZaL7vqz7aWlpXB1dVVbb2pqCkdHR6PPDw2+u6nppaWlevn321td7k1ISAjWr1+P7du34+uvv4ZSqcS4ceNQXFw8qPECQHR0NL744gv89NNPSEpKQl5eHiZOnIiGhoZex+tr7gHg+++/R21tLRYuXNjnGH3KfXd3U5v0eZ+4paUFr776KubPnw9bW9s+x93pa1Cbpk+fjq+++gopKSl47733cPDgQcyYMQMKhaLX8fqc/y+//BI2Nja3PS1dV/nXVB+jrX0607t+JFE/xMfH4+zZs1r7Hou+KyoqwrJly5CcnKyzSYL0iVKpRFRUFP76178CACIjI3H27Fl88skniIuL03V4g+q7777Dxo0bsWnTJoSGhuLkyZNISEiAp6fnkMsFEQ2e/tblmJgYxMTEqH4eN24cRo4ciU8//RTvvPPOIER6w/UzlQAgPDwc0dHR8PPzw3fffdevI3n65PPPP8eMGTPg6enZ5xh9yr0xa29vx5NPPgkhBJKSkm45Vp9eg/PmzVPdDwsLQ3h4OIYNG4YDBw5g8uTJgxrLQK1fvx6xsbG33UfWVf71vY/hEXktcXZ2homJSY8ZDMvKyuDu7q6zuAbT0qVLsXPnTuzfvx/e3t6q5e7u7mhra0Ntba3aeGPMTXp6OsrLy3HffffB1NQUpqamOHjwID788EOYmprCzc1tyOQCADw8PHDPPfeoLRs5cqTq9Kjr2zwU/m5eeeUV1VH5sLAwLFiwAH/+859VZ24MpVx0159td3d37zFJT0dHB6qrq40+PzT47qamu7u7693fb191uT+unzl08eJFrcXXX/b29ggODu4zFn3MPQAUFBRg7969eP755+/ocfqU+7upTfq4T3y9iS8oKEBycvItj8b35navwcEUGBgIZ2fnPmPRx/wDwOHDh5GdnX3Hfw8YpPxrso/R1j4dG3ktkclkGD16NFJSUlTLlEolUlJS1D5lNUZCCCxduhTbtm3Dvn37EBAQoLZ+9OjRMDMzU8tNdnY2CgsLjS43kydPxpkzZ3Dy5EnVLSoqCrGxsar7QyUXADB+/Pgel/DIycmBn58fACAgIADu7u5q+aivr8exY8eMLh/Nzc2QStXfgk1MTKBUKoEhlovu+rPtMTExqK2tRXp6umrMvn37oFQqER0drZO4yXjdTU2PiYlRGw8AycnJOvn7vV1d7g+FQoEzZ87Aw8NDKzHeicbGRly6dKnPWPQp9zfbsGEDXF1dMWvWrDt6nD7l/m5qk77tE19v4nNzc7F37144OTnd8XPc7jU4mIqLi1FVVdVnLPqW/+s+//xzjB49GhEREXf8WG3mXxt9jNb26e56mjy6rc2bNwtzc3PxxRdfiPPnz4tFixYJe3t7UVpaquvQtGrJkiXCzs5OHDhwQFy9elV1a25uVo1ZvHix8PX1Ffv27RMnTpwQMTExIiYmRqdxD5abZ60XQywXaWlpwtTUVKxatUrk5uaKjRs3CktLS/H111+rxrz77rvC3t5ebN++XZw+fVo88sgjIiAgQFy7dk2nsWtaXFyc8PLyEjt37hR5eXli69atwtnZWfzXf/2Xaowx56KhoUFkZmaKzMxMAUCsWbNGZGZmqmYN7s+2T58+XURGRopjx46JI0eOiKCgIDF//nwdbhUZs9vV9AULFojly5erxh89elSYmpqKDz74QGRlZYmVK1cKMzMzcebMmUGPvT91uXv8b7/9ttizZ4+4dOmSSE9PF/PmzRMWFhbi3Llzgx7/Sy+9JA4cOCDy8vLE0aNHxZQpU4Szs7MoLy/vNXZ9yv11CoVC+Pr6ildffbXHOn3LvSbenx966CGxbt061c+DuU98q/jb2trEww8/LLy9vcXJkyfV/h5aW1v7jP92r8HBir+hoUG8/PLLIjU1VeTl5Ym9e/eK++67TwQFBYmWlpY+49eX/F9XV1cnLC0tRVJSUq/Pocv8a6qPCQkJEVu3blX9rI19OjbyWrZu3Trh6+srZDKZGDt2rPjll190HZLWAej1tmHDBtWYa9euiT/+8Y/CwcFBWFpaikcffVRcvXpVp3EPlu6N/FDLxY4dO8SoUaOEubm5GDFihPjss8/U1iuVSrFixQrh5uYmzM3NxeTJk0V2drbO4tWW+vp6sWzZMuHr6yssLCxEYGCgeP3119V2JIw5F/v37+/1fSIuLk6Ifm57VVWVmD9/vrC2tha2trbimWeeEQ0NDTraIhoKblXTJ02apHr9Xvfdd9+J4OBgIZPJRGhoqNi1a5cOou5fXe4ef0JCgmpb3dzcxMyZM0VGRoZO4n/qqaeEh4eHkMlkwsvLSzz11FPi4sWLfcYu9Cj31+3Zs0cA6PU9XN9yr4n3Zz8/P7Fy5Uq1ZYO1T3yr+PPy8vr8e9i/f3+f8d/uNThY8Tc3N4upU6cKFxcXYWZmJvz8/MTvf//7Hg25vub/uk8//VTI5XJRW1vb63PoMv+a6mO6P0Yb+3SSrl9ERERERERERAaA35EnIiIiIiIiMiBs5ImIiIiIiIgMCBt5IiIiIiIiIgPCRp6IiIiIiIjIgLCRJyIiIiIiIjIgbOSJiIiIiIiIDAgbeSIiIiIiIiIDwkaeiIiIiIiIyICwkScivSCRSPD999/rOgwiIiLSEtZ6Is1hI09EWLhwISQSSY/b9OnTdR0aERERaQBrPZFxMdV1AESkH6ZPn44NGzaoLTM3N9dZPERERKRZrPVExoNH5IkI6Crk7u7uajcHBweg61S4pKQkzJgxA3K5HIGBgfjXv/6l9vgzZ87goYceglwuh5OTExYtWoTGxka1MevXr0doaCjMzc3h4eGBpUuXqq2vrKzEo48+CktLSwQFBeGHH35QraupqUFsbCxcXFwgl8sRFBTUY2eEiIiI+sZaT2Q82MgTUb+sWLECc+fOxalTpxAbG4t58+YhKysLANDU1IRp06bBwcEBx48fx5YtW7B371614p2UlIT4+HgsWrQIZ86cwQ8//IDhw4er/Y63334bTz75JE6fPo2ZM2ciNjYW1dXVqt9//vx57N69G1lZWUhKSoKzs/MgZ4GIiMh4sdYTGRBBRENeXFycMDExEVZWVmq3VatWCSGEACAWL16s9pjo6GixZMkSIYQQn332mXBwcBCNjY2q9bt27RJSqVSUlpYKIYTw9PQUr7/+ep8xABBvvPGG6ufGxkYBQOzevVsIIcTs2bPFM888o+EtJyIiGhpY64mMC78jT0QAgF/96ldISkpSW+bo6Ki6HxMTo7YuJiYGJ0+eBABkZWUhIiICVlZWqvXjx4+HUqlEdnY2JBIJSkpKMHny5FvGEB4errpvZWUFW1tblJeXAwCWLFmCuXPnIiMjA1OnTsWcOXMwbty4AW41ERHR0MFaT2Q82MgTEdBVTLuf/qYpcrm8X+PMzMzUfpZIJFAqlQCAGTNmoKCgAD/++COSk5MxefJkxMfH44MPPtBKzERERMaGtZ7IePA78kTUL7/88kuPn0eOHAkAGDlyJE6dOoWmpibV+qNHj0IqlSIkJAQ2Njbw9/dHSkrKgGJwcXFBXFwcvv76a6xduxafffbZgJ6PiIiIbmCtJzIcPCJPRACA1tZWlJaWqi0zNTVVTTKzZcsWREVFYcKECdi4cSPS0tLw+eefAwBiY2OxcuVKxMXF4a233kJFRQVeeOEFLFiwAG5ubgCAt956C4sXL4arqytmzJiBhoYGHD16FC+88EK/4nvzzTcxevRohIaGorW1FTt37lTtXBAREdHtsdYTGQ828kQEAPjpp5/g4eGhtiwkJAQXLlwAumaZ3bx5M/74xz/Cw8MD33zzDe655x4AgKWlJfbs2YNly5ZhzJgxsLS0xNy5c7FmzRrVc8XFxaGlpQV/+9vf8PLLL8PZ2RmPP/54v+OTyWT4y1/+gvz8fMjlckycOBGbN2/W2PYTEREZO9Z6IuMhEZ0zSBIR9UkikWDbtm2YM2eOrkMhIiIiLWCtJzIs/I48ERERERERkQFhI09ERERERERkQHhqPREREREREZEB4RF5IiIiIiIiIgPCRp6IiIiIiIjIgLCRJyIiIiIiIjIgbOSJiIiIiIiIDAgbeSIiIiIiIiIDwkaeiIiIiIiIyICwkSciIiIiIiIyIGzkiYiIiIiIiAzI/wGGo5hBozf98wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the MLPClassifier_3 class for binary classification\n",
    "class MLPClassifier_3:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, activation='relu', \n",
    "                 learning_rate=0.01, epochs=100, batch_size=32, optimizer='sgd', patience=5, min_delta=0.001):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) * np.sqrt(2. / layer_sizes[i-1]))\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "        self.set_activation(activation)\n",
    "\n",
    "    def set_activation(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = self.sigmoid\n",
    "            self.activation_derivative = self.sigmoid_derivative\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = self.tanh\n",
    "            self.activation_derivative = self.tanh_derivative\n",
    "        elif activation == 'relu':\n",
    "            self.activation = self.relu\n",
    "            self.activation_derivative = self.relu_derivative\n",
    "        elif activation == 'linear':\n",
    "            self.activation = self.linear\n",
    "            self.activation_derivative = self.linear_derivative\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -709, 709)))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh_derivative(x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_derivative(x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_derivative(x):\n",
    "        return np.ones_like(x)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.layer_outputs = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(self.layer_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self.activation(z) if i < len(self.weights) - 1 else self.sigmoid(z)\n",
    "            self.layer_outputs.append(a)\n",
    "        return self.layer_outputs[-1]\n",
    "\n",
    "    def backward_propagation(self, X, y, loss_function='bce'):\n",
    "        m = X.shape[0]\n",
    "        if loss_function == 'bce':\n",
    "            delta = self.layer_outputs[-1] - y.reshape(-1, 1)\n",
    "        elif loss_function == 'mse':\n",
    "            delta = (self.layer_outputs[-1] - y.reshape(-1, 1)) * self.sigmoid_derivative(self.layer_outputs[-1])\n",
    "        gradients = []\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dW = np.dot(self.layer_outputs[i].T, delta) / m\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            gradients.append((dW, db))\n",
    "            if i > 0:\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.activation_derivative(self.layer_outputs[i])\n",
    "        return list(reversed(gradients))\n",
    "\n",
    "    def update_parameters(self, gradients):\n",
    "        for i, (dW, db) in enumerate(gradients):\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None, loss_function='bce'):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        y = y.to_numpy()  # Convert to numpy array\n",
    "        if y_val is not None:\n",
    "            y_val = y_val.to_numpy()  # Convert to numpy array\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(0, X.shape[0], self.batch_size):\n",
    "                batch_X = X[i:i+self.batch_size]\n",
    "                batch_y = y[i:i+self.batch_size]\n",
    "                \n",
    "                y_pred = self.forward_propagation(batch_X)\n",
    "                gradients = self.backward_propagation(batch_X, batch_y, loss_function)\n",
    "                self.update_parameters(gradients)\n",
    "            \n",
    "            loss = self.compute_loss(X, y, loss_function)\n",
    "            self.losses.append(loss)\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_loss = self.compute_loss(X_val, y_val, loss_function)\n",
    "                self.val_losses.append(val_loss)\n",
    "                \n",
    "                if val_loss < best_val_loss - self.min_delta:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward_propagation(X)\n",
    "\n",
    "    def compute_loss(self, X, y, loss_function='bce'):\n",
    "        y_pred = self.forward_propagation(X)\n",
    "        if loss_function == 'bce':\n",
    "            return -np.mean(y * np.log(y_pred + 1e-8) + (1 - y) * np.log(1 - y_pred + 1e-8))\n",
    "        elif loss_function == 'mse':\n",
    "            return np.mean((y_pred - y.reshape(-1, 1))**2)\n",
    "\n",
    "# Load the Pima Indians Diabetes dataset\n",
    "diabetes_df = pd.read_csv('../../data/external/diabetes.csv')\n",
    "\n",
    "# Preprocess the dataset\n",
    "X_diabetes = diabetes_df.drop('Outcome', axis=1)\n",
    "y_diabetes = diabetes_df['Outcome']\n",
    "\n",
    "X_train_d, X_temp_d, y_train_d, y_temp_d = train_test_split(X_diabetes, y_diabetes, test_size=0.3, random_state=42)\n",
    "X_val_d, X_test_d, y_val_d, y_test_d = train_test_split(X_temp_d, y_temp_d, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler_d = StandardScaler()\n",
    "X_train_d_standardized = scaler_d.fit_transform(X_train_d)\n",
    "X_val_d_standardized = scaler_d.transform(X_val_d)\n",
    "X_test_d_standardized = scaler_d.transform(X_test_d)\n",
    "\n",
    "# Convert back to DataFrame for consistency\n",
    "X_train_d = pd.DataFrame(X_train_d_standardized, columns=X_diabetes.columns)\n",
    "X_val_d = pd.DataFrame(X_val_d_standardized, columns=X_diabetes.columns)\n",
    "X_test_d = pd.DataFrame(X_test_d_standardized, columns=X_diabetes.columns)\n",
    "\n",
    "# Train models with MSE and BCE loss\n",
    "model_mse = MLPClassifier_3(input_size=X_train_d.shape[1], hidden_sizes=[], output_size=1, activation='linear', epochs=1000)\n",
    "model_bce = MLPClassifier_3(input_size=X_train_d.shape[1], hidden_sizes=[], output_size=1, activation='linear', epochs=1000)\n",
    "\n",
    "model_mse.fit(X_train_d, y_train_d, X_val_d, y_val_d, loss_function='mse')\n",
    "model_bce.fit(X_train_d, y_train_d, X_val_d, y_val_d, loss_function='bce')\n",
    "\n",
    "# Plot the loss vs epochs for both models\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(model_mse.losses, label='MSE Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('MSE Loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model_bce.losses, label='BCE Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('BCE Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('figures/3/q_3_5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Observations and Differences\n",
    "We can observe the convergence plots and note down the differences. Typically, BCE loss is more suitable for binary classification tasks as it aligns better with the probabilistic interpretation of binary outcomes. MSE loss might not converge as well and could lead to different convergence behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Classification Accuracy: 0.6810\n",
      "\n",
      "==================================================\n",
      "\n",
      "Epoch 100/1000, Loss: 23.6294\n",
      "Epoch 200/1000, Loss: 23.5499\n",
      "Epoch 300/1000, Loss: 23.5393\n",
      "Epoch 400/1000, Loss: 23.5375\n",
      "Epoch 500/1000, Loss: 23.5373\n",
      "Early stopping at epoch 511\n",
      "Regression MSE: 28.3368\n",
      "Regression MAE: 3.5249\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "\n",
    "class MLP_combined:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, task='regression', activation='relu', \n",
    "                 learning_rate=0.01, epochs=100, batch_size=32, optimizer='sgd', patience=5, min_delta=0.001):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.task = task\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) * np.sqrt(2. / layer_sizes[i-1]))\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "        self.set_activation(activation)\n",
    "\n",
    "    def set_activation(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = self.sigmoid\n",
    "            self.activation_derivative = self.sigmoid_derivative\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = self.tanh\n",
    "            self.activation_derivative = self.tanh_derivative\n",
    "        elif activation == 'relu':\n",
    "            self.activation = self.relu\n",
    "            self.activation_derivative = self.relu_derivative\n",
    "        elif activation == 'linear':\n",
    "            self.activation = self.linear\n",
    "            self.activation_derivative = self.linear_derivative\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -709, 709)))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh_derivative(x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_derivative(x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_derivative(x):\n",
    "        return np.ones_like(x)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.layer_outputs = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(self.layer_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            if i < len(self.weights) - 1:\n",
    "                a = self.activation(z)\n",
    "            else:\n",
    "                if self.task == 'classification':\n",
    "                    a = self.sigmoid(z)\n",
    "                else:\n",
    "                    a = z\n",
    "            self.layer_outputs.append(a)\n",
    "        return self.layer_outputs[-1]\n",
    "\n",
    "    def backward_propagation(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        if self.task == 'classification':\n",
    "            delta = self.layer_outputs[-1] - y.reshape(-1, 1)\n",
    "        else:\n",
    "            delta = self.layer_outputs[-1] - y.reshape(-1, 1)\n",
    "        gradients = []\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dW = np.dot(self.layer_outputs[i].T, delta) / m\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            gradients.append((dW, db))\n",
    "            if i > 0:\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.activation_derivative(self.layer_outputs[i])\n",
    "        return list(reversed(gradients))\n",
    "\n",
    "    def update_parameters(self, gradients):\n",
    "        for i, (dW, db) in enumerate(gradients):\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        y = y.to_numpy()  # Convert to numpy array\n",
    "        if y_val is not None:\n",
    "            y_val = y_val.to_numpy()  # Convert to numpy array\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(0, X.shape[0], self.batch_size):\n",
    "                batch_X = X[i:i+self.batch_size]\n",
    "                batch_y = y[i:i+self.batch_size]\n",
    "                \n",
    "                y_pred = self.forward_propagation(batch_X)\n",
    "                gradients = self.backward_propagation(batch_X, batch_y)\n",
    "                self.update_parameters(gradients)\n",
    "            \n",
    "            loss = self.compute_loss(X, y)\n",
    "            self.losses.append(loss)\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_loss = self.compute_loss(X_val, y_val)\n",
    "                self.val_losses.append(val_loss)\n",
    "                \n",
    "                if val_loss < best_val_loss - self.min_delta:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward_propagation(X)\n",
    "\n",
    "    def compute_loss(self, X, y):\n",
    "        y_pred = self.forward_propagation(X)\n",
    "        if self.task == 'classification':\n",
    "            return -np.mean(y * np.log(y_pred + 1e-8) + (1 - y) * np.log(1 - y_pred + 1e-8))\n",
    "        else:\n",
    "            return np.mean((y_pred - y.reshape(-1, 1))**2)\n",
    "\n",
    "# Load the Pima Indians Diabetes dataset for classification\n",
    "diabetes_df = pd.read_csv('../../data/external/diabetes.csv')\n",
    "\n",
    "# Preprocess the dataset\n",
    "X_diabetes = diabetes_df.drop('Outcome', axis=1)\n",
    "y_diabetes = diabetes_df['Outcome']\n",
    "\n",
    "X_train_d, X_temp_d, y_train_d, y_temp_d = train_test_split(X_diabetes, y_diabetes, test_size=0.3, random_state=42)\n",
    "X_val_d, X_test_d, y_val_d, y_test_d = train_test_split(X_temp_d, y_temp_d, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler_d = StandardScaler()\n",
    "X_train_d_standardized = scaler_d.fit_transform(X_train_d)\n",
    "X_val_d_standardized = scaler_d.transform(X_val_d)\n",
    "X_test_d_standardized = scaler_d.transform(X_test_d)\n",
    "\n",
    "# Convert back to DataFrame for consistency\n",
    "X_train_d = pd.DataFrame(X_train_d_standardized, columns=X_diabetes.columns)\n",
    "X_val_d = pd.DataFrame(X_val_d_standardized, columns=X_diabetes.columns)\n",
    "X_test_d = pd.DataFrame(X_test_d_standardized, columns=X_diabetes.columns)\n",
    "\n",
    "# Train model for classification\n",
    "model_classification = MLP_combined(input_size=X_train_d.shape[1], hidden_sizes=[], output_size=1, task='classification', activation='linear', epochs=1000)\n",
    "model_classification.fit(X_train_d, y_train_d, X_val_d, y_val_d)\n",
    "\n",
    "# Evaluate classification model\n",
    "y_pred_classification = model_classification.predict(X_test_d)\n",
    "y_pred_classification_binary = (y_pred_classification > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test_d, y_pred_classification_binary)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Load the Housing dataset for regression\n",
    "housing_df = pd.read_csv('../../data/external/HousingData.csv')\n",
    "\n",
    "# Plot the distribution of the target variable (MEDV)\n",
    "medv_values = housing_df['MEDV']\n",
    "\n",
    "# Handle NaN values by filling them with the mean of the column\n",
    "housing_df.fillna(housing_df.mean(), inplace=True)\n",
    "\n",
    "# Ensure no NaN values are present\n",
    "assert not housing_df.isnull().values.any(), \"There are still NaN values in the dataset\"\n",
    "\n",
    "# Preprocess the dataset\n",
    "X_housing = housing_df.drop('MEDV', axis=1)\n",
    "y_housing = housing_df['MEDV']\n",
    "\n",
    "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
    "X_train_h, X_temp_h, y_train_h, y_temp_h = train_test_split(X_housing, y_housing, test_size=0.3, random_state=42)\n",
    "X_val_h, X_test_h, y_val_h, y_test_h = train_test_split(X_temp_h, y_temp_h, test_size=0.5, random_state=42)\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_h_imputed = imputer.fit_transform(X_train_h)\n",
    "X_val_h_imputed = imputer.transform(X_val_h)\n",
    "X_test_h_imputed = imputer.transform(X_test_h)\n",
    "\n",
    "# Normalize the features using Min-Max scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_h_normalized = min_max_scaler.fit_transform(X_train_h_imputed)\n",
    "X_val_h_normalized = min_max_scaler.transform(X_val_h_imputed)\n",
    "X_test_h_normalized = min_max_scaler.transform(X_test_h_imputed)\n",
    "\n",
    "# Standardize the features to have mean=0 and std=1 using Z-score scaling\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_h_standardized = standard_scaler.fit_transform(X_train_h_imputed)\n",
    "X_val_h_standardized = standard_scaler.transform(X_val_h_imputed)\n",
    "X_test_h_standardized = standard_scaler.transform(X_test_h_imputed)\n",
    "\n",
    "# Convert back to DataFrame for consistency\n",
    "X_train_h = pd.DataFrame(X_train_h_standardized, columns=X_housing.columns)\n",
    "X_val_h = pd.DataFrame(X_val_h_standardized, columns=X_housing.columns)\n",
    "X_test_h = pd.DataFrame(X_test_h_standardized, columns=X_housing.columns)\n",
    "\n",
    "# Train model for regression\n",
    "model_regression = MLP_combined(input_size=X_train_h.shape[1], hidden_sizes=[], output_size=1, task='regression', activation='linear', epochs=1000)\n",
    "model_regression.fit(X_train_h, y_train_h, X_val_h, y_val_h)\n",
    "\n",
    "# Evaluate regression model\n",
    "y_pred_regression = model_regression.predict(X_test_h)\n",
    "mse = mean_squared_error(y_test_h, y_pred_regression)\n",
    "mae = mean_absolute_error(y_test_h, y_pred_regression)\n",
    "print(f\"Regression MSE: {mse:.4f}\")\n",
    "print(f\"Regression MAE: {mae:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
