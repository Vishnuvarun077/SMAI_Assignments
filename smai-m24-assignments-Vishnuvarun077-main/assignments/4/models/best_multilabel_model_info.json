{
    "config": {
        "lr": 0.001,
        "dropout": 0.5,
        "optimizer": "adam",
        "epochs": 30,
        "conv_layers": 3
    },
    "metrics": {
        "train_losses": [
            0.26883404123299015,
            0.23707056079570413,
            0.22700076232555555,
            0.22062859933842258,
            0.21411897003801947,
            0.2089108709378291,
            0.20258843800440657,
            0.1964128128995145,
            0.1881698585555033,
            0.1787292158543156,
            0.16995314043487994,
            0.16337438222720538,
            0.15605169757822443,
            0.15166822287636966,
            0.14688706392337222,
            0.1435756712660269,
            0.13862559218243295,
            0.13584500121964416,
            0.13260257835996334,
            0.12839336139220878,
            0.12673193870613417,
            0.12377526682948098,
            0.12260995663437746,
            0.12019382489060387,
            0.11863568183129208,
            0.1166966187242929,
            0.11542961859914858,
            0.11333058681811778,
            0.11319904778209434,
            0.11093470932641611
        ],
        "val_losses": [
            0.25024163168161473,
            0.24045297440062177,
            0.23333771837914877,
            0.22921963800933767,
            0.229491166493043,
            0.22699929492429216,
            0.2230720157596342,
            0.21737829883127135,
            0.2097897660779826,
            0.21439643176470666,
            0.20032775790450422,
            0.17454789244034824,
            0.18420209081724603,
            0.1780465659586356,
            0.16580452686770164,
            0.1973536404127136,
            0.15642825844004116,
            0.1618431661515794,
            0.177454466990968,
            0.1652278315295723,
            0.18217290227519387,
            0.14941814886604218,
            0.16040223063108452,
            0.17669169770236662,
            0.13552099409850038,
            0.1392124275419306,
            0.1385585544729962,
            0.13369312807620365,
            0.13563182563620044,
            0.13240621026922414
        ],
        "train_exact_match": [
            0.006265862944162436,
            0.011183375634517767,
            0.01649746192893401,
            0.022075930629209213,
            0.02514276649746193,
            0.024455372253574695,
            0.027548646365249823,
            0.02929357022311784,
            0.03243972081218274,
            0.037436548223350255,
            0.05092005076142132,
            0.06472081218274112,
            0.07931472081218274,
            0.09033946700507614,
            0.109507191207657,
            0.11936865482233502,
            0.14112732657775057,
            0.1549016497461929,
            0.16851734349192096,
            0.18221235195846122,
            0.19146573604060912,
            0.20397102371387676,
            0.21277495772402905,
            0.22210765656480935,
            0.23270939086294415,
            0.24056154822335024,
            0.2570590101522843,
            0.2616857022500885,
            0.2675285532994924,
            0.2755922166072778
        ],
        "val_exact_match": [
            0.03324468085106383,
            0.0,
            0.03324468085106383,
            0.03324468085106383,
            0.03324468085106383,
            0.03590425531914894,
            0.041555851063829786,
            0.052526595744680854,
            0.047872340425531915,
            0.0398936170212766,
            0.01163563829787234,
            0.07214095744680851,
            0.0598404255319149,
            0.057180851063829786,
            0.07247340425531915,
            0.050199468085106384,
            0.09408244680851063,
            0.09075797872340426,
            0.07513297872340426,
            0.09308510638297872,
            0.07313829787234043,
            0.11070478723404255,
            0.09308510638297872,
            0.06382978723404255,
            0.16522606382978725,
            0.1519281914893617,
            0.15392287234042554,
            0.17918882978723405,
            0.17154255319148937,
            0.1875
        ],
        "train_hamming_acc": [
            0.9230391638465877,
            0.9325481175972926,
            0.9330372250423012,
            0.933285744500846,
            0.9333906161872533,
            0.9335501269035533,
            0.9341582064297802,
            0.9347495417371687,
            0.9354175479413424,
            0.9361648688663283,
            0.9379318245910886,
            0.9392687182741117,
            0.940941377608573,
            0.9422800338409475,
            0.9435464255499154,
            0.9447246897913142,
            0.9463797236322617,
            0.9476205583756344,
            0.9488182106598986,
            0.9499101099830796,
            0.9507367456288778,
            0.9516092075578116,
            0.9521917301184434,
            0.952922306824591,
            0.9536819655950366,
            0.9545077199661591,
            0.9555819937958263,
            0.9558419698251551,
            0.9561468908629442,
            0.9571497814438803
        ],
        "val_hamming_acc": [
            0.9318890366430264,
            0.9310800827423171,
            0.9310246749408988,
            0.9316452423167852,
            0.9316489361702129,
            0.9324357269503547,
            0.9329085401891253,
            0.9348699763593382,
            0.9353575650118205,
            0.9345929373522461,
            0.9345301418439719,
            0.9387115839243498,
            0.9360298463356975,
            0.9376920803782507,
            0.9407986111111111,
            0.9350251182033099,
            0.9418661347517728,
            0.9408503250591017,
            0.9409057328605201,
            0.943465573286052,
            0.9388778073286052,
            0.9460106382978725,
            0.9429632092198582,
            0.940266696217494,
            0.9503693853427895,
            0.9495087174940897,
            0.9502585697399527,
            0.951484929078014,
            0.9516326832151298,
            0.9535978132387708
        ]
    },
    "model_architecture": "MultiLabelCNN(\n  (conv_layers): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (4): Dropout2d(p=0.5, inplace=False)\n    )\n    (1): Sequential(\n      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (4): Dropout2d(p=0.5, inplace=False)\n    )\n    (2): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (4): Dropout2d(p=0.5, inplace=False)\n    )\n  )\n  (fc1): Linear(in_features=1152, out_features=512, bias=True)\n  (batch_norm_fc): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc2): Linear(in_features=512, out_features=30, bias=True)\n)",
    "final_metrics": {
        "train_loss": 0.11093470932641611,
        "val_loss": 0.13240621026922414,
        "train_exact_match": 0.2755922166072778,
        "val_exact_match": 0.1875,
        "train_hamming_acc": 0.9571497814438803,
        "val_hamming_acc": 0.9535978132387708
    }
}